Directory structure:
└── diala/
    ├── backend/
    │   └── src/
    │       ├── main.py
    │       ├── api/
    │       │   └── public/
    │       │       └── hunter_leadgen.py
    │       ├── core/
    │       │   └── leadgen/
    │       │       ├── API.md
    │       │       ├── hunter_search_service.py
    │       │       ├── jina_client.py
    │       │       └── PRODUCTION_IMPROVEMENTS.md
    │       └── tasks/
    │           └── hunter.py
    └── frontend/
        ├── convex/
        │   ├── hunterActions.ts
        │   ├── hunterHttpEndpoints.ts
        │   ├── hunterMutations.ts
        │   ├── hunterQueries.ts
        │   ├── rateLimitHelpers.ts
        │   ├── schema.ts
        │   └── testSetup.ts
        └── src/
            ├── app/
            │   ├── dashboard/
            │   │   └── business-hunter/
            │   │       └── page.tsx
            │   └── onboarding/
            │       └── hunter/
            │           └── page.tsx
            ├── components/
            │   └── onboarding/
            │       └── hunter/
            │           ├── CompanyDetailsStep.tsx
            │           ├── ContactPreferencesStep.tsx
            │           ├── IndustryLocationStep.tsx
            │           ├── SearchDefinitionStep.tsx
            │           ├── SearchKeywordsStep.tsx
            │           ├── SearchPreviewStep.tsx
            │           ├── SearchProgressStep.tsx
            │           ├── SearchResultsStep.tsx
            │           ├── types.ts
            │           └── ValidationCriteriaStep.tsx
            └── hooks/
                └── useHunterSearch.ts

================================================
FILE: backend/src/main.py
================================================
# backend/src/main.py
"""
Main FastAPI application for Diala Backend
"""

import logging
import sys
import asyncio
from fastapi import FastAPI, Request
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware
from fastapi.openapi.utils import get_openapi

# Load environment variables from .env.local and .env files
from dotenv import load_dotenv
from pathlib import Path

# Get the backend root directory
backend_root = Path(__file__).resolve().parent.parent

# Load .env.local first, then .env (like in the working test)
load_dotenv(backend_root / ".env.local")
load_dotenv(backend_root / ".env")

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

# Import service instances for pre-loading
from .services.realtime_analysis_service import get_realtime_analysis_service
from .services.audio_separation_service import audio_separation_service

# Import routers
from .api.public import (
    youtube_transcripts, hunter_leadgen, audio_transcripts, 
    tiktok_content, youtube_content, instagram_content, 
    twitch_content, voice_onboarding, chatterbox_tts, 
    embedding_models, bulk, voice_models
)

# Create FastAPI app
app = FastAPI(
    title="Diala Backend API",
    description="Diala Voice Agent Backend Services",
    version="1.0.0",
    docs_url="/docs",
    redoc_url="/redoc",
)

# --- THE FIX: Correct CORS Configuration ---
# We explicitly list the origins (ports) that are allowed to talk to this backend.
# Using a specific list instead of "*" is more secure and resolves the
# browser's conflict with `allow_credentials=True`.
origins = [
    "http://localhost:3000",  # Your Next.js frontend
    "http://127.0.0.1:3000",
    # Add any other origins you might use, like a deployed frontend URL
]

app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# --- MODEL LOADING STATE ---
app.state.models_ready = False

async def load_models_background():
    """The actual model loading logic, to be run in the background."""
    logger.info("Background model loading initiated...")
    try:
        realtime_service = await get_realtime_analysis_service()
        await realtime_service.ensure_models_loaded()
        # Audio separation service loads models on-demand, no pre-loading needed
        app.state.models_ready = True
        logger.info("✅ All models have been pre-loaded and the server is ready.")
    except Exception as e:
        logger.error(f"❌ Failed to load models in the background: {e}", exc_info=True)

@app.on_event("startup")
async def startup_event():
    """
    On startup, create a background task to load the models.
    """
    logger.info("Diala Backend API starting up...")
    asyncio.create_task(load_models_background())
    logger.info("Server is running. Model loading continues in the background.")

# Include routers
app.include_router(audio_transcripts.router, prefix="/api/public/audio", tags=["Audio"])
app.include_router(youtube_transcripts.router, prefix="/api/public/youtube", tags=["YouTube"])
app.include_router(hunter_leadgen.router, prefix="/api/public/hunter", tags=["Hunter"])
app.include_router(tiktok_content.router, prefix="/api/public/tiktok", tags=["Social Content"])
app.include_router(youtube_content.router, prefix="/api/public/youtube", tags=["Social Content"])
app.include_router(instagram_content.router, prefix="/api/public/instagram", tags=["Social Content"])
app.include_router(twitch_content.router, prefix="/api/public/twitch", tags=["Social Content"])
app.include_router(voice_onboarding.router, tags=["Voice Onboarding"])
app.include_router(voice_models.router, prefix="/api/public", tags=["Voice Models"])
app.include_router(chatterbox_tts.router, tags=["TTS"])
app.include_router(embedding_models.router, prefix="/api/public", tags=["Embeddings"])
app.include_router(bulk.router, prefix="/api/public/bulk", tags=["Bulk Processing"])

# Health check endpoint now also reports model readiness
@app.get("/health", tags=["System"])
async def health_check(request: Request):
    return {
        "status": "healthy",
        "service": "diala-backend",
        "version": "1.0.0",
        "models_ready": request.app.state.models_ready
    }

@app.get("/", tags=["System"])
async def root():
    return { "message": "Welcome to Diala Backend API", "documentation": "/docs" }



================================================
FILE: backend/src/api/public/hunter_leadgen.py
================================================
"""
Hunter LeadGen API - Streamlined endpoints for lead generation searches.
"""

from fastapi import APIRouter, HTTPException, BackgroundTasks, Query, WebSocket, WebSocketDisconnect
from pydantic import BaseModel, Field
from typing import Optional, List, Dict, Any
import asyncio
import os
import json
import logging
import requests
import time
from datetime import datetime
from pathlib import Path
from dotenv import load_dotenv
from convex import ConvexClient

# Import the new service
from src.core.leadgen.hunter_search_service import HunterSearchService, start_hunter_search_background

# Load environment variables
backend_env_path = os.path.join(os.path.dirname(__file__), "../../../.env")
load_dotenv(backend_env_path)

frontend_env_path = os.path.join(os.path.dirname(__file__), "../../../../frontend/.env.local")
load_dotenv(frontend_env_path)

router = APIRouter()
logger = logging.getLogger(__name__)

# Configure verbose logging
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - [%(funcName)s:%(lineno)d] - %(message)s'
)

# Initialize Convex client
CONVEX_URL = os.getenv("NEXT_PUBLIC_CONVEX_URL", "http://127.0.0.1:3210")
CONVEX_HTTP_URL = os.getenv("CONVEX_HTTP_URL", "http://localhost:3211")
convex_client = ConvexClient(CONVEX_URL)

# API Keys
JINA_API_KEY = os.getenv("JINA_API_KEY")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
GROQ_API_KEY = os.getenv("GROQ_API_KEY")

# Active searches (for tracking and cancellation)
active_searches = {}
# Store asyncio tasks for cancellation
active_tasks = {}

class LeadSearchRequest(BaseModel):
    """Request model for starting a lead generation search."""
    search_id: str = Field(..., description="Unique search identifier for tracking")
    user_id: str = Field(..., description="User ID for rate limiting and ownership")
    search_config: Dict[str, Any] = Field(..., description="Search configuration parameters")
    
    class Config:
        json_schema_extra = {
            "example": {
                "search_id": "search_123456",
                "user_id": "user123",
                "search_config": {
                    "searchName": "Tech Startups in SF",
                    "searchObjective": "Find tech startup leads for partnership",
                    "selectedSources": ["web"],
                    "industry": "Technology",
                    "location": "San Francisco, CA",
                    "companySize": "1-50",
                    "jobTitles": ["CEO", "CTO"],
                    "keywords": "AI, machine learning",
                    "includeEmails": True,
                    "includePhones": True,
                    "includeLinkedIn": False,
                    "validationCriteria": {
                        "mustHaveWebsite": True,
                        "mustHaveContactInfo": True,
                        "mustHaveSpecificKeywords": ["API", "integration", "partner"],
                        "mustBeInIndustry": True,
                        "customValidationRules": "Must offer enterprise solutions"
                    }
                }
            }
        }


class LeadSearchResponse(BaseModel):
    """Response model for search job status."""
    status: str = Field(..., description="Job status", example="processing")
    search_id: str = Field(..., description="Search identifier")
    message: str = Field(..., description="Status message")
    progress: Optional[int] = Field(None, description="Progress percentage (0-100)")


def send_convex_update(search_id: str, progress: int, stage: str, **kwargs):
    """Send progress update to Convex with retry logic."""
    max_retries = 3
    retry_delay = 1.0
    
    for attempt in range(max_retries):
        try:
            url = f"{CONVEX_HTTP_URL}/updateSearchProgress"
            payload = {
                "searchId": search_id,
                "progress": progress,
                "currentStage": stage,
                **kwargs
            }
            
            logger.debug(f"[CONVEX UPDATE {attempt+1}/{max_retries}] Sending to {url}: {stage} ({progress}%)")
            
            response = requests.post(
                url,
                json=payload,
                headers={"Content-Type": "application/json"},
                timeout=5
            )
            
            if response.status_code == 200:
                logger.info(f"[CONVEX UPDATE SUCCESS] {search_id}: {stage} ({progress}%)")
                return True
            else:
                logger.warning(f"[CONVEX UPDATE FAILED] HTTP {response.status_code}: {response.text[:200]}")
                
        except requests.exceptions.ConnectionError as e:
            logger.error(f"[CONVEX CONNECTION ERROR] Attempt {attempt+1}/{max_retries}: {str(e)}")
            logger.debug(f"Convex URL: {CONVEX_HTTP_URL}")
            
            if attempt < max_retries - 1:
                logger.info(f"Retrying in {retry_delay}s...")
                time.sleep(retry_delay)
                retry_delay *= 2  # Exponential backoff
            else:
                logger.error(f"[CONVEX UNREACHABLE] Failed after {max_retries} attempts")
                
        except requests.exceptions.Timeout:
            logger.error(f"[CONVEX TIMEOUT] Request timed out after 5s")
            
        except Exception as e:
            logger.error(f"[CONVEX ERROR] Unexpected error: {str(e)}", exc_info=True)
            break
    
    return False


def send_convex_results(search_id: str, results: Dict[str, Any]):
    """Send final results to Convex."""
    try:
        # Convert leads to frontend format
        leads = []
        for lead in results.get("leads", []):
            formatted_lead = {
                "leadId": f"lead_{search_id}_{len(leads)}",
                "name": lead.get("company_name", "Unknown"),
                "companyName": lead.get("company_name", "Unknown"),
                "websiteUrl": lead.get("url", ""),
                "email": lead.get("contact_info", {}).get("emails", [None])[0],
                "phone": lead.get("contact_info", {}).get("phones", [None])[0],
                "emailVerified": bool(lead.get("contact_info", {}).get("emails")),
                "phoneVerified": bool(lead.get("contact_info", {}).get("phones")),
                "confidence": lead.get("score", 0) / 100,  # Convert percentage to 0-1
                "dataSource": "web",
                "jobTitle": "Contact",
                "industry": results.get("search_config", {}).get("industry", "Unknown"),
                "location": results.get("search_config", {}).get("location", "Unknown"),
            }
            leads.append(formatted_lead)
        
        # Store leads
        convex_client.mutation("hunterMutations:storeLeadResults", {
            "searchId": search_id,
            "leads": leads
        })
        
        # Update search results
        url = f"{CONVEX_HTTP_URL}/updateSearchResults"
        summary = {
            "totalLeads": len(leads),
            "verifiedEmails": len([l for l in leads if l.get("emailVerified")]),
            "verifiedPhones": len([l for l in leads if l.get("phoneVerified")]),
            "businessWebsites": len(leads),
            "avgResponseRate": "N/A",
            "searchTime": f"{int(results.get('stats', {}).get('duration_seconds', 0) / 60)}m"
        }
        
        response = requests.post(
            url,
            json={"searchId": search_id, "results": summary},
            headers={"Content-Type": "application/json"},
            timeout=5
        )
        
        logger.info(f"Stored {len(leads)} leads for search {search_id}")
        
    except Exception as e:
        logger.error(f"Error sending results to Convex: {e}")


def send_convex_status(search_id: str, status: str, error: Optional[str] = None):
    """Update search status in Convex."""
    try:
        url = f"{CONVEX_HTTP_URL}/updateSearchStatus"
        payload = {"searchId": search_id, "status": status}
        if error:
            payload["error"] = error
            
        requests.post(
            url,
            json=payload,
            headers={"Content-Type": "application/json"},
            timeout=5
        )
    except Exception as e:
        logger.error(f"Error updating search status: {e}")


async def process_lead_search(search_id: str, user_id: str, search_config: Dict[str, Any]):
    """Process lead search asynchronously."""
    try:
        logger.info("="*60)
        logger.info(f"[SEARCH START] ID: {search_id}, User: {user_id}")
        logger.info(f"[CONFIG] {json.dumps(search_config, indent=2)}")
        logger.info("="*60)
        
        # Store in active searches
        active_searches[search_id] = {
            "status": "processing",
            "started_at": datetime.now(),
            "user_id": user_id,
            "progress": 0,
            "leads_found": 0,
            "cancelled": False
        }
        
        # Check if search was cancelled
        if search_id in active_searches and active_searches[search_id].get("cancelled"):
            logger.info(f"[SEARCH CANCELLED] {search_id} was cancelled before starting")
            return
            
        # Initialize service
        if not JINA_API_KEY or not GROQ_API_KEY:
            raise ValueError("JINA_API_KEY and GROQ_API_KEY must be configured")
            
        service = HunterSearchService(JINA_API_KEY, OPENAI_API_KEY, GROQ_API_KEY)
        
        # Progress callback
        async def progress_callback(update: Dict[str, Any]):
            # Check if cancelled
            if search_id in active_searches and active_searches[search_id].get("cancelled"):
                logger.info(f"[SEARCH CANCELLED] {search_id} cancelled during progress update")
                raise asyncio.CancelledError("Search cancelled by user")
                
            stage = update.get("stage", "processing")
            progress = update.get("progress", 0)
            message = update.get("message", "")
            leads_found = update.get("leads_found", 0)
            
            logger.info(f"[PROGRESS] Search {search_id}: {message} ({progress}%, {leads_found} leads)")
            
            # Update active search
            if search_id in active_searches:
                active_searches[search_id]["progress"] = progress
                active_searches[search_id]["leads_found"] = leads_found
                active_searches[search_id]["last_update"] = datetime.now()
            
            # Send to Convex
            send_convex_update(
                search_id, 
                progress, 
                message,
                totalLeads=leads_found
            )
        
        # Cancellation check function
        async def cancellation_check():
            return search_id in active_searches and active_searches[search_id].get("cancelled", False)
        
        # Run the search
        results = await service.hunt_leads(
            search_config,
            target_leads=300,
            progress_callback=progress_callback,
            cancellation_check=cancellation_check
        )
        
        # Store search config in results for reference
        results["search_config"] = search_config
        
        # Send results to Convex
        if results.get("cancelled"):
            logger.info(f"[SEARCH CANCELLED] {search_id}: Found {len(results.get('leads', []))} leads before cancellation")
            # Still send partial results if any
            if results.get('leads'):
                send_convex_results(search_id, results)
            send_convex_status(search_id, "cancelled", "Search cancelled by user")
        elif results.get("success"):
            logger.info(f"[SEARCH SUCCESS] {search_id}: {len(results.get('leads', []))} leads found")
            send_convex_results(search_id, results)
            send_convex_status(search_id, "completed")
        else:
            error = results.get("error", "Unknown error")
            logger.error(f"[SEARCH FAILED] {search_id}: {error}")
            send_convex_status(search_id, "failed", error)
        
        # Clean up
        if search_id in active_searches:
            del active_searches[search_id]
        if search_id in active_tasks:
            del active_tasks[search_id]
            
    except asyncio.CancelledError:
        logger.info(f"[SEARCH CANCELLED] {search_id} was cancelled")
        send_convex_status(search_id, "cancelled", "Search cancelled by user")
        
        if search_id in active_searches:
            del active_searches[search_id]
        if search_id in active_tasks:
            del active_tasks[search_id]
            
    except Exception as e:
        logger.error(f"[CRITICAL ERROR] Search {search_id} crashed: {str(e)}", exc_info=True)
        send_convex_status(search_id, "failed", str(e))
        
        if search_id in active_searches:
            del active_searches[search_id]
        if search_id in active_tasks:
            del active_tasks[search_id]


@router.post("/search", response_model=LeadSearchResponse, summary="Start Lead Generation Search")
async def start_lead_search(
    request: LeadSearchRequest,
    background_tasks: BackgroundTasks
):
    """
    Start a new lead generation search.
    
    The search runs asynchronously and updates progress via Convex webhooks.
    """
    logger.info(f"[API REQUEST] Starting lead search {request.search_id} for user {request.user_id}")
    
    # Validate API keys
    if not JINA_API_KEY or not GROQ_API_KEY:
        logger.error("API keys (Jina, Groq) are not configured.")
        raise HTTPException(
            status_code=500,
            detail="Search service not properly configured. Missing API keys."
        )
    
    # Check if search already exists
    if request.search_id in active_searches:
        return LeadSearchResponse(
            status="processing",
            search_id=request.search_id,
            message="Search already in progress",
            progress=active_searches[request.search_id].get("progress", 0)
        )
    
    # Test Convex connectivity first
    logger.info(f"[CONVEX TEST] Testing connection to {CONVEX_HTTP_URL}")
    
    # Create search record in Convex first
    try:
        convex_client.mutation("hunterMutations:createLeadSearch", {
            "searchId": request.search_id,
            "userId": request.user_id,
            "searchConfig": request.search_config
        })
        logger.info(f"[CONVEX] Created search record for {request.search_id}")
    except Exception as e:
        logger.warning(f"[CONVEX] Failed to create search record: {e}")
        # Continue anyway - the update functions will create a placeholder
    
    # Send initial status
    if send_convex_update(request.search_id, 0, "Initializing search..."):
        logger.info("[CONVEX TEST] Connection successful")
    else:
        logger.error("[CONVEX TEST] Connection failed - updates may not reach frontend")
        
    send_convex_status(request.search_id, "processing")
    
    # Initialize task variable
    task = None
    
    # Try new pipeline first, fallback to legacy
    use_new_pipeline = os.getenv("USE_NEW_HUNTER_PIPELINE", "true").lower() == "true"
    
    if use_new_pipeline:
        # Use new optimized pipeline
        try:
            # Prefer AI-generated queries if possible
            pipeline_queries = None
            try:
                svc = HunterSearchService(JINA_API_KEY, OPENAI_API_KEY, GROQ_API_KEY)
                ai_query_objects = asyncio.get_event_loop().run_until_complete(
                    svc.generate_ai_search_queries(request.search_config, max_queries=60)
                )
                pipeline_queries = [q["query"] for q in ai_query_objects] if ai_query_objects else None
                logger.info(f"[PIPELINE] Generated {len(pipeline_queries) if pipeline_queries else 0} AI queries")
            except Exception as e:
                logger.debug(f"[PIPELINE] AI query generation failed: {e}")

            # Convert search config to pipeline format
            pipeline_config = {
                "queries": pipeline_queries or generate_queries_from_config(request.search_config),
                "concurrency": 24,
                "batch_size": 50,
                "flush_interval": 5,
                "dedup_threshold": 86,
                "blocklist_domains": []  # Add any blocked domains
            }
            
            # Start new pipeline in background
            start_hunter_search_background(request.search_id, pipeline_config)
            logger.info(f"[NEW PIPELINE] Started background search {request.search_id}")
            
        except Exception as e:
            logger.error(f"[NEW PIPELINE] Failed to start: {e}, falling back to legacy")
            use_new_pipeline = False
    
    if not use_new_pipeline:
        # Fallback to legacy pipeline
        task = asyncio.create_task(
            process_lead_search(
                request.search_id,
                request.user_id,
                request.search_config
            )
        )
        active_tasks[request.search_id] = task
    
        # Add cleanup callback only for legacy tasks
        def cleanup_task(future):
            if request.search_id in active_tasks:
                del active_tasks[request.search_id]
        
        task.add_done_callback(cleanup_task)
    
    return LeadSearchResponse(
        status="processing",
        search_id=request.search_id,
        message="Lead search started successfully",
        progress=0
    )


@router.get("/search/{search_id}", summary="Get Search Status")
async def get_search_status(search_id: str):
    """Get the current status of a lead generation search."""
    # Check active searches first
    if search_id in active_searches:
        search = active_searches[search_id]
        return {
            "search_id": search_id,
            "status": "processing",
            "progress": search.get("progress", 0),
            "leads_found": search.get("leads_found", 0),
            "started_at": search.get("started_at").isoformat()
        }
    
    # Check Convex for completed/failed searches
    try:
        search_data = convex_client.query("hunterQueries:getLeadSearch", {
            "searchId": search_id
        })
        
        if search_data:
            return {
                "search_id": search_id,
                "status": search_data.get("status", "unknown"),
                "progress": search_data.get("progress", 100),
                "total_leads": search_data.get("totalLeads", 0),
                "error": search_data.get("error")
            }
        else:
            raise HTTPException(status_code=404, detail="Search not found")
            
    except Exception as e:
        logger.error(f"Error getting search status: {e}")
        raise HTTPException(status_code=500, detail="Failed to get search status")


@router.post("/search/{search_id}/cancel", summary="Cancel Lead Search")
async def cancel_lead_search(search_id: str):
    """
    Cancel an active lead generation search.
    
    This will stop all API calls and prevent further credit usage.
    """
    logger.info(f"[CANCEL REQUEST] Received cancellation request for {search_id}")
    
    # Check if search exists
    if search_id not in active_searches and search_id not in active_tasks:
        logger.warning(f"[CANCEL FAILED] Search {search_id} not found")
        raise HTTPException(status_code=404, detail="Search not found")
    
    # Mark as cancelled
    if search_id in active_searches:
        active_searches[search_id]["cancelled"] = True
        active_searches[search_id]["status"] = "cancelling"
        logger.info(f"[CANCEL] Marked {search_id} as cancelled")
    
    # Cancel the asyncio task
    if search_id in active_tasks:
        task = active_tasks[search_id]
        if not task.done():
            task.cancel()
            logger.info(f"[CANCEL] Cancelled task for {search_id}")
        else:
            logger.info(f"[CANCEL] Task for {search_id} already completed")
    
    # Update Convex
    send_convex_status(search_id, "cancelled", "Search cancelled by user")
    
    return {
        "status": "cancelled",
        "search_id": search_id,
        "message": "Search cancellation initiated"
    }


@router.get("/health", summary="Health Check")
async def health_check():
    """Health check endpoint for the Hunter LeadGen service."""
    return {
        "status": "healthy",
        "service": "Hunter LeadGen API (Streamlined)",
        "timestamp": datetime.now().isoformat(),
        "jina_configured": bool(JINA_API_KEY),
        "openai_configured": bool(OPENAI_API_KEY),
        "groq_configured": bool(GROQ_API_KEY),
        "convex_url": CONVEX_URL,
        "convex_http_url": CONVEX_HTTP_URL,
        "active_searches": len(active_searches),
        "active_search_ids": list(active_searches.keys())
    }


@router.get("/stats", summary="Get Service Statistics")
async def get_service_stats():
    """Get current service statistics."""
    # Load recent results if available
    stats = {
        "active_searches": len(active_searches),
        "recent_results": None
    }
    
    try:
        results_file = "data/hunter_results.json"
        if os.path.exists(results_file):
            with open(results_file, 'r') as f:
                recent = json.load(f)
                stats["recent_results"] = {
                    "total_leads": recent.get("total_found", 0),
                    "stats": recent.get("stats", {})
                }
    except Exception as e:
        logger.error(f"Error loading stats: {e}")
    
    return stats


@router.websocket("/ws/{search_id}")
async def websocket_endpoint(websocket: WebSocket, search_id: str):
    """
    WebSocket endpoint for real-time search monitoring and cancellation.
    
    When the WebSocket disconnects (user closes tab/refreshes), the search is automatically cancelled.
    """
    await websocket.accept()
    logger.info(f"[WEBSOCKET] Client connected for search {search_id}")
    
    try:
        # Send initial status
        if search_id in active_searches:
            await websocket.send_json({
                "type": "status",
                "search_id": search_id,
                "status": active_searches[search_id]["status"],
                "progress": active_searches[search_id].get("progress", 0),
                "leads_found": active_searches[search_id].get("leads_found", 0)
            })
        
        # Keep connection alive and monitor
        while True:
            # Wait for any message from client (ping/pong)
            data = await websocket.receive_text()
            
            # Send current status
            if search_id in active_searches:
                await websocket.send_json({
                    "type": "heartbeat",
                    "search_id": search_id,
                    "active": True
                })
            else:
                await websocket.send_json({
                    "type": "heartbeat",
                    "search_id": search_id,
                    "active": False
                })
                break
                
    except WebSocketDisconnect:
        logger.info(f"[WEBSOCKET] Client disconnected for search {search_id}")
        
        # Cancel the search on disconnect
        if search_id in active_searches and not active_searches[search_id].get("cancelled"):
            logger.info(f"[WEBSOCKET] Auto-cancelling search {search_id} due to client disconnect")
            
            # Mark as cancelled
            active_searches[search_id]["cancelled"] = True
            
            # Cancel the task
            if search_id in active_tasks:
                task = active_tasks[search_id]
                if not task.done():
                    task.cancel()
                    
            # Update Convex
            send_convex_status(search_id, "cancelled", "Search cancelled due to connection loss")
            
    except Exception as e:
        logger.error(f"[WEBSOCKET] Error for search {search_id}: {e}")
        await websocket.close()


def generate_queries_from_config(search_config: Dict[str, Any]) -> List[str]:
    """Convert legacy search config to query list for new pipeline."""
    queries = []
    
    # Extract key information
    industry = search_config.get("industry", "")
    location = search_config.get("location", "")
    keywords = search_config.get("keywords", "")
    company_size = search_config.get("companySize", "")
    job_titles = search_config.get("jobTitles", [])
    
    # Generate query variations similar to legacy system
    if industry and location:
        queries.append(f"{industry} companies {location}")
    
    if keywords:
        queries.append(f"{keywords} {location}".strip())
    
    # Business-focused queries
    business_terms = ["companies", "businesses", "firms", "services"]
    for term in business_terms[:2]:  # Use first 2
        if industry:
            query = f"{industry} {term} {location}".strip()
            queries.append(query)
    
    # Contact-focused queries
    if industry:
        queries.append(f"{industry} contact information email phone {location}".strip())
        queries.append(f"{industry} business directory {location}".strip())
    
    return [q for q in queries if q]  # Remove empty queries


@router.post("/ingest_batch", summary="Ingest Lead Batch")
async def ingest_lead_batch(payload: dict):
    """
    Endpoint for new pipeline to incrementally save lead batches.
    """
    search_id = payload.get("search_id")
    leads = payload.get("leads", [])
    
    if not search_id:
        raise HTTPException(status_code=400, detail="search_id required")
    
    logger.info(f"[INGEST BATCH] Received {len(leads)} leads for search {search_id}")
    
    try:
        # Convert leads to Convex format and store
        convex_leads = []
        for lead in leads:
            formatted_lead = {
                "leadId": f"lead_{search_id}_{len(convex_leads)}",
                "name": lead.get("name", lead.get("company", "Unknown")),
                "companyName": lead.get("company", lead.get("name", "Unknown")),
                "websiteUrl": lead.get("url", ""),
                "email": lead.get("email"),
                "phone": lead.get("phone"),
                "emailVerified": lead.get("email_valid", False),
                "phoneVerified": bool(lead.get("phone")),
                "confidence": lead.get("meta", {}).get("score", 50) / 100,  # Convert to 0-1
                "dataSource": "web",
                "jobTitle": lead.get("enrichment", {}).get("title", "Contact"),
                "industry": lead.get("industry", "Unknown"),
                "location": lead.get("location", "Unknown"),
            }
            convex_leads.append(formatted_lead)
        
        # Store in Convex via existing client
        if convex_leads:
            convex_client.mutation("hunterMutations:storeLeadResults", {
                "searchId": search_id,
                "leads": convex_leads
            })
        
        return {"status": "success", "ingested": len(convex_leads)}
        
    except Exception as e:
        logger.error(f"[INGEST BATCH] Error: {e}")
        raise HTTPException(status_code=500, detail=f"Ingestion failed: {str(e)}")


# Add discovery endpoints for new pipeline
@router.post("/discover/groq", summary="Groq Discovery")
async def discover_groq(payload: dict):
    """Discovery endpoint using Groq."""
    # For now, return empty - integrate with existing Groq validation later
    return []

@router.post("/discover/jina", summary="Jina Discovery") 
async def discover_jina(payload: dict):
    """Discovery endpoint using Jina."""
    query = payload.get("q", "")
    if not query:
        return []
    
    try:
        # Use existing Jina client for discovery
        service = HunterSearchService(JINA_API_KEY, OPENAI_API_KEY, GROQ_API_KEY)
        async with service.jina_client as client:
            # Search for the query
            result = await client.search(query, page=1)
            
            # Convert to pipeline format
            candidates = []
            for item in result.get("results", []):
                candidate = {
                    "id": f"jina_{len(candidates)}",
                    "name": item.get("title", "Unknown"),
                    "company": item.get("title", "Unknown"),
                    "url": item.get("url", ""),
                    "description": item.get("description", ""),
                    "match_score": 75,  # Default score
                    "source": "jina"
                }
                candidates.append(candidate)
            
            return candidates[:10]  # Limit to 10 results
            
    except Exception as e:
        logger.error(f"Jina discovery failed: {e}")
        return []

@router.post("/discover/thirdparty", summary="Third Party Discovery")
async def discover_thirdparty(payload: dict):
    """Discovery endpoint for third party sources."""
    # For now, return empty - can add more sources later
    return []



================================================
FILE: backend/src/core/leadgen/API.md
================================================
# Hunter LeadGen API Documentation

## Table of Contents
1. [System Overview](#system-overview)
2. [Architecture](#architecture)
3. [API Endpoints](#api-endpoints)
4. [Processing Phases](#processing-phases)
5. [Data Models](#data-models)
6. [Integration Points](#integration-points)
7. [Error Handling & Recovery](#error-handling--recovery)
8. [Data Retention & Cleanup](#data-retention--cleanup)
9. [Configuration](#configuration)

## System Overview

The Hunter LeadGen API is a sophisticated lead generation system that searches, validates, and enriches business leads through a multi-phase processing pipeline. It integrates with Convex for real-time updates and data persistence, uses Jina Reader for content extraction, and supports user-defined validation criteria.

### Key Features
- **Generic Validation**: User-defined criteria instead of hardcoded rules
- **Multi-source Search**: Web scraping, databases, and directories
- **Contact Enrichment**: Email, phone, and social media extraction
- **Real-time Progress**: WebSocket-style updates via Convex
- **Checkpoint Recovery**: Resume failed searches from last successful phase
- **Tiered Data Retention**: 7-day retention for free tier, unlimited for paid

## Architecture

```
Frontend (Next.js) 
    ↓
Convex Actions (Rate Limiting & Auth)
    ↓
Backend API (FastAPI)
    ↓
LeadGen Pipeline (6 Phases)
    ↓
Convex Database (Results Storage)
```

### Data Flow
1. User submits search criteria via frontend
2. Convex validates rate limits and creates search record
3. Backend API receives request and starts async processing
4. Each phase processes data and saves checkpoints
5. Results are sent back to Convex for permanent storage
6. Frontend polls for updates and displays results

## API Endpoints

### POST `/api/public/hunter/search`
Initiates a new lead generation search.

**Request Body:**
```json
{
  "search_id": "search_123456",
  "user_id": "user123",
  "search_config": {
    "searchName": "Tech Startups in SF",
    "searchObjective": "Find tech startup leads for partnership",
    "selectedSources": ["web", "database"],
    "industry": "Technology",
    "location": "San Francisco, CA",
    "companySize": "1-50",
    "jobTitles": ["CEO", "CTO"],
    "keywords": "AI, machine learning",
    "includeEmails": true,
    "includePhones": true,
    "includeLinkedIn": false,
    "validationCriteria": {
      "mustHaveWebsite": true,
      "mustHaveContactInfo": true,
      "mustHaveSpecificKeywords": ["API", "integration", "partner"],
      "mustBeInIndustry": true,
      "customValidationRules": "Must offer enterprise solutions"
    }
  }
}
```

**Response:**
```json
{
  "status": "processing",
  "search_id": "search_123456",
  "message": "Lead search processing started",
  "progress": 0
}
```

### GET `/api/public/hunter/search/{search_id}`
Gets the current status of a lead generation search.

**Response:**
```json
{
  "search_id": "search_123456",
  "status": "processing",
  "progress": 75,
  "current_stage": "Phase 5: Validating leads against criteria...",
  "total_leads": null,
  "error": null
}
```

### GET `/api/public/hunter/health`
Health check endpoint.

**Response:**
```json
{
  "status": "healthy",
  "service": "Hunter LeadGen API",
  "timestamp": "2024-01-20T10:30:00Z",
  "jina_configured": true,
  "convex_url": "http://127.0.0.1:3210"
}
```

### POST `/api/public/hunter/webhook`
Internal webhook for external service updates.

## Processing Phases

### Phase 1: Search Query Generation
- **Module**: `phase1_search.py`
- **Function**: Generates dynamic search queries based on user criteria
- **Input**: Search configuration with validation criteria
- **Output**: List of search results with URLs and metadata
- **Checkpoint**: `data/checkpoints/{search_id}/phase_1_checkpoint.json`

### Phase 2: Link Extraction
- **Module**: `phase2_extract_links.py`
- **Function**: Extracts and deduplicates URLs from search results
- **Input**: Search results from Phase 1
- **Output**: Structured list of unique URLs with metadata
- **Checkpoint**: Saved in temporary JSON files

### Phase 3: Content Extraction
- **Module**: `phase3_extract_content.py`
- **Function**: Uses Jina Reader API to extract content from URLs
- **Input**: List of URLs from Phase 2
- **Output**: Extracted content with text, metadata, and structure
- **Features**:
  - Batch processing (3 URLs at a time)
  - Rate limiting protection
  - Retry logic for failed extractions

### Phase 4: Data Combination
- **Module**: `phase4_save_content.py`
- **Function**: Combines extracted content with metadata
- **Input**: Content from Phase 3 and links from Phase 2
- **Output**: Combined data structure ready for validation
- **Storage**: `data/combined_data.json`

### Phase 5: Generic Validation
- **Module**: `phase5_validate.py`
- **Function**: Validates leads against user-defined criteria
- **Input**: Combined data and validation criteria
- **Output**: Validated leads with scores and check results
- **Validation Checks**:
  - Website availability
  - Contact information presence
  - Keyword matching
  - Industry relevance
  - Custom rule evaluation
  - AI-powered validation (if DeepSeek API available)

### Phase 6: Report Generation
- **Module**: `phase6_create_final_report.py`
- **Function**: Creates final lead list with contact extraction
- **Input**: Validated data from Phase 5
- **Output**: Final leads with extracted contacts
- **Features**:
  - Email extraction with regex
  - Phone number extraction (multiple formats)
  - Social media profile extraction
  - Metadata enrichment

## Data Models

### LeadSearchRequest
```python
class LeadSearchRequest(BaseModel):
    search_id: str
    user_id: str
    search_config: Dict[str, Any]
```

### SearchConfig Structure
```python
{
    "searchName": str,
    "searchObjective": str,
    "selectedSources": List[str],  # ["web", "database", "directory"]
    "industry": str,
    "location": str,
    "companySize": Optional[str],
    "jobTitles": List[str],
    "keywords": Optional[str],
    "includeEmails": bool,
    "includePhones": bool,
    "includeLinkedIn": bool,
    "validationCriteria": {
        "mustHaveWebsite": bool,
        "mustHaveContactInfo": bool,
        "mustHaveSpecificKeywords": List[str],
        "mustBeInIndustry": bool,
        "customValidationRules": str
    }
}
```

### Lead Result Structure
```python
{
    "leadId": str,
    "name": Optional[str],
    "email": Optional[str],
    "phone": Optional[str],
    "linkedInUrl": Optional[str],
    "websiteUrl": Optional[str],
    "companyName": Optional[str],
    "companySize": Optional[str],
    "industry": Optional[str],
    "location": Optional[str],
    "jobTitle": Optional[str],
    "emailVerified": bool,
    "phoneVerified": bool,
    "confidence": float,  # 0-1
    "dataSource": str
}
```

## Integration Points

### Convex Integration
- **Client**: `ConvexClient` initialized with `NEXT_PUBLIC_CONVEX_URL`
- **Mutations**:
  - `hunterMutations:updateSearchProgress`: Progress updates
  - `hunterMutations:updateSearchStatus`: Status changes
  - `hunterMutations:updateSearchResults`: Final results
  - `hunterMutations:storeLeadResults`: Lead storage
- **Queries**:
  - `hunterQueries:getLeadSearch`: Search status retrieval

### Jina Reader API
- **Endpoint**: `https://r.jina.ai/{url}`
- **Authentication**: Bearer token via `JINA_API_KEY`
- **Headers**:
  - `X-Return-Format: markdown`
  - `X-With-Generated-Alt: true`
- **Rate Limiting**: 3 URLs per batch, 2-second delay between batches

### External Services
- **DeepSeek AI**: Optional AI validation (if API key configured)
- **Query Builder**: Dynamic search query generation

## Error Handling & Recovery

### Checkpoint System
```python
def save_phase_checkpoint(search_id: str, phase: int, data: Dict[str, Any]):
    """Save checkpoint for phase recovery"""
    checkpoint_dir = f"data/checkpoints/{search_id}"
    checkpoint_file = f"phase_{phase}_checkpoint.json"
    # Saves phase data with timestamp

def load_phase_checkpoint(search_id: str, phase: int) -> Optional[Dict[str, Any]]:
    """Load checkpoint if exists"""
    # Returns checkpoint data or None
```

### Error Recovery Flow
1. Phase fails → Exception caught
2. Checkpoint saved (if partial progress)
3. Error logged and sent to Convex
4. Temporary files moved to error directory
5. Search marked as failed with error details
6. On retry: Resume from last checkpoint

### Cleanup on Error
```python
cleanup_temp_files(search_id, keep_on_error=True)
# Moves files to data/errors/{search_id}/ for debugging
```

## Data Retention & Cleanup

### Temporary File Management
```python
def cleanup_temp_files(search_id: str, keep_on_error: bool = False):
    """Clean up temporary JSON files after processing"""
    temp_files = [
        "data/search_results.json",
        "data/extracted_links.json",
        "data/website_contents.json",
        "data/extracted_content.json",
        "data/combined_data.json",
        "data/validated_data.json",
        "data/final_results.json",
        "data/valid_leads_simplified.json"
    ]
    # Removes or moves files based on success/error
```

### Data Retention Policy
- **Free Tier**: 7-day retention (auto-cleanup via Convex cron)
- **Premium/Enterprise**: Unlimited retention
- **Implementation**: `expiresAt` field in Convex schema

### Scheduled Cleanup (Convex)
```typescript
// Daily at 2 AM UTC
cleanupExpiredSearches()
// Removes searches where expiresAt < now

// Daily at midnight UTC
resetDailyUsage()
// Resets searchesToday counter

// Monthly on 1st
resetMonthlyUsage()
// Resets leadsThisMonth counter
```

## Configuration

### Environment Variables
```bash
# Backend (.env)
DEEPSEEK_API_KEY=your_key          # Optional: AI validation
JINA_API_KEY=your_key              # Required: Content extraction
NEXT_PUBLIC_CONVEX_URL=url         # Convex endpoint

# Frontend (.env.local)
NEXT_PUBLIC_CONVEX_URL=url         # Convex endpoint
JINA_API_KEY=your_key              # Jina Reader API
```

### Directory Structure
```
data/
├── checkpoints/           # Phase checkpoints
│   └── {search_id}/
│       └── phase_X_checkpoint.json
├── errors/               # Failed search data
│   └── {search_id}/
│       ├── *.json       # Moved temp files
│       └── checkpoints/ # Moved checkpoints
└── *.json               # Temporary processing files
```

### Rate Limits by Tier
```javascript
const tierLimits = {
  free: { 
    searchesPerDay: 5, 
    leadsPerSearch: 50, 
    totalLeadsPerMonth: 250,
    dataRetentionDays: 7
  },
  premium: { 
    searchesPerDay: 100, 
    leadsPerSearch: 500, 
    totalLeadsPerMonth: 50000,
    dataRetentionDays: -1  // Unlimited
  },
  enterprise: { 
    searchesPerDay: -1,    // Unlimited
    leadsPerSearch: -1, 
    totalLeadsPerMonth: -1,
    dataRetentionDays: -1
  }
};
```

## Best Practices

1. **Always Include Validation Criteria**: Phase 5 requires user-defined criteria
2. **Monitor Checkpoints**: Use for debugging failed searches
3. **Handle Rate Limits**: Implement exponential backoff for external APIs
4. **Clean Up Resources**: Temporary files are auto-cleaned on success
5. **Use Appropriate Batch Sizes**: 3 URLs per Jina batch, 100 leads per Convex batch
6. **Log Extensively**: All phases log progress for debugging
7. **Test Error Scenarios**: Checkpoints enable graceful recovery

## Troubleshooting

### Common Issues

1. **"No validation criteria provided"**
   - Ensure `validationCriteria` is included in search config
   - Check that criteria object has required fields

2. **Jina Reader Timeouts**
   - Reduce batch size
   - Check API key validity
   - Implement retry logic

3. **Convex Connection Errors**
   - Verify `NEXT_PUBLIC_CONVEX_URL`
   - Check network connectivity
   - Ensure Convex dev server is running

4. **Phase Failures**
   - Check `data/errors/{search_id}/` for debug info
   - Review checkpoint files for last successful state
   - Check logs for specific error messages

5. **Missing Results**
   - Verify all phases completed (check progress)
   - Ensure leads passed validation criteria
   - Check if data retention expired (free tier)


================================================
FILE: backend/src/core/leadgen/hunter_search_service.py
================================================
"""
Hunter Search Service - Streamlined lead generation with parallel processing.
"""

import os
import json
import asyncio
import logging
import time
import psutil
from typing import List, Dict, Any, Optional, Callable
from datetime import datetime
from pathlib import Path
import re
import groq

from .jina_client import JinaClient

# Import new pipeline
try:
    from ...services.hunter_pipeline import run_hunter_pipeline
    PIPELINE_AVAILABLE = True
except ImportError as e:
    try:
        # Try alternative import path
        import sys
        import os
        backend_root = os.path.dirname(os.path.dirname(os.path.dirname(__file__)))
        sys.path.insert(0, backend_root)
        from src.services.hunter_pipeline import run_hunter_pipeline
        PIPELINE_AVAILABLE = True
    except ImportError:
        PIPELINE_AVAILABLE = False
        logging.warning(f"New hunter pipeline not available: {e}, falling back to legacy implementation")

logger = logging.getLogger(__name__)

# Configure verbose logging
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - [%(funcName)s:%(lineno)d] - %(message)s'
)


class HunterSearchService:
    """Main service for lead generation with parallel processing."""
    
    def __init__(self, jina_api_key: str, openai_api_key: Optional[str] = None, groq_api_key: Optional[str] = None):
        # Reduce concurrent connections to prevent DNS overload
        self.jina_client = JinaClient(jina_api_key, max_concurrent=5)
        self.openai_api_key = openai_api_key
        
        if not groq_api_key:
            raise ValueError("Groq API key is required for lead validation.")
        self.groq_client = groq.AsyncGroq(api_key=groq_api_key)

        self.results = []
        self.validated_results = []
        self.query_performance = {}  # Track which queries return results
        self.tried_queries = set()  # Avoid duplicate queries
        self.stats = {
            "queries_generated": 0,
            "urls_found": 0,
            "content_extracted": 0,
            "leads_validated": 0,
            "validation_time": 0.0,
            "search_time": 0.0,
            "extraction_time": 0.0,
            "start_time": None,
            "end_time": None,
            "empty_iterations": 0,
            "fallback_queries_used": 0
        }
        logger.info("HunterSearchService initialized with Groq validator")
        self._log_system_info()
    
    def _log_system_info(self):
        """Log system information for debugging."""
        try:
            process = psutil.Process()
            logger.info(f"[SYSTEM] CPU={psutil.cpu_percent()}%, Memory={psutil.virtual_memory().percent}%, "
                       f"Process Memory={process.memory_info().rss / 1024 / 1024:.2f}MB")
        except Exception as e:
            logger.debug(f"Could not get system info: {e}")

    async def generate_ai_search_queries(self, search_config: Dict[str, Any], max_queries: int = 60) -> List[Dict[str, Any]]:
        """
        Use Groq (moonshotai/kimi-k2-instruct) to synthesize a diverse set of high-quality search queries.
        Returns a list of objects: {"type","query","intent","tags"} ordered by predicted usefulness.
        """
        # Sanitize/compact search_config for prompt (avoid huge payloads)
        compact = {
            "industry": search_config.get("industry"),
            "location": search_config.get("location"),
            "keywords": search_config.get("keywords"),
            "companySize": search_config.get("companySize"),
            "jobTitles": search_config.get("jobTitles"),
            "validationCriteria": search_config.get("validationCriteria", {})
        }

        prompt = f"""You are a query synthesis expert for web search. Generate a JSON object with a "queries" field containing an array of query objects.

Each query object must have these exact fields:
- "type": one of ["longtail","boolean","directory_site","site_specific","inurl_title","role_offer","pain_point","social_profile","exclusion"]  
- "query": the search string
- "intent": one of ["contact","company_page","service_page","directory_listing","review","social","press","job_posting"]
- "tags": array of short tags

Generate {max_queries} diverse queries for finding business leads and contact pages.

Rules:
1. Prefer long-tail queries with contact intent (e.g. "roofing contractors Belfast contact email phone")
2. Include site: and inurl: operators for directories (checkatrade.com, yell.com, linkedin.com/company, trustpilot.com)
3. Combine job titles with company descriptors for role_offer queries
4. Include exclusion queries with -job -forum -blog to reduce noise
5. Use boolean operators (AND, OR, quotes) for precise targeting

Search config: {json.dumps(compact)}

Output format:
{{"queries": [
  {{"type": "longtail", "query": "example query", "intent": "contact", "tags": ["tag1", "tag2"]}},
  ...
]}}"""

        try:
            # Check cache first
            cache_dir = Path("data/query_cache")
            cache_dir.mkdir(parents=True, exist_ok=True)
            config_hash = abs(hash(json.dumps(compact, sort_keys=True)))
            cache_file = cache_dir / f"{config_hash}.json"
            
            # Check if cache exists and is recent (24 hours)
            if cache_file.exists():
                cache_age = time.time() - cache_file.stat().st_mtime
                if cache_age < 24 * 3600:  # 24 hours
                    logger.info(f"[AI QUERY] Using cached queries for config hash {config_hash}")
                    with open(cache_file, 'r') as f:
                        return json.load(f)

            # Use Groq client (async)
            logger.info(f"[AI QUERY] Generating {max_queries} queries via Groq for: {compact}")
            resp = await self.groq_client.chat.completions.create(
                messages=[{"role": "user", "content": prompt}],
                model="moonshotai/kimi-k2-instruct",
                temperature=0.0,
                response_format={"type": "json_object"}
            )
            
            raw = resp.choices[0].message.content
            logger.debug(f"[AI QUERY] Groq response: {raw[:200]}...")
            
            # Parse JSON - expect object with queries field
            parsed = json.loads(raw)
            if isinstance(parsed, dict) and 'queries' in parsed:
                parsed = parsed['queries']
            elif isinstance(parsed, list):
                # Direct array response (legacy)
                pass
            else:
                logger.warning(f"[AI QUERY] Unexpected response format: {type(parsed)}")
                raise ValueError("Groq did not return expected format")

            # Basic normalization + scoring heuristic
            scored = []
            for item in parsed:
                if not isinstance(item, dict):
                    continue
                    
                qtext = item.get("query", "").strip()
                if not qtext:
                    continue
                    
                score = 0
                # Score based on query quality indicators
                if "site:" in qtext or "inurl:" in qtext:
                    score += 20
                if any(w in qtext.lower() for w in ["contact", "email", "phone", "quote", "get a quote", "request a quote"]):
                    score += 15
                if any(t in (item.get("tags") or []) for t in ["directory", "review", "linkedin", "facebook", "trustpilot"]):
                    score += 10
                if any(j.lower() in qtext.lower() for j in (search_config.get("jobTitles") or [])):
                    score += 10
                # Prefer longer, more specific queries
                word_count = len(qtext.split())
                if word_count >= 4:
                    score += 5
                elif word_count <= 2:
                    score -= 10
                    
                item["_score"] = score
                scored.append(item)

            # Sort by score descending
            scored.sort(key=lambda x: x.get("_score", 0), reverse=True)
            
            # Dedupe and limit
            seen = set()
            out = []
            for it in scored:
                q = it["query"]
                if q in seen:
                    continue
                seen.add(q)
                out.append(it)
                if len(out) >= max_queries:
                    break

            # Cache the AI queries to disk
            try:
                with open(cache_file, "w") as f:
                    json.dump(out, f, indent=2)
                logger.info(f"[AI QUERY] Cached {len(out)} queries to {cache_file}")
            except Exception as e:
                logger.warning(f"[AI QUERY] Failed to cache queries: {e}")

            logger.info(f"[AI QUERY] Generated {len(out)} AI queries (top score: {out[0].get('_score', 0) if out else 0})")
            return out

        except Exception as e:
            logger.error(f"[AI QUERY] Groq query generation failed: {e}", exc_info=True)
            return []
    
    def generate_search_queries(self, search_config: Dict[str, Any], fallback_level: int = 0) -> List[str]:
        """
        Generate search queries from user configuration.
        
        Args:
            search_config: User's search configuration
            fallback_level: Fallback level for legacy queries
            
        Returns:
            List of search queries
        """
        # Prefer AI-generated queries (Groq) first, fallback to legacy heuristics.
        queries = []
        
        # Try AI query generation first (only on initial call, not fallbacks)
        if fallback_level == 0:
            try:
                ai_queries = asyncio.get_event_loop().run_until_complete(
                    self.generate_ai_search_queries(search_config, max_queries=40)
                )
                if ai_queries:
                    # ai_queries is a list of dicts: {"type","query","intent","tags"}
                    # flatten to strings and keep order
                    ai_list = [q["query"] for q in ai_queries if q.get("query")]
                    # prepend AI queries (they'll be deduped below)
                    queries.extend(ai_list)
                    logger.info(f"[AI QUERY] Added {len(ai_list)} AI-generated queries")
            except Exception as e:
                logger.debug(f"[AI QUERY] Groq query generation failed, using legacy generator: {e}")

        # Continue with legacy query generation (as fallback or supplement)
        legacy_queries = []
        
        # Extract key information
        industry = search_config.get("industry", "")
        location = search_config.get("location", "")
        keywords = search_config.get("keywords", "")
        company_size = search_config.get("companySize", "")
        job_titles = search_config.get("jobTitles", [])
        
        # Base components
        base_terms = []
        
        # Add industry terms
        if industry:
            base_terms.append(industry)
            # Add related terms
            industry_map = {
                "Roofing & Construction": ["roofing", "roof repair", "construction", "contractor"],
                "Technology": ["tech", "software", "IT", "technology"],
                "Healthcare": ["health", "medical", "healthcare", "clinic"],
                "Finance": ["financial", "finance", "investment", "banking"],
                "Retail": ["retail", "shop", "store", "commerce"],
                "Manufacturing": ["manufacturing", "production", "factory", "industrial"]
            }
            base_terms.extend(industry_map.get(industry, []))
        
        # Add keywords
        if keywords:
            base_terms.extend(keywords.split(","))
        
        # Add location
        location_str = f" {location}" if location else ""
        
        # Generate legacy query variations (as supplement/fallback)
        # Query 1: Direct industry + location
        if industry and location:
            legacy_queries.append(f"{industry} companies {location}")
        
        # Query 2: Keywords + location
        if keywords:
            legacy_queries.append(f"{keywords} {location}".strip())
        
        # Query 3: Industry + business terms + location
        business_terms = ["companies", "businesses", "firms", "services", "contractors", "providers"]
        for term in business_terms[:3]:  # Use first 3
            if base_terms:
                query = f"{base_terms[0]} {term} {location}".strip()
                legacy_queries.append(query)
        
        # Query 4: Contact-focused queries
        if base_terms:
            legacy_queries.append(f"{base_terms[0]} contact information email phone {location}".strip())
            legacy_queries.append(f"{base_terms[0]} business directory {location}".strip())
        
        # Query 5: Size-specific queries
        if company_size and base_terms:
            size_map = {
                "1-10": "small business startup",
                "11-50": "small medium business SMB",
                "51-200": "medium business",
                "201-500": "large company",
                "500+": "enterprise corporation"
            }
            size_terms = size_map.get(company_size, "business")
            legacy_queries.append(f"{size_terms} {base_terms[0]} {location}".strip())
        
        # Combine AI queries with legacy queries
        queries.extend(legacy_queries)
        
        # Remove duplicates and empty queries
        queries = list(dict.fromkeys([q for q in queries if q]))
        
        # Apply fallback strategies if previous searches returned no results
        if fallback_level > 0:
            logger.info(f"[FALLBACK] Applying fallback level {fallback_level} query generation")
            fallback_queries = []
            
            if fallback_level == 1:
                # Level 1: Broader industry terms
                if industry and location:
                    fallback_queries.extend([
                        f"{industry} {location}",
                        f"{industry.split()[0]} companies {location}",  # First word only
                        f"construction {location}" if "construction" in industry.lower() else f"{industry} {location}",
                        f"contractors {location}",
                        f"local {industry} {location}"
                    ])
                    
            elif fallback_level == 2:
                # Level 2: Location-focused with general business terms
                if location:
                    fallback_queries.extend([
                        f"businesses {location}",
                        f"companies {location}",
                        f"contractors {location}",
                        f"{location} business directory",
                        f"{location} yellow pages"
                    ])
                    
            elif fallback_level >= 3:
                # Level 3: Very broad searches
                location_parts = location.split(",")
                if location_parts:
                    city = location_parts[0].strip()
                    fallback_queries.extend([
                        city,
                        f"{city} businesses",
                        f"{city} services",
                        "Belfast roofing" if "Belfast" in location else f"{city} contractors"
                    ])
            
            # Add fallback queries to the beginning
            queries = fallback_queries + queries
            self.stats["fallback_queries_used"] += len(fallback_queries)
        
        # Filter out already tried queries
        new_queries = [q for q in queries if q not in self.tried_queries]
        
        # Mark queries as tried
        for q in new_queries:
            self.tried_queries.add(q)
        
        # Limit to reasonable number
        new_queries = new_queries[:10]
        
        self.stats["queries_generated"] += len(new_queries)
        logger.info("="*60)
        logger.info(f"[QUERY GENERATION] Generated {len(new_queries)} new search queries (fallback level: {fallback_level}):")
        for i, query in enumerate(new_queries):
            logger.info(f"  Query {i+1}: {query}")
        logger.info("="*60)
        
        return new_queries
    
    async def validate_lead(self, content_data: Dict[str, Any], validation_criteria: Dict[str, Any]) -> Dict[str, Any]:
        """
        Validate a lead against user criteria using Groq Kimi K2 model.
        """
        if not content_data.get("success"):
            return {
                "url": content_data.get("url"),
                "valid": False,
                "score": 0,
                "reasons": ["Failed to extract content"],
                "matched_criteria": [],
                "contact_info": {}
            }
        
        content = content_data.get("content", "")[:8000]  # Truncate content for the model
        title = content_data.get("title", "")
        url = content_data.get("url", "")

        prompt = f"""
        You are a lead validation expert. Analyze the following website content and determine if it's a valid lead based on the provided criteria.

        **Website URL:** {url}
        **Website Title:** {title}
        **Website Content (first 8000 characters):**
        ---
        {content}
        ---

        **Validation Criteria:**
        - **Industry:** {validation_criteria.get('industry', 'N/A')}
        - **Must have contact info (email/phone)?** {'Yes' if validation_criteria.get('mustHaveContactInfo') else 'No'}
        - **Must strictly match industry?** {'Yes' if validation_criteria.get('mustBeInIndustry') else 'No'}
        - **Required keywords on page:** {validation_criteria.get('mustHaveSpecificKeywords', []) or 'None'}
        - **Custom Rules:** {validation_criteria.get('customValidationRules', 'N/A')}

        **Instructions:**
        Return a single JSON object with no other text. The JSON object must have this exact structure:
        {{
          "valid": boolean,
          "score": number (0-100, where a score >= 40 means valid),
          "reasons": ["string"],
          "matched_criteria": ["string"]
        }}

        **Reasoning Process:**
        1. Evaluate if the website content aligns with the specified **Industry**.
        2. Check for contact information (emails, phone numbers, contact pages).
        3. Confirm if the **Required keywords** are present in the content.
        4. Assess if the **Custom Rules** are met.
        5. Calculate a confidence **score** based on how many criteria are met and the quality of the match. A lead is "valid" if the score is 40 or more.
        6. Populate `reasons` with a brief explanation for the score.
        7. Populate `matched_criteria` with a list of criteria that were successfully met.
        """

        try:
            chat_completion = await self.groq_client.chat.completions.create(
                messages=[{"role": "user", "content": prompt}],
                model="moonshotai/kimi-k2-instruct",
                temperature=0.0,
                response_format={"type": "json_object"},
            )
            response_json_str = chat_completion.choices[0].message.content
            llm_result = json.loads(response_json_str)

            # Combine LLM result with structured data from Jina
            extracted_data = content_data.get("extracted_data", {})
            return {
                "url": url,
                "title": title,
                "valid": llm_result.get("valid", False),
                "score": llm_result.get("score", 0),
                "matched_criteria": llm_result.get("matched_criteria", []),
                "reasons": llm_result.get("reasons", ["LLM response was incomplete."]),
                "contact_info": {
                    "emails": extracted_data.get("emails", []),
                    "phones": extracted_data.get("phones", []),
                    "has_contact_form": extracted_data.get("has_contact_form", False)
                }
            }

        except Exception as e:
            logger.error(f"Groq validation failed for URL {url}: {e}", exc_info=True)
            return {
                "url": url,
                "title": title,
                "valid": False,
                "score": 0,
                "reasons": [f"LLM validation error: {e}"],
                "matched_criteria": [],
                "contact_info": {}
            }
    
    async def process_search_results(self, search_results: List[Dict[str, Any]], 
                                   validation_criteria: Dict[str, Any],
                                   progress_callback: Optional[Callable] = None) -> List[Dict[str, Any]]:
        """
        Process search results: extract content and validate in parallel.
        """
        urls = list(set(r.get("url") for r in search_results if r.get("url")))
        url_to_result = {r.get("url"): r for r in search_results if r.get("url")}
        
        self.stats["urls_found"] += len(urls)
        logger.info(f"[URL PROCESSING] Found {len(urls)} unique URLs to process")
        if not urls:
            return []
        
        if progress_callback:
            await progress_callback({
                "stage": "content_extraction",
                "message": f"Extracting content from {len(urls)} websites...",
                "total": len(urls)
            })
        
        logger.info(f"[CONTENT EXTRACTION] Starting extraction for {len(urls)} URLs")
        extraction_start = time.time()
        content_results = await self.jina_client.read_urls(urls, progress_callback)
        extraction_time = time.time() - extraction_start
        self.stats["extraction_time"] += extraction_time
        
        successful_extractions = len([r for r in content_results if r.get("success")])
        self.stats["content_extracted"] += successful_extractions
        logger.info(f"[CONTENT EXTRACTION] Completed in {extraction_time:.2f}s - Success: {successful_extractions}/{len(urls)}")
        
        if progress_callback:
            await progress_callback({
                "stage": "validation",
                "message": f"Validating {len(content_results)} leads with AI...",
                "total": len(content_results)
            })
        
        logger.info(f"[VALIDATION] Starting parallel validation for {len(content_results)} results")
        validation_start = time.time()
        
        validation_tasks = [self.validate_lead(content, validation_criteria) for content in content_results]
        all_validation_results = await asyncio.gather(*validation_tasks)
        
        validated_leads = []
        for validation_result in all_validation_results:
            if validation_result["valid"]:
                url = validation_result.get("url")
                search_data = url_to_result.get(url, {})
                content_data = next((c for c in content_results if c.get("url") == url), {})

                lead = {
                    "url": url,
                    "title": validation_result.get("title", ""),
                    "company_name": self.extract_company_name(validation_result.get("title", "")),
                    "description": content_data.get("description", search_data.get("description", "")),
                    "score": validation_result["score"],
                    "matched_criteria": validation_result["matched_criteria"],
                    "contact_info": validation_result["contact_info"],
                    "extracted_at": datetime.now().isoformat(),
                    "search_position": search_data.get("position", 0),
                    "search_query": search_data.get("search_query", "")
                }
                validated_leads.append(lead)
        
        self.stats["leads_validated"] += len(validated_leads)
        validated_leads.sort(key=lambda x: x["score"], reverse=True)
        validation_time = time.time() - validation_start
        self.stats["validation_time"] += validation_time
        
        logger.info(f"[VALIDATION] Completed in {validation_time:.2f}s - Valid: {len(validated_leads)}/{len(content_results)}")
        
        if validated_leads:
            logger.info("[TOP LEADS] Top 5 validated leads:")
            for i, lead in enumerate(validated_leads[:5]):
                logger.info(f"  {i+1}. {lead['company_name']} (Score: {lead['score']:.1f}%) - {lead['url']}")
        
        return validated_leads
    
    def extract_company_name(self, title: str) -> str:
        """Extract company name from title."""
        # Remove common suffixes
        name = title
        for suffix in [" - Home", " | Homepage", " - Official", " - Website", " Ltd", " LLC", " Inc"]:
            name = name.replace(suffix, "")
        
        # Take first part before separators
        for sep in ["|", "-", ":", "/"]:
            if sep in name:
                name = name.split(sep)[0]
        
        return name.strip()
    
    async def hunt_leads(self, search_config: Dict[str, Any], 
                        target_leads: int = 30,
                        progress_callback: Optional[Callable] = None,
                        cancellation_check: Optional[Callable] = None) -> Dict[str, Any]:
        """
        Main entry point for lead hunting with parallel processing.
        """
        self.stats["start_time"] = datetime.now()
        all_validated_leads = []
        processed_urls = set()
        
        try:
            async with self.jina_client as client:
                # 1. Generate search queries
                if progress_callback:
                    await progress_callback({
                        "stage": "initialization",
                        "message": "Generating search queries...",
                        "progress": 5
                    })
                
                initial_queries = self.generate_search_queries(search_config)
                
                if not initial_queries:
                    return {
                        "success": False,
                        "error": "No search queries generated",
                        "leads": [],
                        "stats": self.stats
                    }
                
                # Start with initial queries
                available_queries = initial_queries.copy()
                fallback_level = 0
                
                # 2. Search in batches until we have enough leads
                pages_per_query = 3
                batch_size = 5
                total_iterations = 0
                max_iterations = 15  # Increased to allow for fallback queries
                consecutive_empty_iterations = 0
                
                while len(all_validated_leads) < target_leads and total_iterations < max_iterations:
                    total_iterations += 1
                    
                    # Check for cancellation
                    if cancellation_check and await cancellation_check():
                        logger.info("[HUNT CANCELLED] Cancellation requested, stopping search")
                        raise asyncio.CancelledError("Search cancelled by user")
                    
                    # Search progress
                    search_progress = 10 + (total_iterations * 10)
                    if progress_callback:
                        await progress_callback({
                            "stage": "searching",
                            "message": f"Searching... (iteration {total_iterations})",
                            "progress": min(search_progress, 40),
                            "leads_found": len(all_validated_leads)
                        })
                    
                    # Get next batch of queries
                    if not available_queries:
                        # Generate fallback queries if we're out of queries
                        fallback_level += 1
                        logger.info(f"[FALLBACK] No more queries available, generating fallback level {fallback_level}")
                        available_queries = self.generate_search_queries(search_config, fallback_level)
                        
                        if not available_queries:
                            logger.warning("[NO MORE QUERIES] Unable to generate more search queries")
                            break
                    
                    # Take up to batch_size queries
                    query_batch = available_queries[:batch_size]
                    available_queries = available_queries[batch_size:]
                    
                    # Search with batch
                    logger.info(f"[SEARCH BATCH] Iteration {total_iterations}: Searching {len(query_batch)} queries, {pages_per_query} pages each")
                    search_start = time.time()
                    
                    search_results = await client.search_multiple(query_batch, pages_per_query)
                    
                    search_time = time.time() - search_start
                    self.stats["search_time"] += search_time
                    logger.info(f"[SEARCH BATCH] Completed in {search_time:.2f}s - Found {len(search_results)} results")
                    
                    # Filter out already processed URLs
                    new_results = []
                    for result in search_results:
                        # Handle both 'url' and 'link' fields (Jina uses 'url')
                        url = result.get("url") or result.get("link")
                        if url and url not in processed_urls:
                            processed_urls.add(url)
                            result["url"] = url  # Ensure url field exists
                            result["search_query"] = query_batch[0]  # Track which query found it
                            new_results.append(result)
                    
                    if not new_results:
                        consecutive_empty_iterations += 1
                        self.stats["empty_iterations"] += 1
                        logger.warning(f"[ITERATION {total_iterations}] No new results found (empty iterations: {consecutive_empty_iterations})")
                        
                        # If we get 3 consecutive empty iterations, force fallback queries
                        if consecutive_empty_iterations >= 3:
                            logger.info("[FALLBACK TRIGGER] Too many empty iterations, forcing fallback queries")
                            available_queries = []  # Force fallback generation on next iteration
                            consecutive_empty_iterations = 0
                        
                        continue
                    else:
                        consecutive_empty_iterations = 0  # Reset counter
                        logger.info(f"[ITERATION {total_iterations}] Found {len(new_results)} new URLs to process")
                        
                        # Track query performance
                        for query in query_batch:
                            if query not in self.query_performance:
                                self.query_performance[query] = 0
                            self.query_performance[query] += len(new_results)
                    
                    # Check for cancellation before processing
                    if cancellation_check and await cancellation_check():
                        logger.info("[HUNT CANCELLED] Cancellation requested during processing")
                        raise asyncio.CancelledError("Search cancelled by user")
                    
                    # Process and validate results
                    validation_criteria = search_config.get("validationCriteria", {})
                    validation_criteria["industry"] = search_config.get("industry", "")
                    
                    validated_batch = await self.process_search_results(
                        new_results, 
                        validation_criteria,
                        progress_callback
                    )
                    
                    all_validated_leads.extend(validated_batch)
                    
                    logger.info(f"[ITERATION {total_iterations} COMPLETE] New leads: {len(validated_batch)}, Total leads: {len(all_validated_leads)}/{target_leads}")
                    self._log_system_info()
                    
                    # Update progress
                    if progress_callback:
                        await progress_callback({
                            "stage": "processing",
                            "message": f"Found {len(all_validated_leads)} leads so far...",
                            "progress": min(50 + (len(all_validated_leads) / target_leads) * 40, 90),
                            "leads_found": len(all_validated_leads),
                            "target": target_leads
                        })
                
                # 3. Final processing
                self.stats["end_time"] = datetime.now()
                duration = (self.stats["end_time"] - self.stats["start_time"]).total_seconds()
                
                logger.info("="*60)
                logger.info("[HUNT COMPLETE] Final Statistics:")
                logger.info(f"  Total duration: {duration:.2f}s")
                logger.info(f"  Search time: {self.stats['search_time']:.2f}s")
                logger.info(f"  Extraction time: {self.stats['extraction_time']:.2f}s")
                logger.info(f"  Validation time: {self.stats['validation_time']:.2f}s")
                logger.info(f"  Queries generated: {self.stats['queries_generated']}")
                logger.info(f"  Fallback queries used: {self.stats['fallback_queries_used']}")
                logger.info(f"  Empty iterations: {self.stats['empty_iterations']}")
                logger.info(f"  URLs found: {self.stats['urls_found']}")
                logger.info(f"  Content extracted: {self.stats['content_extracted']}")
                logger.info(f"  Leads validated: {len(all_validated_leads)}")
                
                # Log top performing queries
                if self.query_performance:
                    top_queries = sorted(self.query_performance.items(), key=lambda x: x[1], reverse=True)[:5]
                    logger.info("[TOP QUERIES] Best performing search queries:")
                    for query, count in top_queries:
                        logger.info(f"  '{query}': {count} results")
                
                logger.info("="*60)
                
                # Get final stats
                jina_stats = client.get_stats()
                
                # Prepare final results
                final_results = {
                    "success": True,
                    "leads": all_validated_leads[:target_leads],  # Limit to target
                    "total_found": len(all_validated_leads),
                    "stats": {
                        **self.stats,
                        "duration_seconds": duration,
                        "jina_stats": jina_stats
                    }
                }
                
                # Save results
                self.save_results(final_results)
                
                if progress_callback:
                    await progress_callback({
                        "stage": "completed",
                        "message": f"Search completed! Found {len(all_validated_leads)} validated leads.",
                        "progress": 100,
                        "leads_found": len(all_validated_leads)
                    })
                
                return final_results
                
        except asyncio.CancelledError:
            logger.info(f"[HUNT CANCELLED] Search was cancelled after finding {len(all_validated_leads)} leads")
            self.stats["end_time"] = datetime.now()
            
            # Return partial results
            return {
                "success": False,
                "cancelled": True,
                "error": "Search cancelled by user",
                "leads": all_validated_leads,
                "stats": self.stats
            }
            
        except Exception as e:
            logger.error(f"[CRITICAL ERROR] Lead hunting failed: {str(e)}", exc_info=True)
            self.stats["end_time"] = datetime.now()
            
            # Log partial results
            logger.info(f"[PARTIAL RESULTS] Found {len(all_validated_leads)} leads before error")
            
            return {
                "success": False,
                "error": str(e),
                "leads": all_validated_leads,
                "stats": self.stats
            }
    
    def save_results(self, results: Dict[str, Any]):
        """Save results to file for debugging."""
        try:
            Path("data").mkdir(exist_ok=True)
            
            # Save full results
            with open("data/hunter_results.json", "w") as f:
                json.dump(results, f, indent=2)
            
            # Save simplified lead list
            leads = results.get("leads", [])
            simplified = []
            
            for lead in leads:
                simplified.append({
                    "company": lead.get("company_name", "Unknown"),
                    "url": lead.get("url", ""),
                    "score": lead.get("score", 0),
                    "emails": lead.get("contact_info", {}).get("emails", []),
                    "phones": lead.get("contact_info", {}).get("phones", [])
                })
            
            with open("data/hunter_leads_simple.json", "w") as f:
                json.dump(simplified, f, indent=2)
                
            logger.info(f"Saved {len(leads)} leads to data/hunter_results.json")
            
        except Exception as e:
            logger.error(f"Error saving results: {e}")


# New pipeline integration functions
def start_hunter_search_background(search_id: str, config: dict):
    """
    Non-blocking kick: spawn the async pipeline on the event loop.
    Use this from your FastAPI route or job scheduler to return quickly.
    """
    global PIPELINE_AVAILABLE, run_hunter_pipeline
    
    logger.info(f"[BACKGROUND] PIPELINE_AVAILABLE: {PIPELINE_AVAILABLE}")
    
    # Try to import pipeline if not available
    if not PIPELINE_AVAILABLE:
        try:
            from ...services.hunter_pipeline import run_hunter_pipeline
            PIPELINE_AVAILABLE = True
            logger.info("[BACKGROUND] Successfully imported pipeline on demand")
        except ImportError:
            try:
                import sys, os
                backend_root = os.path.dirname(os.path.dirname(os.path.dirname(__file__)))
                sys.path.insert(0, backend_root)
                from src.services.hunter_pipeline import run_hunter_pipeline
                PIPELINE_AVAILABLE = True
                logger.info("[BACKGROUND] Successfully imported pipeline via alternative path")
            except ImportError as e:
                logger.error(f"New pipeline not available even on demand: {e}")
                return
        
    try:
        loop = asyncio.get_event_loop()
    except RuntimeError:
        loop = None
    if loop and loop.is_running():
        # running inside an existing loop (uvicorn): create task
        asyncio.create_task(_runner(search_id, config))
    else:
        # not running in loop (unit tests or CLI), run directly
        asyncio.run(_runner(search_id, config))

async def _runner(search_id: str, config: dict):
    try:
        await run_hunter_pipeline(search_id, config)
    except Exception:
        logging.exception("hunter pipeline failed for %s", search_id)



================================================
FILE: backend/src/core/leadgen/jina_client.py
================================================
"""
Unified Jina AI client for Search and Reader APIs with async support.
"""

import os
import json
import asyncio
import aiohttp
import logging
import time
import psutil
import socket
from typing import List, Dict, Any, Optional, Callable
from datetime import datetime
import urllib.parse
from pathlib import Path
from aiohttp import TCPConnector, ClientTimeout
try:
    from aiohttp.resolver import AsyncResolver
    ASYNC_RESOLVER_AVAILABLE = True
except ImportError:
    ASYNC_RESOLVER_AVAILABLE = False

logger = logging.getLogger(__name__)

# Configure verbose logging
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - [%(funcName)s:%(lineno)d] - %(message)s'
)


class RateLimiter:
    """Token bucket rate limiter for API requests."""
    
    def __init__(self, rate: float = 10.0, burst: int = 20, name: str = "default"):
        self.rate = rate
        self.burst = burst
        self.tokens = burst
        self.last_update = time.monotonic()
        self._lock = asyncio.Lock()
        self.name = name
        self.total_requests = 0
        self.total_wait_time = 0.0
        logger.info(f"RateLimiter '{name}' initialized: rate={rate} req/sec ({rate*60} RPM), burst={burst}")
    
    async def acquire(self, tokens: int = 1) -> float:
        """Acquire tokens, waiting if necessary."""
        async with self._lock:
            now = time.monotonic()
            elapsed = now - self.last_update
            self.tokens = min(self.burst, self.tokens + elapsed * self.rate)
            self.last_update = now
            
            self.total_requests += 1
            logger.debug(f"RateLimiter '{self.name}': tokens available={self.tokens:.2f}, requesting={tokens}")
            
            if self.tokens < tokens:
                wait_time = (tokens - self.tokens) / self.rate
                self.total_wait_time += wait_time
                logger.warning(f"RateLimiter '{self.name}': Rate limit hit! Waiting {wait_time:.2f}s (total wait: {self.total_wait_time:.2f}s)")
                await asyncio.sleep(wait_time)
                self.tokens = tokens
                return wait_time
            
            self.tokens -= tokens
            logger.debug(f"RateLimiter '{self.name}': Tokens consumed, remaining={self.tokens:.2f}")
            return 0.0
    
    def get_stats(self) -> Dict[str, Any]:
        """Get rate limiter statistics."""
        return {
            "name": self.name,
            "total_requests": self.total_requests,
            "total_wait_time": self.total_wait_time,
            "current_tokens": self.tokens,
            "rate": self.rate,
            "burst": self.burst
        }


class JinaClient:
    """Unified client for Jina Search and Reader APIs."""
    
    def __init__(self, api_key: str, max_concurrent: int = 5):
        self.api_key = api_key
        self.search_base_url = "https://s.jina.ai"
        self.reader_base_url = "https://r.jina.ai"
        self.max_concurrent = max_concurrent
        
        # Separate rate limiters for each API
        # Search API: 100 RPM = 1.67 requests/second
        self.search_rate_limiter = RateLimiter(rate=1.67, burst=5, name="search")
        # Reader API: 500 RPM = 8.33 requests/second  
        self.reader_rate_limiter = RateLimiter(rate=8.33, burst=20, name="reader")
        
        self.session: Optional[aiohttp.ClientSession] = None
        self.semaphore = asyncio.Semaphore(max_concurrent)
        
        # Statistics
        self.stats = {
            "search_calls": 0,
            "reader_calls": 0,
            "search_errors": 0,
            "reader_errors": 0,
            "dns_errors": 0,
            "rate_limit_waits": 0,
            "total_results": 0,
            "active_connections": 0,
            "start_time": datetime.now()
        }
        
        logger.info(f"JinaClient initialized: max_concurrent={max_concurrent}")
        self._log_system_info()
    
    def _log_system_info(self):
        """Log system information for debugging."""
        try:
            process = psutil.Process()
            logger.info(f"System info: CPU={psutil.cpu_percent()}%, Memory={psutil.virtual_memory().percent}%, " 
                       f"Process connections={len(process.connections())}, Open files={len(process.open_files())}")
        except Exception as e:
            logger.debug(f"Could not get system info: {e}")
    
    async def __aenter__(self):
        """Async context manager entry."""
        # Create custom connector with connection pooling and DNS caching
        connector_kwargs = {
            "limit": self.max_concurrent,  # Total connection pool limit
            "limit_per_host": self.max_concurrent,  # Per-host limit
            "ttl_dns_cache": 300,  # DNS cache for 5 minutes
            "use_dns_cache": True,
            "force_close": True
        }
        
        # Only use AsyncResolver if available
        if ASYNC_RESOLVER_AVAILABLE:
            try:
                connector_kwargs["resolver"] = AsyncResolver()
                logger.info("Using AsyncResolver for DNS resolution")
            except Exception as e:
                logger.warning(f"AsyncResolver initialization failed: {e}. Using default resolver.")
        else:
            logger.warning("aiodns not installed. Using default resolver. Install with: pip install aiodns")
        
        connector = TCPConnector(**connector_kwargs)
        
        self.session = aiohttp.ClientSession(
            connector=connector,
            timeout=ClientTimeout(total=45, connect=10, sock_read=30)
        )
        
        logger.info("HTTP session created with connection pooling and DNS caching")
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """Async context manager exit."""
        if self.session:
            await self.session.close()
            logger.info("HTTP session closed")
        
        # Log final statistics
        self._log_final_stats()
    
    async def search(self, query: str, page: int = 1) -> Dict[str, Any]:
        """
        Search using Jina Search API.
        
        Args:
            query: Search query
            page: Page number (1-based)
            
        Returns:
            Search results dict
        """
        async with self.semaphore:
            self.stats["active_connections"] += 1
            logger.debug(f"Acquiring semaphore for search (active: {self.stats['active_connections']}/{self.max_concurrent})")
            
            # Rate limiting for search API
            wait_time = await self.search_rate_limiter.acquire()
            if wait_time > 0:
                self.stats["rate_limit_waits"] += 1
            
            self.stats["search_calls"] += 1
            request_start = time.time()
            
            try:
                # Prepare request
                encoded_query = urllib.parse.quote(query)
                url = f"{self.search_base_url}/?q={encoded_query}"
                if page > 1:
                    url += f"&page={page}"
                
                headers = {
                    "Accept": "application/json",
                    "Authorization": f"Bearer {self.api_key}",
                    "X-Engine": "auto"  # Use auto mode for better results
                }
                
                logger.info(f"[SEARCH {self.stats['search_calls']}] Query: '{query}' (page {page})")
                
                # Make request with DNS resolution logging
                try:
                    # Log DNS resolution
                    logger.debug(f"Resolving DNS for {self.search_base_url}")
                    
                    async with self.session.get(url, headers=headers) as response:
                        response_time = time.time() - request_start
                        logger.info(f"[SEARCH RESPONSE] Status={response.status}, Time={response_time:.2f}s")
                        response_text = await response.text()
                    
                    if response.status != 200:
                        logger.error(f"Jina search error: {response.status} - {response_text[:500]}")
                        self.stats["search_errors"] += 1
                        return {"error": f"HTTP {response.status}", "results": []}
                    
                    # Log raw response for debugging
                    logger.debug(f"[RAW RESPONSE] First 500 chars: {response_text[:500]}")
                    
                    # Parse response
                    try:
                        data = json.loads(response_text)
                    except json.JSONDecodeError:
                        logger.error(f"Invalid JSON response: {response_text[:200]}...")
                        self.stats["search_errors"] += 1
                        return {"error": "Invalid JSON", "results": []}
                    
                    # Extract results - Jina API returns {code: 200, status: 20000, data: [...]}
                    if (data.get("code") == 200 or data.get("status") == 20000) and "data" in data:
                        results = data["data"]
                        self.stats["total_results"] += len(results)
                        
                        # Format results
                        formatted_results = []
                        for i, result in enumerate(results):
                            formatted_results.append({
                                "position": i + 1 + (page - 1) * 10,
                                "title": result.get("title", ""),
                                "url": result.get("url", ""),
                                "link": result.get("url", ""),  # Also store as 'link' for compatibility
                                "description": result.get("description", ""),
                                "content": result.get("content", "")  # Sometimes included
                            })
                        
                        logger.info(f"[SEARCH SUCCESS] Found {len(formatted_results)} results for '{query}' (page {page})")
                        
                        # Log sample result for debugging
                        if formatted_results:
                            logger.debug(f"[RESULT SAMPLE] First result: URL={formatted_results[0].get('url')[:80]}, Title={formatted_results[0].get('title')[:50]}")
                        
                        return {"results": formatted_results, "error": None}
                    else:
                        logger.error(f"Unexpected response format. Keys: {list(data.keys())}, code: {data.get('code')}, status: {data.get('status')}")
                        logger.debug(f"Response sample: {json.dumps(data, indent=2)[:500]}...")
                        self.stats["search_errors"] += 1
                        return {"error": "Unexpected format", "results": []}
                        
                except aiohttp.ClientConnectorError as e:
                    self.stats["dns_errors"] += 1
                    logger.error(f"[DNS ERROR] Failed to resolve {self.search_base_url}: {str(e)}")
                    return {"error": f"DNS resolution failed: {str(e)}", "results": []}
                        
            except asyncio.TimeoutError:
                elapsed = time.time() - request_start
                logger.error(f"[TIMEOUT] Search timeout after {elapsed:.2f}s for query: {query}")
                self.stats["search_errors"] += 1
                return {"error": "Timeout", "results": []}
            except Exception as e:
                elapsed = time.time() - request_start
                logger.error(f"[ERROR] Search failed after {elapsed:.2f}s for '{query}': {str(e)}")
                self.stats["search_errors"] += 1
                return {"error": str(e), "results": []}
            finally:
                self.stats["active_connections"] -= 1
                logger.debug(f"Released semaphore (active: {self.stats['active_connections']}/{self.max_concurrent})")
        
        # This should never be reached, but just in case
        logger.error(f"[CRITICAL] search() reached end without returning - returning empty results")
        return {"error": "Unexpected code path", "results": []}
    
    async def read_url(self, url: str) -> Dict[str, Any]:
        """
        Extract content from URL using Jina Reader API.
        
        Args:
            url: URL to extract content from
            
        Returns:
            Extracted content dict
        """
        async with self.semaphore:
            self.stats["active_connections"] += 1
            logger.debug(f"Acquiring semaphore for reader (active: {self.stats['active_connections']}/{self.max_concurrent})")
            
            # Rate limiting for reader API
            wait_time = await self.reader_rate_limiter.acquire()
            if wait_time > 0:
                self.stats["rate_limit_waits"] += 1
            
            self.stats["reader_calls"] += 1
            request_start = time.time()
            
            try:
                # Prepare request
                reader_url = f"{self.reader_base_url}/{url}"
                headers = {
                    "Accept": "application/json",
                    "Authorization": f"Bearer {self.api_key}",
                    "X-Return-Format": "json",
                    "X-With-Content": "true",
                    "X-With-Links": "true"
                }
                
                logger.info(f"[READER {self.stats['reader_calls']}] URL: {url[:100]}...")
                
                # Make request with DNS resolution logging
                logger.debug(f"Resolving DNS for {self.reader_base_url}")
                
                async with self.session.get(reader_url, headers=headers) as response:
                    response_time = time.time() - request_start
                    logger.info(f"[READER RESPONSE] Status={response.status}, Time={response_time:.2f}s")
                    if response.status != 200:
                        error_text = await response.text()
                        logger.error(f"[READER ERROR] HTTP {response.status} for {url}: {error_text[:200]}")
                        self.stats["reader_errors"] += 1
                        return {
                            "url": url,
                            "error": f"HTTP {response.status}",
                            "success": False
                        }
                    
                    # Parse response
                    try:
                        data = await response.json()
                    except:
                        # Sometimes returns plain text
                        content = await response.text()
                        data = {"content": content}
                    
                    # Extract data
                    result = {
                        "url": url,
                        "title": data.get("title", ""),
                        "content": data.get("content", ""),
                        "description": data.get("description", ""),
                        "publishedTime": data.get("publishedTime"),
                        "metadata": data.get("metadata", {}),
                        "success": True,
                        "extracted_at": datetime.now().isoformat()
                    }
                    
                    # Extract contact info if present
                    content_lower = result["content"].lower()
                    
                    # Simple email extraction
                    import re
                    email_pattern = r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b'
                    emails = list(set(re.findall(email_pattern, result["content"])))
                    
                    # Simple phone extraction (basic patterns)
                    phone_patterns = [
                        r'\b\d{3}[-.]?\d{3}[-.]?\d{4}\b',  # US format
                        r'\b\d{4}\s?\d{6,7}\b',  # UK format
                        r'\+\d{1,3}\s?\d{4,14}\b'  # International
                    ]
                    phones = []
                    for pattern in phone_patterns:
                        phones.extend(re.findall(pattern, result["content"]))
                    phones = list(set(phones))
                    
                    result["extracted_data"] = {
                        "emails": emails[:5],  # Limit to 5
                        "phones": phones[:5],
                        "has_contact_form": "contact" in content_lower and "form" in content_lower,
                        "has_email": len(emails) > 0,
                        "has_phone": len(phones) > 0
                    }
                    
                    return result
                    
            except asyncio.TimeoutError:
                elapsed = time.time() - request_start
                logger.error(f"[TIMEOUT] Reader timeout after {elapsed:.2f}s for URL: {url}")
                self.stats["reader_errors"] += 1
                return {"url": url, "error": "Timeout", "success": False}
            except Exception as e:
                elapsed = time.time() - request_start
                logger.error(f"[ERROR] Reader failed after {elapsed:.2f}s for {url}: {str(e)}")
                self.stats["reader_errors"] += 1
                return {"url": url, "error": str(e), "success": False}
            finally:
                self.stats["active_connections"] -= 1
                logger.debug(f"Released semaphore (active: {self.stats['active_connections']}/{self.max_concurrent})")
    
    async def search_multiple(self, queries: List[str], pages_per_query: int = 2) -> List[Dict[str, Any]]:
        """
        Search multiple queries in parallel.
        
        Args:
            queries: List of search queries
            pages_per_query: Number of pages to fetch per query
            
        Returns:
            Combined list of all results
        """
        tasks = []
        for query in queries:
            for page in range(1, pages_per_query + 1):
                tasks.append(self.search(query, page))
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # Combine all results
        all_results = []
        seen_urls = set()
        
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                logger.error(f"Search task {i} failed: {result}")
                continue
            
            if result is None:
                logger.error(f"Search task {i} returned None")
                continue
            
            if result.get("error"):
                logger.debug(f"Search task {i} had error: {result.get('error')}")
                continue
                
            task_results = result.get("results", [])
            logger.debug(f"Search task {i} returned {len(task_results)} results")
            
            for item in task_results:
                url = item.get("url")
                if url and url not in seen_urls:
                    seen_urls.add(url)
                    all_results.append(item)
        
        logger.info(f"[SEARCH MULTIPLE] Combined {len(all_results)} unique results from {len(results)} searches")
        return all_results
    
    async def read_urls(self, urls: List[str], progress_callback: Optional[Callable] = None) -> List[Dict[str, Any]]:
        """
        Read multiple URLs in parallel with progress updates.
        
        Args:
            urls: List of URLs to read
            progress_callback: Optional callback for progress updates
            
        Returns:
            List of extracted content
        """
        total = len(urls)
        completed = 0
        results = []
        
        # Process in smaller batches to avoid overwhelming the API
        # Reduce batch size to prevent DNS overload
        batch_size = min(3, self.max_concurrent)  # Max 3 concurrent reads
        
        logger.info(f"[BATCH READER] Processing {total} URLs in batches of {batch_size}")
        self._log_system_info()
        
        for i in range(0, total, batch_size):
            batch = urls[i:i + batch_size]
            batch_num = i // batch_size + 1
            logger.info(f"[BATCH {batch_num}] Processing URLs {i+1}-{min(i+batch_size, total)} of {total}")
            
            tasks = [self.read_url(url) for url in batch]
            
            batch_start = time.time()
            batch_results = await asyncio.gather(*tasks, return_exceptions=True)
            batch_time = time.time() - batch_start
            
            logger.info(f"[BATCH {batch_num}] Completed in {batch_time:.2f}s")
            
            for result in batch_results:
                if isinstance(result, Exception):
                    logger.error(f"Read task failed: {result}")
                    results.append({"error": str(result), "success": False})
                elif result is None:
                    logger.error(f"Read task returned None")
                    results.append({"error": "Result was None", "success": False})
                else:
                    results.append(result)
                
                completed += 1
                
                if progress_callback:
                    await progress_callback({
                        "stage": "content_extraction",
                        "completed": completed,
                        "total": total,
                        "percentage": int((completed / total) * 100)
                    })
        
        return results
    
    def get_stats(self) -> Dict[str, Any]:
        """Get client statistics."""
        stats = self.stats.copy()
        
        # Calculate success rates
        total_search = stats["search_calls"]
        if total_search > 0:
            stats["search_success_rate"] = 1 - (stats["search_errors"] / total_search)
        else:
            stats["search_success_rate"] = 0
            
        total_reader = stats["reader_calls"]
        if total_reader > 0:
            stats["reader_success_rate"] = 1 - (stats["reader_errors"] / total_reader)
        else:
            stats["reader_success_rate"] = 0
        
        return stats
    
    def _log_final_stats(self):
        """Log final statistics on exit."""
        runtime = (datetime.now() - self.stats["start_time"]).total_seconds()
        
        logger.info("="*60)
        logger.info("JinaClient Final Statistics:")
        logger.info(f"  Runtime: {runtime:.2f}s")
        logger.info(f"  Search API calls: {self.stats['search_calls']} (errors: {self.stats['search_errors']})")
        logger.info(f"  Reader API calls: {self.stats['reader_calls']} (errors: {self.stats['reader_errors']})")
        logger.info(f"  DNS errors: {self.stats['dns_errors']}")
        logger.info(f"  Total results: {self.stats['total_results']}")
        logger.info(f"  Rate limit waits: {self.stats['rate_limit_waits']}")
        
        # Log rate limiter stats
        search_stats = self.search_rate_limiter.get_stats()
        reader_stats = self.reader_rate_limiter.get_stats()
        logger.info(f"  Search rate limiter: {search_stats['total_requests']} requests, {search_stats['total_wait_time']:.2f}s wait time")
        logger.info(f"  Reader rate limiter: {reader_stats['total_requests']} requests, {reader_stats['total_wait_time']:.2f}s wait time")
        logger.info("="*60)


================================================
FILE: backend/src/core/leadgen/PRODUCTION_IMPROVEMENTS.md
================================================
# Production Improvements for Hunter Search

## Overview
This document describes the production-ready improvements made to the hunter search system to handle concurrent users, rate limiting, and provide accurate progress reporting.

## Key Improvements

### 1. Rate Limiting
- **Token Bucket Algorithm**: Implements a sliding window rate limiter
- **Distributed Rate Limiting**: Uses Redis when available for multi-instance deployments
- **Per-User Limits**: Can limit by user ID, IP address, or globally
- **Configurable**: 10 requests per 60-second window (adjustable)

```python
# Check rate limit before making API calls
if not wait_for_rate_limit(user_id, max_wait=10):
    return {"error": "Rate limit exceeded"}
```

### 2. Concurrent Request Management
- **Semaphore Control**: Limits to 3 concurrent Jina API requests
- **Request Queuing**: Automatically queues requests when limit is reached
- **Thread-Safe**: All operations are thread-safe for concurrent users

### 3. Retry Logic with Exponential Backoff
- **Automatic Retries**: 3 retries with exponential backoff (1.5x factor)
- **Smart Handling**: Different strategies for 429 (rate limit) vs connection errors
- **Circuit Breaker**: Prevents cascading failures

### 4. Enhanced Progress Reporting
Progress is now calculated accurately across:
- Multiple queries per search
- Multiple pages per query
- Query formatting time
- Actual results found

Example progress callback data:
```json
{
    "message": "Query 3/5, page 2",
    "progress": 45,
    "stats": {
        "api_calls": 12,
        "cache_hits": 3,
        "cache_misses": 2,
        "total_results": 67,
        "cache_hit_rate": 0.6,
        "error_rate": 0.0
    }
}
```

### 5. Performance Metrics
Real-time tracking of:
- API calls made
- Cache hit/miss ratio
- Format and search errors
- Total results found
- Error rates

### 6. Debug Enhancements
- **Query Formatting**: Saved in debug logs with timestamps
- **Performance Data**: Metrics included in all debug outputs
- **Request/Response**: Full API interactions logged in DEBUG mode

## Configuration

### Environment Variables
```bash
# Required
JINA_API_KEY=your_jina_key
DEEPSEEK_API_KEY=your_deepseek_key  # or OPENAI_API_KEY

# Optional
REDIS_URL=redis://localhost:6379
DEBUG_SEARCH=true
```

### Rate Limit Configuration
```python
# In phase1_search.py
RATE_LIMIT_REQUESTS = 10  # requests per window
RATE_LIMIT_WINDOW = 60    # seconds
MAX_CONCURRENT_REQUESTS = 3
```

## Usage Example

```python
from src.core.leadgen import phase1_search

# Define progress callback
def my_progress_callback(update):
    print(f"Progress: {update['progress']}% - {update['message']}")
    print(f"Stats: {update['stats']}")

# Run search with progress tracking
results = phase1_search.run(
    custom_queries=["roofing contractors Belfast"],
    user_id="user_123",  # For per-user rate limiting
    progress_callback=my_progress_callback
)
```

## Performance Characteristics

### Without Query Formatting
- Single query: ~10 results
- Limited relevance
- Fast but incomplete

### With Query Formatting
- 3-5 queries generated per search
- 30-50 results typical
- Much better relevance
- Slightly slower but comprehensive

### Concurrent Performance
- Handles 10+ concurrent users
- Redis enables horizontal scaling
- Graceful degradation without Redis

## Monitoring

The system provides several monitoring points:

1. **Logs**: Structured logging with search context
2. **Metrics**: Real-time performance statistics
3. **Debug Files**: Detailed request/response data
4. **Progress Callbacks**: Live updates for UI

## Error Handling

### Rate Limit Exceeded
- Waits up to 10 seconds for rate limit window
- Returns empty results if timeout
- Logs incident with user ID

### API Errors
- Automatic retry with backoff
- Falls back to cached results when possible
- Clear error messages in logs

### Network Issues
- Connection pooling for efficiency
- Timeout handling (30s default)
- Graceful degradation

## Best Practices

1. **Always provide user_id** for better rate limiting
2. **Implement progress callbacks** for UI updates
3. **Monitor cache hit rates** - should be >50% in production
4. **Use Redis** for multi-instance deployments
5. **Set appropriate timeouts** based on your needs

## Testing

```bash
# Test query formatting
python test_query_formatting.py

# Test improved search with metrics
python test_improved_search.py

# Load test with concurrent requests
python test_concurrent_search.py
```


================================================
FILE: backend/src/tasks/hunter.py
================================================
from celery import shared_task

@shared_task
def stub(*args, **kwargs):
    """TODO: implement real logic."""
    return "stub"



================================================
FILE: frontend/convex/hunterActions.ts
================================================
import { action } from "./_generated/server";
import { v } from "convex/values";
import { api, internal } from "./_generated/api";
import { checkRateLimit } from "./rateLimitHelpers";

// Lead search configuration interface
interface LeadSearchConfig {
  searchName: string;
  searchObjective: string;
  selectedSources: string[];
  industry: string;
  location: string;
  companySize?: string;
  jobTitles: string[];
  keywords?: string;
  includeEmails: boolean;
  includePhones: boolean;
  includeLinkedIn: boolean;
  validationCriteria?: {
    mustHaveWebsite: boolean;
    mustHaveContactInfo: boolean;
    mustHaveSpecificKeywords: string[];
    mustBeInIndustry: boolean;
    customValidationRules: string;
  };
}

// Create a new lead search
export const createLeadSearch = action({
  args: {
    userId: v.string(),
    searchConfig: v.object({
      searchName: v.string(),
      searchObjective: v.string(),
      selectedSources: v.array(v.string()),
      industry: v.string(),
      location: v.string(),
      companySize: v.optional(v.string()),
      jobTitles: v.array(v.string()),
      keywords: v.optional(v.string()),
      includeEmails: v.boolean(),
      includePhones: v.boolean(),
      includeLinkedIn: v.boolean(),
      validationCriteria: v.optional(v.object({
        mustHaveWebsite: v.boolean(),
        mustHaveContactInfo: v.boolean(),
        mustHaveSpecificKeywords: v.array(v.string()),
        mustBeInIndustry: v.boolean(),
        customValidationRules: v.string(),
      })),
    }),
  },
  handler: async (ctx, { userId, searchConfig }) => {
    // Get user subscription and check limits
    let subscription = await ctx.runMutation(internal.rateLimitHelpers.getUserSubscription, { userId });
    if (!subscription) {
      // Create a default free subscription for testing
      console.log("No subscription found, creating default free subscription for user:", userId);
      subscription = await ctx.runMutation(internal.rateLimitHelpers.getUserSubscription, { userId });
      if (!subscription) {
        throw new Error("Failed to create user subscription");
      }
    }

    // NEW: Reset usage counters before checking limits
    await ctx.runMutation(internal.rateLimitHelpers.resetUsageCountersIfNeeded, { userId });

    // Check rate limits
    const rateLimitCheck = await checkRateLimit(ctx, userId, "leadSearch", subscription.tier as any);
    if (!rateLimitCheck.allowed) {
      throw new Error(rateLimitCheck.error);
    }

    // Check subscription limits (this is now a safe read-only query)
    const limitsCheck = await ctx.runQuery(internal.rateLimitHelpers.checkSubscriptionLimits, {
      userId,
      feature: "search",
      additionalLeads: subscription.leadsPerSearch,
    });

    if (!limitsCheck.allowed) {
      throw new Error(limitsCheck.error);
    }

    // Check if premium features are being used
    const premiumSources = ["database", "directory"];
    const usingPremiumSources = searchConfig.selectedSources.some(source => 
      premiumSources.includes(source)
    );

    if (usingPremiumSources && subscription.tier === "free") {
      throw new Error("Premium data sources require a paid subscription");
    }

    if (searchConfig.includeLinkedIn && subscription.tier === "free") {
      throw new Error("LinkedIn data requires a premium subscription");
    }

    // Generate unique search ID
    const searchId = `search_${Date.now()}_${Math.random().toString(36).substring(2)}`;

    // Create search record
    await ctx.runMutation(internal.hunterMutations.createLeadSearch, {
      searchId,
      userId,
      searchConfig,
    });

    // Increment usage for this search
    await ctx.runMutation(internal.rateLimitHelpers.incrementUsage, {
      userId,
      feature: "search",
    });

    // Start the search process
    try {
      await initiateBackendSearch(ctx, searchId, searchConfig, userId);
    } catch (error: any) {
      // Update search status to failed
      await ctx.runMutation(internal.hunterMutations.updateSearchStatus, {
        searchId,
        status: "failed",
        error: error.message || "Failed to initiate search",
      });
      throw error;
    }

    return {
      searchId,
      status: "initializing",
      message: "Search initiated successfully",
    };
  },
});

// Initiate backend search using Jina Reader integration
async function initiateBackendSearch(
  ctx: any,
  searchId: string,
  searchConfig: LeadSearchConfig,
  userId: string
) {
  // Update status to initializing
  await ctx.runMutation(internal.hunterMutations.updateSearchProgress, {
    searchId,
    progress: 10,
    currentStage: "Initializing search...",
  });

  // Prepare search payload for backend (matching LeadSearchRequest model)
  const searchPayload = {
    search_id: searchId,
    user_id: userId,
    search_config: {
      searchName: searchConfig.searchName,
      searchObjective: searchConfig.searchObjective,
      selectedSources: searchConfig.selectedSources,
      industry: searchConfig.industry,
      location: searchConfig.location,
      companySize: searchConfig.companySize,
      jobTitles: searchConfig.jobTitles,
      keywords: searchConfig.keywords,
      includeEmails: searchConfig.includeEmails,
      includePhones: searchConfig.includePhones,
      includeLinkedIn: searchConfig.includeLinkedIn,
      validationCriteria: searchConfig.validationCriteria,
    },
  };

  // Call backend LeadGen service
  const backendUrl = process.env.BACKEND_URL || "http://localhost:8001";
  
  let result;
  try {
    const response = await fetch(`${backendUrl}/api/public/hunter/search`, {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        "Authorization": `Bearer ${process.env.API_KEY}`,
      },
      body: JSON.stringify(searchPayload),
    });

    if (!response.ok) {
      const errorText = await response.text();
      throw new Error(`Backend search failed: ${errorText}`);
    }

    result = await response.json();
  } catch (error) {
    // Re-throw the error to be handled by the caller
    throw error;
  }
  
  // Update search status
  await ctx.runMutation(internal.hunterMutations.updateSearchProgress, {
    searchId,
    progress: 20,
    currentStage: "Search submitted to processing pipeline",
  });

  return result;
}

// Get search status and progress
export const getSearchStatus = action({
  args: { searchId: v.string() },
  handler: async (ctx, { searchId }) => {
    const search = await ctx.runQuery(internal.hunterQueries.getLeadSearch, { searchId });
    
    if (!search) {
      throw new Error("Search not found");
    }

    // If search is completed, get results summary
    if (search.status === "completed") {
      const resultsCount = await ctx.runQuery(internal.hunterQueries.getSearchResultsCount, { searchId });
      
      return {
        ...search,
        resultsCount,
      };
    }

    return search;
  },
});

// Get search results with pagination
export const getSearchResults = action({
  args: {
    searchId: v.string(),
    limit: v.optional(v.number()),
    offset: v.optional(v.number()),
    filters: v.optional(v.object({
      emailVerified: v.optional(v.boolean()),
      phoneVerified: v.optional(v.boolean()),
      minConfidence: v.optional(v.number()),
      dataSources: v.optional(v.array(v.string())),
    })),
  },
  handler: async (ctx, { searchId, limit = 50, offset = 0, filters }) => {
    // Verify user has access to this search
    const search = await ctx.runQuery(internal.hunterQueries.getLeadSearch, { searchId });
    if (!search) {
      throw new Error("Search not found");
    }

    const results = await ctx.runQuery(internal.hunterQueries.getSearchResults, {
      searchId,
      limit,
      offset,
      filters,
    });

    return {
      results,
      total: search.totalLeads || 0,
      hasMore: offset + limit < (search.totalLeads || 0),
    };
  },
});

// Export search results
export const exportSearchResults = action({
  args: {
    userId: v.string(),
    searchId: v.string(),
    format: v.union(v.literal("csv"), v.literal("json"), v.literal("xlsx")),
    fields: v.array(v.string()),
    filters: v.optional(v.object({
      emailVerified: v.optional(v.boolean()),
      phoneVerified: v.optional(v.boolean()),
      minConfidence: v.optional(v.number()),
      dataSources: v.optional(v.array(v.string())),
    })),
  },
  handler: async (ctx, { userId, searchId, format, fields, filters }) => {
    // Check if user has export permissions
    const subscription = await ctx.runQuery(internal.hunterQueries.getUserSubscription, { userId });
    if (!subscription) {
      throw new Error("User subscription not found");
    }

    if (subscription.tier === "free") {
      throw new Error("Export feature requires a premium subscription");
    }

    // Check rate limits for exports
    const rateLimitCheck = await checkRateLimit(ctx, userId, "leadExport", subscription.tier as any);
    if (!rateLimitCheck.allowed) {
      throw new Error(rateLimitCheck.error);
    }

    // Verify user owns this search
    const search = await ctx.runQuery(internal.hunterQueries.getLeadSearch, { searchId });
    if (!search || search.userId !== userId) {
      throw new Error("Search not found or access denied");
    }

    // Generate export ID
    const exportId = `export_${Date.now()}_${Math.random().toString(36).substring(2)}`;

    // Create export job
    await ctx.runMutation(internal.hunterMutations.createExportJob, {
      exportId,
      userId,
      searchId,
      format,
      fields,
      filters,
    });

    // Trigger export processing
    await processExportJob(ctx, exportId);

    return {
      exportId,
      status: "processing",
      message: "Export job created successfully",
    };
  },
});

// Process export job
async function processExportJob(ctx: any, exportId: string) {
  // This would typically call a backend service to generate the export file
  // For now, we'll simulate the process
  
  const backendUrl = process.env.BACKEND_URL || "http://localhost:8001";
  
  try {
    const response = await fetch(`${backendUrl}/api/hunter/export`, {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        "Authorization": `Bearer ${process.env.API_KEY}`,
      },
      body: JSON.stringify({ export_id: exportId }),
    });

    if (!response.ok) {
      await ctx.runMutation(internal.hunterMutations.updateExportStatus, {
        exportId,
        status: "failed",
        error: "Export processing failed",
      });
      throw new Error("Export processing failed");
    }

    const result = await response.json();
    return result;
  } catch (error: any) {
    // Ensure export status is updated even if there's an error
    await ctx.runMutation(internal.hunterMutations.updateExportStatus, {
      exportId,
      status: "failed",
      error: error.message || "Export processing failed",
    });
    throw error;
  }
}

// Get user's search history
export const getSearchHistory = action({
  args: {
    userId: v.string(),
    limit: v.optional(v.number()),
    offset: v.optional(v.number()),
  },
  handler: async (ctx, { userId, limit = 20, offset = 0 }) => {
    const searches = await ctx.runQuery(internal.hunterQueries.getUserSearchHistory, {
      userId,
      limit,
      offset,
    });

    return searches;
  },
});

// Delete a search and its results
export const deleteSearch = action({
  args: {
    userId: v.string(),
    searchId: v.string(),
  },
  handler: async (ctx, { userId, searchId }) => {
    // Verify ownership
    const search = await ctx.runQuery(internal.hunterQueries.getLeadSearch, { searchId });
    if (!search || search.userId !== userId) {
      throw new Error("Search not found or access denied");
    }

    // Delete search and all related data
    await ctx.runMutation(internal.hunterMutations.deleteSearch, { searchId });

    return { success: true, message: "Search deleted successfully" };
  },
});

// Webhook endpoint for backend to update search progress
export const updateSearchProgress = action({
  args: {
    searchId: v.string(),
    progress: v.number(),
    currentStage: v.optional(v.string()),
    status: v.optional(v.union(
      v.literal("processing"),
      v.literal("completed"),
      v.literal("failed")
    )),
    results: v.optional(v.object({
      totalLeads: v.number(),
      verifiedEmails: v.number(),
      verifiedPhones: v.number(),
      businessWebsites: v.number(),
      avgResponseRate: v.string(),
      searchTime: v.string(),
    })),
    error: v.optional(v.string()),
  },
  handler: async (ctx, args) => {
    // Verify API key (in production, you'd validate the webhook signature)
    const apiKey = process.env.API_KEY;
    if (!apiKey) {
      throw new Error("API key not configured");
    }

    // Update search progress
    await ctx.runMutation(internal.hunterMutations.updateSearchProgress, {
      searchId: args.searchId,
      progress: args.progress,
      currentStage: args.currentStage,
    });

    // If status is provided, update it
    if (args.status) {
      await ctx.runMutation(internal.hunterMutations.updateSearchStatus, {
        searchId: args.searchId,
        status: args.status,
        error: args.error,
      });
    }

    // If results are provided, update them
    if (args.results) {
      await ctx.runMutation(internal.hunterMutations.updateSearchResults, {
        searchId: args.searchId,
        results: args.results,
      });

      // Update user's monthly lead count
      if (args.results.totalLeads > 0) {
        const search = await ctx.runQuery(internal.hunterQueries.getLeadSearch, { 
          searchId: args.searchId 
        });
        
        if (search) {
          await ctx.runMutation(internal.rateLimitHelpers.incrementUsage, {
            userId: search.userId,
            feature: "search",
            leadsCount: args.results.totalLeads,
          });
        }
      }
    }

    return { success: true };
  },
});

// Store lead results from backend
export const storeLeadResults = action({
  args: {
    searchId: v.string(),
    leads: v.array(v.object({
      leadId: v.string(),
      name: v.optional(v.string()),
      email: v.optional(v.string()),
      phone: v.optional(v.string()),
      linkedInUrl: v.optional(v.string()),
      websiteUrl: v.optional(v.string()),
      companyName: v.optional(v.string()),
      companySize: v.optional(v.string()),
      industry: v.optional(v.string()),
      location: v.optional(v.string()),
      jobTitle: v.optional(v.string()),
      department: v.optional(v.string()),
      seniority: v.optional(v.string()),
      emailVerified: v.boolean(),
      phoneVerified: v.boolean(),
      confidence: v.number(),
      dataSource: v.string(),
    })),
  },
  handler: async (ctx, { searchId, leads }) => {
    // Store lead results in batches
    const batchSize = 100;
    for (let i = 0; i < leads.length; i += batchSize) {
      const batch = leads.slice(i, i + batchSize);
      await ctx.runMutation(internal.hunterMutations.storeLeadResults, {
        searchId,
        leads: batch,
      });
    }

    return { 
      success: true, 
      message: `Stored ${leads.length} leads for search ${searchId}` 
    };
  },
});



================================================
FILE: frontend/convex/hunterHttpEndpoints.ts
================================================
import { httpAction } from "./_generated/server";
import { api, internal } from "./_generated/api";

// HTTP endpoint for updating search progress
export const updateSearchProgress = httpAction(async (ctx, request) => {
  const data = await request.json();
  
  try {
    await ctx.runMutation(internal.hunterMutations.updateSearchProgress, {
      searchId: data.searchId,
      progress: data.progress,
      currentStage: data.currentStage,
    });
    
    return new Response(JSON.stringify({ success: true }), {
      status: 200,
      headers: { "Content-Type": "application/json" },
    });
  } catch (error) {
    console.error("Error updating search progress:", error);
    return new Response(JSON.stringify({ error: error.message }), {
      status: 500,
      headers: { "Content-Type": "application/json" },
    });
  }
});

// HTTP endpoint for updating search status
export const updateSearchStatus = httpAction(async (ctx, request) => {
  const data = await request.json();
  
  try {
    await ctx.runMutation(internal.hunterMutations.updateSearchStatus, {
      searchId: data.searchId,
      status: data.status,
      error: data.error,
    });
    
    return new Response(JSON.stringify({ success: true }), {
      status: 200,
      headers: { "Content-Type": "application/json" },
    });
  } catch (error) {
    console.error("Error updating search status:", error);
    return new Response(JSON.stringify({ error: error.message }), {
      status: 500,
      headers: { "Content-Type": "application/json" },
    });
  }
});

// HTTP endpoint for updating search results
export const updateSearchResults = httpAction(async (ctx, request) => {
  const data = await request.json();
  
  try {
    await ctx.runMutation(internal.hunterMutations.updateSearchResults, {
      searchId: data.searchId,
      results: data.results,
    });
    
    return new Response(JSON.stringify({ success: true }), {
      status: 200,
      headers: { "Content-Type": "application/json" },
    });
  } catch (error) {
    console.error("Error updating search results:", error);
    return new Response(JSON.stringify({ error: error.message }), {
      status: 500,
      headers: { "Content-Type": "application/json" },
    });
  }
});


================================================
FILE: frontend/convex/hunterMutations.ts
================================================
import { internalMutation } from "./_generated/server";
import { v } from "convex/values";

// Create a new lead search
export const createLeadSearch = internalMutation({
  args: {
    searchId: v.string(),
    userId: v.string(),
    searchConfig: v.object({
      searchName: v.string(),
      searchObjective: v.string(),
      selectedSources: v.array(v.string()),
      industry: v.string(),
      location: v.string(),
      companySize: v.optional(v.string()),
      jobTitles: v.array(v.string()),
      keywords: v.optional(v.string()),
      includeEmails: v.boolean(),
      includePhones: v.boolean(),
      includeLinkedIn: v.boolean(),
      validationCriteria: v.optional(v.object({
        mustHaveWebsite: v.boolean(),
        mustHaveContactInfo: v.boolean(),
        mustHaveSpecificKeywords: v.array(v.string()),
        mustBeInIndustry: v.boolean(),
        customValidationRules: v.string(),
      })),
    }),
  },
  handler: async (ctx, { searchId, userId, searchConfig }) => {
    const now = new Date().toISOString();
    
    // Get user subscription to determine tier
    const subscription = await ctx.db
      .query("userSubscriptions")
      .withIndex("by_user", (q) => q.eq("userId", userId))
      .first();
    
    const userTier = subscription?.tier || "free";
    
    // Calculate expiry date for free tier (7 days)
    let expiresAt = undefined;
    if (userTier === "free") {
      const expiryDate = new Date();
      expiryDate.setDate(expiryDate.getDate() + 7);
      expiresAt = expiryDate.toISOString();
    }
    
    await ctx.db.insert("leadSearches", {
      searchId,
      userId,
      searchName: searchConfig.searchName,
      searchObjective: searchConfig.searchObjective,
      selectedSources: searchConfig.selectedSources,
      industry: searchConfig.industry,
      location: searchConfig.location,
      companySize: searchConfig.companySize,
      jobTitles: searchConfig.jobTitles,
      keywords: searchConfig.keywords,
      includeEmails: searchConfig.includeEmails,
      includePhones: searchConfig.includePhones,
      includeLinkedIn: searchConfig.includeLinkedIn,
      validationCriteria: searchConfig.validationCriteria,
      status: "pending",
      progress: 0,
      createdAt: now,
      updatedAt: now,
      userTier,
      expiresAt,
    });
  },
});



// Update search progress
export const updateSearchProgress = internalMutation({
  args: {
    searchId: v.string(),
    progress: v.number(),
    currentStage: v.optional(v.string()),
  },
  handler: async (ctx, { searchId, progress, currentStage }) => {
    const search = await ctx.db
      .query("leadSearches")
      .withIndex("by_search", (q) => q.eq("searchId", searchId))
      .first();

    if (!search) {
      console.warn(`Search ${searchId} not found, creating placeholder...`);
      // Create a minimal search record with default values
      const now = new Date().toISOString();
      await ctx.db.insert("leadSearches", {
        searchId,
        userId: "unknown", // Will be updated when proper creation happens
        searchName: "Search " + searchId,
        searchObjective: "Auto-created search",
        selectedSources: ["web"],
        industry: "Unknown",
        location: "Unknown",
        jobTitles: [],
        includeEmails: true,
        includePhones: true,
        includeLinkedIn: false,
        status: "processing",
        progress: 0,
        createdAt: now,
        updatedAt: now,
      });
      
      // Get the newly created search
      const newSearch = await ctx.db
        .query("leadSearches")
        .withIndex("by_search", (q) => q.eq("searchId", searchId))
        .first();
      
      if (!newSearch) {
        throw new Error("Failed to create search record");
      }
      
      // Continue with the update using the new record
      const updates: any = {
        progress,
        updatedAt: new Date().toISOString(),
      };

      if (currentStage) {
        updates.currentStage = currentStage;
      }

      // Auto-update status based on progress
      if (progress >= 100) {
        updates.status = "completed";
        updates.completedAt = new Date().toISOString();
      } else if (progress > 0 && newSearch.status === "pending") {
        updates.status = "processing";
      }

      await ctx.db.patch(newSearch._id, updates);
      return;
    }

    const updates: any = {
      progress,
      updatedAt: new Date().toISOString(),
    };

    if (currentStage) {
      updates.currentStage = currentStage;
    }

    // Auto-update status based on progress
    if (progress >= 100) {
      updates.status = "completed";
      updates.completedAt = new Date().toISOString();
    } else if (progress > 0 && search.status === "pending") {
      updates.status = "processing";
    }

    await ctx.db.patch(search._id, updates);
  },
});

// Update search status
export const updateSearchStatus = internalMutation({
  args: {
    searchId: v.string(),
    status: v.union(
      v.literal("pending"),
      v.literal("initializing"),
      v.literal("processing"),
      v.literal("completed"),
      v.literal("failed")
    ),
    error: v.optional(v.string()),
  },
  handler: async (ctx, { searchId, status, error }) => {
    const search = await ctx.db
      .query("leadSearches")
      .withIndex("by_search", (q) => q.eq("searchId", searchId))
      .first();

    if (!search) {
      console.warn(`Search ${searchId} not found, creating placeholder...`);
      // Create a minimal search record with default values
      const now = new Date().toISOString();
      await ctx.db.insert("leadSearches", {
        searchId,
        userId: "unknown", // Will be updated when proper creation happens
        searchName: "Search " + searchId,
        searchObjective: "Auto-created search",
        selectedSources: ["web"],
        industry: "Unknown",
        location: "Unknown",
        jobTitles: [],
        includeEmails: true,
        includePhones: true,
        includeLinkedIn: false,
        status: "processing",
        progress: 0,
        createdAt: now,
        updatedAt: now,
      });
      
      // Get the newly created search
      const newSearch = await ctx.db
        .query("leadSearches")
        .withIndex("by_search", (q) => q.eq("searchId", searchId))
        .first();
      
      if (!newSearch) {
        throw new Error("Failed to create search record");
      }
      
      // Continue with the update using the new record
      const updates: any = {
        status,
        updatedAt: new Date().toISOString(),
      };

      if (error) {
        updates.error = error;
      }

      if (status === "completed") {
        updates.completedAt = new Date().toISOString();
        updates.progress = 100;
      } else if (status === "failed") {
        updates.completedAt = new Date().toISOString();
      }

      await ctx.db.patch(newSearch._id, updates);
      return;
    }

    const updates: any = {
      status,
      updatedAt: new Date().toISOString(),
    };

    if (error) {
      updates.error = error;
    }

    if (status === "completed") {
      updates.completedAt = new Date().toISOString();
      updates.progress = 100;
    } else if (status === "failed") {
      updates.completedAt = new Date().toISOString();
    }

    await ctx.db.patch(search._id, updates);
  },
});

// Update search results summary
export const updateSearchResults = internalMutation({
  args: {
    searchId: v.string(),
    results: v.object({
      totalLeads: v.number(),
      verifiedEmails: v.number(),
      verifiedPhones: v.number(),
      businessWebsites: v.number(),
      avgResponseRate: v.string(),
      searchTime: v.string(),
    }),
  },
  handler: async (ctx, { searchId, results }) => {
    const search = await ctx.db
      .query("leadSearches")
      .withIndex("by_search", (q) => q.eq("searchId", searchId))
      .first();

    if (!search) {
      console.warn(`Search ${searchId} not found, creating placeholder for results update...`);
      // Create a minimal search record with default values
      const now = new Date().toISOString();
      await ctx.db.insert("leadSearches", {
        searchId,
        userId: "unknown", // Will be updated when proper creation happens
        searchName: "Search " + searchId,
        searchObjective: "Auto-created search",
        selectedSources: ["web"],
        industry: "Unknown",
        location: "Unknown",
        jobTitles: [],
        includeEmails: true,
        includePhones: true,
        includeLinkedIn: false,
        status: "completed", // Set to completed since we're updating results
        progress: 100,
        createdAt: now,
        updatedAt: now,
      });
      
      // Get the newly created search
      const newSearch = await ctx.db
        .query("leadSearches")
        .withIndex("by_search", (q) => q.eq("searchId", searchId))
        .first();
      
      if (!newSearch) {
        throw new Error("Failed to create search record for results update");
      }
      
      // Continue with the update using the new record
      await ctx.db.patch(newSearch._id, {
        totalLeads: results.totalLeads,
        verifiedEmails: results.verifiedEmails,
        verifiedPhones: results.verifiedPhones,
        businessWebsites: results.businessWebsites,
        avgResponseRate: results.avgResponseRate,
        searchTime: results.searchTime,
        updatedAt: new Date().toISOString(),
      });
      return;
    }

    await ctx.db.patch(search._id, {
      totalLeads: results.totalLeads,
      verifiedEmails: results.verifiedEmails,
      verifiedPhones: results.verifiedPhones,
      businessWebsites: results.businessWebsites,
      avgResponseRate: results.avgResponseRate,
      searchTime: results.searchTime,
      updatedAt: new Date().toISOString(),
    });
  },
});

// Store lead search results
export const storeLeadResults = internalMutation({
  args: {
    searchId: v.string(),
    leads: v.array(v.object({
      leadId: v.string(),
      name: v.optional(v.string()),
      email: v.optional(v.string()),
      phone: v.optional(v.string()),
      linkedInUrl: v.optional(v.string()),
      websiteUrl: v.optional(v.string()),
      companyName: v.optional(v.string()),
      companySize: v.optional(v.string()),
      industry: v.optional(v.string()),
      location: v.optional(v.string()),
      jobTitle: v.optional(v.string()),
      department: v.optional(v.string()),
      seniority: v.optional(v.string()),
      emailVerified: v.boolean(),
      phoneVerified: v.boolean(),
      confidence: v.number(),
      dataSource: v.string(),
    })),
  },
  handler: async (ctx, { searchId, leads }) => {
    const now = new Date().toISOString();
    
    // Store each lead result
    for (const lead of leads) {
      // Check if lead already exists to avoid duplicates
      const existingLead = await ctx.db
        .query("leadSearchResults")
        .withIndex("by_lead", (q) => q.eq("leadId", lead.leadId))
        .first();

      if (!existingLead) {
        await ctx.db.insert("leadSearchResults", {
          searchId,
          leadId: lead.leadId,
          name: lead.name,
          email: lead.email,
          phone: lead.phone,
          linkedInUrl: lead.linkedInUrl,
          websiteUrl: lead.websiteUrl,
          companyName: lead.companyName,
          companySize: lead.companySize,
          industry: lead.industry,
          location: lead.location,
          jobTitle: lead.jobTitle,
          department: lead.department,
          seniority: lead.seniority,
          emailVerified: lead.emailVerified,
          phoneVerified: lead.phoneVerified,
          confidence: lead.confidence,
          dataSource: lead.dataSource,
          extractedAt: now,
          lastUpdated: now,
        });
      }
    }
  },
});

// Create export job
export const createExportJob = internalMutation({
  args: {
    exportId: v.string(),
    userId: v.string(),
    searchId: v.string(),
    format: v.union(v.literal("csv"), v.literal("json"), v.literal("xlsx")),
    fields: v.array(v.string()),
    filters: v.optional(v.object({
      emailVerified: v.optional(v.boolean()),
      phoneVerified: v.optional(v.boolean()),
      minConfidence: v.optional(v.number()),
      dataSources: v.optional(v.array(v.string())),
    })),
  },
  handler: async (ctx, { exportId, userId, searchId, format, fields, filters }) => {
    const now = new Date().toISOString();
    const expiresAt = new Date(Date.now() + 7 * 24 * 60 * 60 * 1000).toISOString(); // 7 days

    await ctx.db.insert("leadExportJobs", {
      exportId,
      userId,
      searchId,
      format,
      fields,
      filters,
      status: "pending",
      progress: 0,
      createdAt: now,
      expiresAt,
    });
  },
});

// Update export job status
export const updateExportStatus = internalMutation({
  args: {
    exportId: v.string(),
    status: v.union(
      v.literal("processing"),
      v.literal("completed"),
      v.literal("failed")
    ),
    progress: v.optional(v.number()),
    recordCount: v.optional(v.number()),
    fileUrl: v.optional(v.string()),
    fileSize: v.optional(v.number()),
    error: v.optional(v.string()),
  },
  handler: async (ctx, args) => {
    const exportJob = await ctx.db
      .query("leadExportJobs")
      .withIndex("by_export", (q) => q.eq("exportId", args.exportId))
      .first();

    if (!exportJob) {
      throw new Error("Export job not found");
    }

    const updates: any = {
      status: args.status,
    };

    if (args.progress !== undefined) {
      updates.progress = args.progress;
    }

    if (args.recordCount !== undefined) {
      updates.recordCount = args.recordCount;
    }

    if (args.fileUrl) {
      updates.fileUrl = args.fileUrl;
    }

    if (args.fileSize !== undefined) {
      updates.fileSize = args.fileSize;
    }

    if (args.error) {
      updates.error = args.error;
    }

    if (args.status === "completed") {
      updates.completedAt = new Date().toISOString();
    }

    await ctx.db.patch(exportJob._id, updates);
  },
});

// Delete a search and all its related data
export const deleteSearch = internalMutation({
  args: { searchId: v.string() },
  handler: async (ctx, { searchId }) => {
    // Delete search record
    const search = await ctx.db
      .query("leadSearches")
      .withIndex("by_search", (q) => q.eq("searchId", searchId))
      .first();

    if (search) {
      await ctx.db.delete(search._id);
    }

    // Delete all lead results for this search
    const results = await ctx.db
      .query("leadSearchResults")
      .withIndex("by_search", (q) => q.eq("searchId", searchId))
      .collect();

    for (const result of results) {
      await ctx.db.delete(result._id);
    }

    // Delete any export jobs for this search
    const exportJobs = await ctx.db
      .query("leadExportJobs")
      .withIndex("by_search", (q) => q.eq("searchId", searchId))
      .collect();

    for (const job of exportJobs) {
      await ctx.db.delete(job._id);
    }
  },
});

// Update user subscription
export const updateUserSubscription = internalMutation({
  args: {
    userId: v.string(),
    tier: v.union(v.literal("free"), v.literal("premium"), v.literal("enterprise")),
    subscriptionId: v.optional(v.string()),
    status: v.optional(v.union(
      v.literal("active"),
      v.literal("cancelled"),
      v.literal("expired"),
      v.literal("trial")
    )),
    expiresAt: v.optional(v.string()),
  },
  handler: async (ctx, { userId, tier, subscriptionId, status, expiresAt }) => {
    const subscription = await ctx.db
      .query("userSubscriptions")
      .withIndex("by_user", (q) => q.eq("userId", userId))
      .first();

    const tierLimits = {
      free: { searchesPerDay: 5, leadsPerSearch: 50, totalLeadsPerMonth: 250 },
      premium: { searchesPerDay: 100, leadsPerSearch: 500, totalLeadsPerMonth: 50000 },
      enterprise: { searchesPerDay: -1, leadsPerSearch: -1, totalLeadsPerMonth: -1 },
    };

    const limits = tierLimits[tier];
    const now = new Date().toISOString();

    if (subscription) {
      // Update existing subscription
      const updates: any = {
        tier,
        searchesPerDay: limits.searchesPerDay,
        leadsPerSearch: limits.leadsPerSearch,
        totalLeadsPerMonth: limits.totalLeadsPerMonth,
        updatedAt: now,
      };

      if (subscriptionId) updates.subscriptionId = subscriptionId;
      if (status) updates.status = status;
      if (expiresAt) updates.expiresAt = expiresAt;

      await ctx.db.patch(subscription._id, updates);
    } else {
      // Create new subscription
      await ctx.db.insert("userSubscriptions", {
        userId,
        tier,
        searchesPerDay: limits.searchesPerDay,
        leadsPerSearch: limits.leadsPerSearch,
        totalLeadsPerMonth: limits.totalLeadsPerMonth,
        searchesToday: 0,
        leadsThisMonth: 0,
        lastResetDate: now,
        subscriptionId,
        status: status || "active",
        createdAt: now,
        updatedAt: now,
        expiresAt,
      });
    }
  },
});

// Cleanup expired export jobs
export const cleanupExpiredExports = internalMutation({
  args: {},
  handler: async (ctx) => {
    const now = new Date().toISOString();
    
    const expiredJobs = await ctx.db
      .query("leadExportJobs")
      .filter((q) => q.lt(q.field("expiresAt"), now))
      .collect();

    for (const job of expiredJobs) {
      await ctx.db.delete(job._id);
    }

    return { deletedJobs: expiredJobs.length };
  },
});

// Reset daily usage counters
export const resetDailyUsage = internalMutation({
  args: {},
  handler: async (ctx) => {
    const allSubscriptions = await ctx.db
      .query("userSubscriptions")
      .collect();

    const now = new Date();
    const today = now.toISOString().split('T')[0];

    for (const subscription of allSubscriptions) {
      const lastReset = new Date(subscription.lastResetDate);
      const lastResetDate = lastReset.toISOString().split('T')[0];

      if (today !== lastResetDate) {
        await ctx.db.patch(subscription._id, {
          searchesToday: 0,
          lastResetDate: now.toISOString(),
          updatedAt: now.toISOString(),
        });
      }
    }
  },
});

// Update lead verification status
export const updateLeadVerification = internalMutation({
  args: {
    leadId: v.string(),
    emailVerified: v.optional(v.boolean()),
    phoneVerified: v.optional(v.boolean()),
    confidence: v.optional(v.number()),
  },
  handler: async (ctx, { leadId, emailVerified, phoneVerified, confidence }) => {
    const lead = await ctx.db
      .query("leadSearchResults")
      .withIndex("by_lead", (q) => q.eq("leadId", leadId))
      .first();

    if (!lead) {
      throw new Error("Lead not found");
    }

    const updates: any = {
      lastUpdated: new Date().toISOString(),
    };

    if (emailVerified !== undefined) {
      updates.emailVerified = emailVerified;
    }

    if (phoneVerified !== undefined) {
      updates.phoneVerified = phoneVerified;
    }

    if (confidence !== undefined) {
      updates.confidence = confidence;
    }

    await ctx.db.patch(lead._id, updates);
  },
});


================================================
FILE: frontend/convex/hunterQueries.ts
================================================
import { query } from "./_generated/server";
import { v } from "convex/values";

// Get user subscription
export const getUserSubscription = query({
  args: { userId: v.string() },
  handler: async (ctx, { userId }) => {
    return await ctx.db
      .query("userSubscriptions")
      .withIndex("by_user", (q) => q.eq("userId", userId))
      .first();
  },
});

// Get lead search by ID
export const getLeadSearch = query({
  args: { searchId: v.string() },
  handler: async (ctx, { searchId }) => {
    return await ctx.db
      .query("leadSearches")
      .withIndex("by_search", (q) => q.eq("searchId", searchId))
      .first();
  },
});

// Get search results count
export const getSearchResultsCount = query({
  args: { searchId: v.string() },
  handler: async (ctx, { searchId }) => {
    const results = await ctx.db
      .query("leadSearchResults")
      .withIndex("by_search", (q) => q.eq("searchId", searchId))
      .collect();
    
    return results.length;
  },
});

// Get search results with pagination and filters
export const getSearchResults = query({
  args: {
    searchId: v.string(),
    limit: v.optional(v.number()),
    offset: v.optional(v.number()),
    filters: v.optional(v.object({
      emailVerified: v.optional(v.boolean()),
      phoneVerified: v.optional(v.boolean()),
      minConfidence: v.optional(v.number()),
      dataSources: v.optional(v.array(v.string())),
    })),
  },
  handler: async (ctx, { searchId, limit = 50, offset = 0, filters }) => {
    let query = ctx.db
      .query("leadSearchResults")
      .withIndex("by_search", (q) => q.eq("searchId", searchId));

    let results = await query.collect();

    // Apply filters
    if (filters) {
      if (filters.emailVerified !== undefined) {
        results = results.filter(r => r.emailVerified === filters.emailVerified);
      }
      if (filters.phoneVerified !== undefined) {
        results = results.filter(r => r.phoneVerified === filters.phoneVerified);
      }
      if (filters.minConfidence !== undefined) {
        results = results.filter(r => r.confidence >= filters.minConfidence);
      }
      if (filters.dataSources && filters.dataSources.length > 0) {
        results = results.filter(r => filters.dataSources.includes(r.dataSource));
      }
    }

    // Apply pagination
    const paginatedResults = results.slice(offset, offset + limit);

    return {
      results: paginatedResults,
      total: results.length,
      hasMore: offset + limit < results.length,
    };
  },
});

// Get user's search history
export const getUserSearchHistory = query({
  args: {
    userId: v.string(),
    limit: v.optional(v.number()),
    offset: v.optional(v.number()),
  },
  handler: async (ctx, { userId, limit = 20, offset = 0 }) => {
    const searches = await ctx.db
      .query("leadSearches")
      .withIndex("by_user", (q) => q.eq("userId", userId))
      .order("desc")
      .take(limit + offset);

    return searches.slice(offset);
  },
});

// Get all user searches for the hunter page
export const getUserSearchesForHunter = query({
  args: { 
    userId: v.string(),
    includeStats: v.optional(v.boolean())
  },
  handler: async (ctx, { userId, includeStats = true }) => {
    const searches = await ctx.db
      .query("leadSearches")
      .withIndex("by_user", (q) => q.eq("userId", userId))
      .order("desc")
      .collect();

    // If includeStats is true, fetch result counts for each search
    if (includeStats) {
      const searchesWithStats = await Promise.all(
        searches.map(async (search) => {
          const resultsCount = await ctx.db
            .query("leadSearchResults")
            .withIndex("by_search", (q) => q.eq("searchId", search.searchId))
            .collect()
            .then(results => results.length);

          return {
            ...search,
            resultsCount
          };
        })
      );
      return searchesWithStats;
    }

    return searches;
  },
});

// Get user's recent searches with results summary
export const getUserDashboardData = query({
  args: { userId: v.string() },
  handler: async (ctx, { userId }) => {
    // Get subscription info
    const subscription = await ctx.db
      .query("userSubscriptions")
      .withIndex("by_user", (q) => q.eq("userId", userId))
      .first();

    // Get recent searches
    const recentSearches = await ctx.db
      .query("leadSearches")
      .withIndex("by_user", (q) => q.eq("userId", userId))
      .order("desc")
      .take(10);

    // Get active searches
    const activeSearches = await ctx.db
      .query("leadSearches")
      .withIndex("by_user_status", (q) => q.eq("userId", userId).eq("status", "processing"))
      .collect();

    // Calculate total leads found this month
    const thisMonth = new Date();
    thisMonth.setDate(1);
    const monthStart = thisMonth.toISOString();

    const monthlySearches = await ctx.db
      .query("leadSearches")
      .withIndex("by_user", (q) => q.eq("userId", userId))
      .filter((q) => q.gte(q.field("createdAt"), monthStart))
      .collect();

    const totalLeadsThisMonth = monthlySearches.reduce((sum, search) => 
      sum + (search.totalLeads || 0), 0
    );

    return {
      subscription,
      recentSearches,
      activeSearches,
      stats: {
        totalSearches: recentSearches.length,
        activeSearches: activeSearches.length,
        totalLeadsThisMonth,
        searchesToday: subscription?.searchesToday || 0,
      },
    };
  },
});

// Get search analytics for a specific search
export const getSearchAnalytics = query({
  args: { searchId: v.string() },
  handler: async (ctx, { searchId }) => {
    const search = await ctx.db
      .query("leadSearches")
      .withIndex("by_search", (q) => q.eq("searchId", searchId))
      .first();

    if (!search) {
      return null;
    }

    const results = await ctx.db
      .query("leadSearchResults")
      .withIndex("by_search", (q) => q.eq("searchId", searchId))
      .collect();

    // Calculate analytics
    const totalResults = results.length;
    const verifiedEmails = results.filter(r => r.emailVerified).length;
    const verifiedPhones = results.filter(r => r.phoneVerified).length;
    const avgConfidence = totalResults > 0 
      ? results.reduce((sum, r) => sum + r.confidence, 0) / totalResults 
      : 0;

    // Source breakdown
    const sourceBreakdown = results.reduce((acc, result) => {
      acc[result.dataSource] = (acc[result.dataSource] || 0) + 1;
      return acc;
    }, {} as Record<string, number>);

    // Industry breakdown
    const industryBreakdown = results.reduce((acc, result) => {
      const industry = result.industry || "Unknown";
      acc[industry] = (acc[industry] || 0) + 1;
      return acc;
    }, {} as Record<string, number>);

    // Company size breakdown
    const companySizeBreakdown = results.reduce((acc, result) => {
      const size = result.companySize || "Unknown";
      acc[size] = (acc[size] || 0) + 1;
      return acc;
    }, {} as Record<string, number>);

    return {
      search,
      analytics: {
        totalResults,
        verifiedEmails,
        verifiedPhones,
        emailVerificationRate: totalResults > 0 ? (verifiedEmails / totalResults) * 100 : 0,
        phoneVerificationRate: totalResults > 0 ? (verifiedPhones / totalResults) * 100 : 0,
        avgConfidence: Math.round(avgConfidence * 100) / 100,
        sourceBreakdown,
        industryBreakdown,
        companySizeBreakdown,
      },
    };
  },
});

// Get export job status
export const getExportJob = query({
  args: { exportId: v.string() },
  handler: async (ctx, { exportId }) => {
    return await ctx.db
      .query("leadExportJobs")
      .withIndex("by_export", (q) => q.eq("exportId", exportId))
      .first();
  },
});

// Get user's export history
export const getUserExportHistory = query({
  args: {
    userId: v.string(),
    limit: v.optional(v.number()),
  },
  handler: async (ctx, { userId, limit = 10 }) => {
    return await ctx.db
      .query("leadExportJobs")
      .withIndex("by_user", (q) => q.eq("userId", userId))
      .order("desc")
      .take(limit);
  },
});

// Search for existing leads across all searches
export const searchExistingLeads = query({
  args: {
    userId: v.string(),
    query: v.string(),
    searchField: v.union(
      v.literal("email"),
      v.literal("name"),
      v.literal("company"),
      v.literal("phone")
    ),
    limit: v.optional(v.number()),
  },
  handler: async (ctx, { userId, query: searchQuery, searchField, limit = 50 }) => {
    // Get all user's searches first
    const userSearches = await ctx.db
      .query("leadSearches")
      .withIndex("by_user", (q) => q.eq("userId", userId))
      .collect();

    const searchIds = userSearches.map(s => s.searchId);

    // Search across all results from user's searches
    const allResults = await ctx.db
      .query("leadSearchResults")
      .collect();

    // Filter by user's searches and search query
    const filteredResults = allResults
      .filter(result => searchIds.includes(result.searchId))
      .filter(result => {
        const fieldValue = result[searchField]?.toLowerCase() || "";
        return fieldValue.includes(searchQuery.toLowerCase());
      })
      .slice(0, limit);

    return filteredResults;
  },
});

// Get lead details by ID
export const getLeadDetails = query({
  args: { leadId: v.string() },
  handler: async (ctx, { leadId }) => {
    return await ctx.db
      .query("leadSearchResults")
      .withIndex("by_lead", (q) => q.eq("leadId", leadId))
      .first();
  },
});

// Get similar leads (same company or industry)
export const getSimilarLeads = query({
  args: {
    leadId: v.string(),
    limit: v.optional(v.number()),
  },
  handler: async (ctx, { leadId, limit = 10 }) => {
    const lead = await ctx.db
      .query("leadSearchResults")
      .withIndex("by_lead", (q) => q.eq("leadId", leadId))
      .first();

    if (!lead) {
      return [];
    }

    // Find leads from same company or industry
    const similarLeads = await ctx.db
      .query("leadSearchResults")
      .collect();

    return similarLeads
      .filter(l => 
        l.leadId !== leadId && (
          (l.companyName && l.companyName === lead.companyName) ||
          (l.industry && l.industry === lead.industry)
        )
      )
      .slice(0, limit);
  },
});

// Get search performance metrics
export const getSearchPerformanceMetrics = query({
  args: { userId: v.string() },
  handler: async (ctx, { userId }) => {
    const searches = await ctx.db
      .query("leadSearches")
      .withIndex("by_user", (q) => q.eq("userId", userId))
      .collect();

    const completedSearches = searches.filter(s => s.status === "completed");
    const totalLeads = completedSearches.reduce((sum, s) => sum + (s.totalLeads || 0), 0);
    const avgLeadsPerSearch = completedSearches.length > 0 
      ? totalLeads / completedSearches.length 
      : 0;

    // Calculate average search time
    const searchesWithTime = completedSearches.filter(s => s.searchTime);
    const avgSearchTime = searchesWithTime.length > 0
      ? searchesWithTime.reduce((sum, s) => {
          const timeMatch = s.searchTime?.match(/(\d+)m\s*(\d+)s/);
          if (timeMatch) {
            return sum + (parseInt(timeMatch[1]) * 60 + parseInt(timeMatch[2]));
          }
          return sum;
        }, 0) / searchesWithTime.length
      : 0;

    return {
      totalSearches: searches.length,
      completedSearches: completedSearches.length,
      failedSearches: searches.filter(s => s.status === "failed").length,
      activeSearches: searches.filter(s => s.status === "processing").length,
      totalLeads,
      avgLeadsPerSearch: Math.round(avgLeadsPerSearch),
      avgSearchTimeSeconds: Math.round(avgSearchTime),
      successRate: searches.length > 0 
        ? (completedSearches.length / searches.length) * 100 
        : 0,
    };
  },
});


================================================
FILE: frontend/convex/rateLimitHelpers.ts
================================================
import { RateLimiter } from "@convex-dev/rate-limiter";
import { components, internal } from "./_generated/api";
import { internalMutation, mutation, query } from "./_generated/server";
import { v } from "convex/values";

// Time constants (in milliseconds)
const HOUR = 60 * 60 * 1000; // 1 hour
const DAY = 24 * 60 * 60 * 1000; // 24 hours

// Initialize rate limiter
export const rateLimiter = new RateLimiter(components.rateLimiter, {
  // Lead search limits
  leadSearchFree: { kind: "token bucket", rate: 100, period: DAY, capacity: 100 },
  leadSearchPremium: { kind: "token bucket", rate: 500, period: DAY, capacity: 100 },
  leadSearchEnterprise: { kind: "token bucket", rate: 1000, period: DAY, capacity: 200 },
  
  // Lead export limits
  leadExportFree: { kind: "token bucket", rate: 10, period: DAY, capacity: 10 },
  leadExportPremium: { kind: "token bucket", rate: 50, period: DAY, capacity: 20 },
  leadExportEnterprise: { kind: "token bucket", rate: 200, period: DAY, capacity: 50 },
  
  // RAG embedding limits
  ragEmbeddingsFree: { kind: "token bucket", rate: 100, period: DAY, capacity: 100 },
  ragEmbeddingsPremium: { kind: "token bucket", rate: 1000, period: DAY, capacity: 200 },
  ragEmbeddingsEnterprise: { kind: "token bucket", rate: 10000, period: DAY, capacity: 1000 },
  
  // RAG workflow limits
  ragWorkflowsFree: { kind: "token bucket", rate: 3, period: DAY, capacity: 3 },
  ragWorkflowsPremium: { kind: "token bucket", rate: 10, period: DAY, capacity: 5 },
  ragWorkflowsEnterprise: { kind: "token bucket", rate: 100, period: DAY, capacity: 20 },
  
  // API request limits (general)
  apiRequestsFree: { kind: "token bucket", rate: 1000, period: HOUR, capacity: 100 },
  apiRequestsPremium: { kind: "token bucket", rate: 5000, period: HOUR, capacity: 500 },
  apiRequestsEnterprise: { kind: "token bucket", rate: 10000, period: HOUR, capacity: 1000 },
  
  // Audio transcription limits
  audioTranscriptionsFree: { kind: "token bucket", rate: 10, period: HOUR, capacity: 10 },
  audioTranscriptionsPremium: { kind: "token bucket", rate: 50, period: HOUR, capacity: 20 },
  audioTranscriptionsEnterprise: { kind: "token bucket", rate: 200, period: HOUR, capacity: 50 },
});

// Default subscription tiers
export const SUBSCRIPTION_TIERS = {
  free: {
    searchesPerDay: 100,
    leadsPerSearch: 100,
    totalLeadsPerMonth: 10000,
    ragWorkflowsPerDay: 3,
    ragEmbeddingsPerDay: 100,
    ragMaxFileSize: 10 * 1024 * 1024, // 10MB
    ragDataRetention: 7, // days
    audioTranscriptionsPerHour: 10,
    audioMaxFileSize: 25 * 1024 * 1024, // 25MB (OpenAI limit)
    audioDataRetention: 7, // days
    features: ["basic_search", "web_sources", "rag_json_export", "audio_transcription"],
  },
  premium: {
    searchesPerDay: 500,
    leadsPerSearch: 1000,
    totalLeadsPerMonth: 500000,
    ragWorkflowsPerDay: 10,
    ragEmbeddingsPerDay: 1000,
    ragMaxFileSize: 100 * 1024 * 1024, // 100MB
    ragDataRetention: 30, // days
    audioTranscriptionsPerHour: 50,
    audioMaxFileSize: 25 * 1024 * 1024, // 25MB (OpenAI limit)
    audioDataRetention: 30, // days
    features: ["advanced_search", "all_sources", "email_verification", "export", "rag_csv_export", "audio_transcription"],
  },
  enterprise: {
    searchesPerDay: -1, // unlimited
    leadsPerSearch: -1, // unlimited
    totalLeadsPerMonth: -1, // unlimited
    ragWorkflowsPerDay: -1, // unlimited
    ragEmbeddingsPerDay: -1, // unlimited
    ragMaxFileSize: -1, // unlimited
    ragDataRetention: -1, // permanent
    audioTranscriptionsPerHour: -1, // unlimited
    audioMaxFileSize: 25 * 1024 * 1024, // 25MB (OpenAI limit)
    audioDataRetention: -1, // permanent
    features: ["unlimited_search", "all_sources", "priority_support", "api_access", "rag_all_exports", "audio_transcription"],
  },
} as const;

// Get or create user subscription
export const getUserSubscription = mutation({
  args: { userId: v.string() },
  handler: async (ctx, { userId }) => {
    let subscription = await ctx.db
      .query("userSubscriptions")
      .withIndex("by_user", (q) => q.eq("userId", userId))
      .first();

    if (!subscription) {
      // Create default free subscription
      const now = new Date().toISOString();
      const subscriptionId = await ctx.db.insert("userSubscriptions", {
        userId,
        tier: "free",
        searchesPerDay: SUBSCRIPTION_TIERS.free.searchesPerDay,
        leadsPerSearch: SUBSCRIPTION_TIERS.free.leadsPerSearch,
        totalLeadsPerMonth: SUBSCRIPTION_TIERS.free.totalLeadsPerMonth,
        searchesToday: 0,
        leadsThisMonth: 0,
        lastResetDate: now,
        status: "active",
        createdAt: now,
        updatedAt: now,
      });

      return await ctx.db.get(subscriptionId);
    }

    return subscription;
  },
});


// NEW: Internal mutation to reset usage counters
export const resetUsageCountersIfNeeded = internalMutation({
  args: { userId: v.string() },
  handler: async (ctx, { userId }) => {
    const subscription = await ctx.db
      .query("userSubscriptions")
      .withIndex("by_user", (q) => q.eq("userId", userId))
      .first();

    if (!subscription) {
      return; // No subscription to reset
    }

    const now = new Date();
    const today = now.toISOString().split('T')[0];
    const lastReset = new Date(subscription.lastResetDate);
    const lastResetDate = lastReset.toISOString().split('T')[0];
    
    const updates: Partial<typeof subscription> = {};

    // Reset daily counters if it's a new day
    if (today !== lastResetDate) {
      updates.searchesToday = 0;
      updates.lastResetDate = now.toISOString();
    }

    // Reset monthly counters if it's a new month
    const currentMonth = now.getMonth();
    const lastResetMonth = lastReset.getMonth();
    if (currentMonth !== lastResetMonth) {
      updates.leadsThisMonth = 0;
      // Also update lastResetDate to prevent daily reset on the same day
      updates.lastResetDate = now.toISOString();
    }

    if (Object.keys(updates).length > 0) {
      updates.updatedAt = now.toISOString();
      await ctx.db.patch(subscription._id, updates);
    }
  }
});


// Check rate limits for a feature
export async function checkRateLimit(
  ctx: any,
  userId: string,
  feature: "leadSearch" | "leadExport" | "apiRequests" | "ragEmbeddings" | "ragWorkflows",
  userTier: "free" | "premium" | "enterprise"
) {
  const rateLimitKey = `${feature}${userTier.charAt(0).toUpperCase() + userTier.slice(1)}`;
  
  try {
    await rateLimiter.limit(ctx, rateLimitKey as any, {
      key: userId,
      throws: true,
    });
    return { allowed: true };
  } catch (error) {
    return {
      allowed: false,
      error: `Rate limit exceeded for ${feature}. Please upgrade your plan or try again later.`,
    };
  }
}

// Check if user has reached their subscription limits (NOW READ-ONLY)
export const checkSubscriptionLimits = query({
  args: {
    userId: v.string(),
    feature: v.union(v.literal("search"), v.literal("export")),
    additionalLeads: v.optional(v.number()),
  },
  handler: async (ctx, { userId, feature, additionalLeads = 0 }) => {
    const subscription = await ctx.db
      .query("userSubscriptions")
      .withIndex("by_user", (q) => q.eq("userId", userId))
      .first();

    if (!subscription) {
      return { allowed: false, error: "No subscription found" };
    }

    // Check limits based on feature
    if (feature === "search") {
      if (subscription.tier !== "enterprise" && subscription.searchesToday >= subscription.searchesPerDay) {
        return {
          allowed: false,
          error: `Daily search limit reached (${subscription.searchesPerDay}). Upgrade for more searches.`,
          limit: subscription.searchesPerDay,
          used: subscription.searchesToday,
        };
      }
    }

    // Check monthly lead limits
    const potentialLeads = subscription.leadsThisMonth + additionalLeads;
    if (subscription.tier !== "enterprise" && potentialLeads > subscription.totalLeadsPerMonth) {
      return {
        allowed: false,
        error: `Monthly lead limit would be exceeded. Upgrade for more leads.`,
        limit: subscription.totalLeadsPerMonth,
        used: subscription.leadsThisMonth,
        wouldUse: potentialLeads,
      };
    }

    return { 
      allowed: true,
      subscription,
      limits: {
        searchesPerDay: subscription.searchesPerDay,
        searchesToday: subscription.searchesToday,
        leadsPerSearch: subscription.leadsPerSearch,
        totalLeadsPerMonth: subscription.totalLeadsPerMonth,
        leadsThisMonth: subscription.leadsThisMonth,
      }
    };
  },
});

// Increment usage counters
export const incrementUsage = mutation({
  args: {
    userId: v.string(),
    feature: v.union(v.literal("search"), v.literal("export")),
    leadsCount: v.optional(v.number()),
  },
  handler: async (ctx, { userId, feature, leadsCount = 0 }) => {
    const subscription = await ctx.db
      .query("userSubscriptions")
      .withIndex("by_user", (q) => q.eq("userId", userId))
      .first();

    if (!subscription) {
      throw new Error("No subscription found");
    }

    const updates: any = {
      updatedAt: new Date().toISOString(),
    };

    if (feature === "search") {
      updates.searchesToday = (subscription.searchesToday || 0) + 1;
    }

    if (leadsCount > 0) {
      updates.leadsThisMonth = (subscription.leadsThisMonth || 0) + leadsCount;
    }

    await ctx.db.patch(subscription._id, updates);
    return await ctx.db.get(subscription._id);
  },
});


// Get user's current usage stats
export const getUserUsageStats = query({
  args: { userId: v.string() },
  handler: async (ctx, { userId }) => {
    const subscription = await ctx.db
      .query("userSubscriptions")
      .withIndex("by_user", (q) => q.eq("userId", userId))
      .first();

    if (!subscription) {
      return null;
    }

    // Get recent searches
    const recentSearches = await ctx.db
      .query("leadSearches")
      .withIndex("by_user", (q) => q.eq("userId", userId))
      .order("desc")
      .take(10);

    return {
      subscription,
      usage: {
        searchesToday: subscription.searchesToday,
        searchesRemaining: subscription.tier === "enterprise" ? -1 : 
          Math.max(0, subscription.searchesPerDay - subscription.searchesToday),
        leadsThisMonth: subscription.leadsThisMonth,
        leadsRemaining: subscription.tier === "enterprise" ? -1 :
          Math.max(0, subscription.totalLeadsPerMonth - subscription.leadsThisMonth),
      },
      recentSearches: recentSearches.length,
      features: SUBSCRIPTION_TIERS[subscription.tier].features,
    };
  },
});



================================================
FILE: frontend/convex/schema.ts
================================================
// frontend/convex/schema.ts
import { defineSchema, defineTable } from "convex/server";
import { v } from "convex/values";

export default defineSchema({
  // Voice Agents table
  voiceAgents: defineTable({
    name: v.string(),
    description: v.string(),
    userId: v.string(),
    purpose: v.union(v.literal("sales"), v.literal("support"), v.literal("appointment"), v.literal("technical"), v.literal("custom")),
    customPurpose: v.optional(v.string()),
    voiceProvider: v.union(v.literal("elevenlabs"), v.literal("chatterbox")),
    voiceId: v.string(),
    voiceStyle: v.union(v.literal("professional"), v.literal("friendly"), v.literal("energetic"), v.literal("calm"), v.literal("custom")),
    speechRate: v.number(),
    pitch: v.number(),
    language: v.string(),
    responseDelay: v.number(),
    interruptionSensitivity: v.number(),
    silenceThreshold: v.number(),
    maxCallDuration: v.number(),
    systemPrompt: v.string(),
    temperature: v.number(),
    maxTokens: v.number(),
    enableTranscription: v.boolean(),
    enableAnalytics: v.boolean(),
    webhookUrl: v.optional(v.string()),
    status: v.union(v.literal("active"), v.literal("idle"), v.literal("offline"), v.literal("configuring"), v.literal("error")),
    createdAt: v.string(),
    updatedAt: v.string(),
    lastActiveAt: v.optional(v.string()),
    totalCalls: v.number(),
    successRate: v.number(),
    avgCallDuration: v.string(),
    satisfactionRating: v.number(),
  })
    .index("by_user", ["userId"])
    .index("by_status", ["status"])
    .index("by_purpose", ["purpose"])
    .index("by_created", ["createdAt"])
    .index("by_user_status", ["userId", "status"]),

  // Call Analytics table
  callAnalytics: defineTable({
    callId: v.string(),
    agentName: v.string(),
    agentId: v.optional(v.id("voiceAgents")),
    customerName: v.string(),
    customerPhone: v.string(),
    status: v.union(v.literal("COMPLETED"), v.literal("FAILED"), v.literal("TRANSFERRED"), v.literal("ABANDONED")),
    startTime: v.string(),
    endTime: v.string(),
    duration: v.string(),
    queueTime: v.string(),
    holdTime: v.string(),
    resolution: v.union(v.literal("RESOLVED"), v.literal("UNRESOLVED"), v.literal("ESCALATED"), v.literal("TRANSFERRED")),
    hasTransfer: v.boolean(),
    sentiment: v.union(v.literal("POSITIVE"), v.literal("NEGATIVE"), v.literal("NEUTRAL"), v.literal("MIXED")),
    qualityScore: v.string(),
    campaignId: v.optional(v.id("campaigns")),
    campaignName: v.string(),
    createdAt: v.number(),
    updatedAt: v.number(),
  })
    .index("by_callId", ["callId"])
    .index("by_agent", ["agentName"])
    .index("by_agentId", ["agentId"])
    .index("by_customer", ["customerPhone"])
    .index("by_campaign", ["campaignId"])
    .index("by_date", ["startTime"]),

  // Agent Call Logs
  agentCallLogs: defineTable({
    agentId: v.id("voiceAgents"),
    callId: v.string(),
    phoneNumber: v.string(),
    direction: v.union(v.literal("inbound"), v.literal("outbound")),
    startTime: v.string(),
    endTime: v.optional(v.string()),
    duration: v.optional(v.number()),
    status: v.union(v.literal("completed"), v.literal("failed"), v.literal("no_answer"), v.literal("busy"), v.literal("cancelled")),
    disposition: v.optional(v.string()),
    sentimentScore: v.optional(v.number()),
    satisfactionRating: v.optional(v.number()),
    recordingUrl: v.optional(v.string()),
    webhookSent: v.boolean(),
    webhookResponse: v.optional(v.string()),
  })
    .index("by_agent", ["agentId"])
    .index("by_call", ["callId"])
    .index("by_agent_time", ["agentId", "startTime"]),

  // Live Calls
  liveCalls: defineTable({
    callId: v.string(),
    agentId: v.id("voiceAgents"),
    agentName: v.string(),
    customerName: v.string(),
    customerPhone: v.string(),
    startTime: v.string(),
    duration: v.string(),
    status: v.union(v.literal("connecting"), v.literal("active"), v.literal("hold"), v.literal("transferring")),
    sentiment: v.union(v.literal("positive"), v.literal("negative"), v.literal("neutral")),
    lastTranscriptUpdate: v.string(),
    isRecording: v.boolean(),
  })
    .index("by_agent", ["agentId"])
    .index("by_status", ["status"]),

  // Swarm Campaigns
  campaigns: defineTable({
    name: v.string(),
    description: v.string(),
    type: v.union(v.literal("outbound"), v.literal("inbound"), v.literal("hybrid")),
    status: v.union(v.literal("active"), v.literal("paused"), v.literal("completed"), v.literal("scheduled")),
    maxConcurrentCalls: v.number(),
    callsPerHour: v.number(),
    retryAttempts: v.number(),
    timeBetweenRetries: v.number(),
    startDate: v.string(),
    endDate: v.optional(v.string()),
    activeHours: v.object({ start: v.string(), end: v.string(), timezone: v.string() }),
    totalCalls: v.number(),
    completedCalls: v.number(),
    successfulCalls: v.number(),
    avgCallDuration: v.string(),
    createdAt: v.string(),
    updatedAt: v.string(),
  })
    .index("by_status", ["status"])
    .index("by_date", ["createdAt"]),

  // Campaign Agents
  campaignAgents: defineTable({
    campaignId: v.id("campaigns"),
    agentId: v.id("voiceAgents"),
    assignedAt: v.string(),
    callsHandled: v.number(),
    successRate: v.number(),
  })
    .index("by_campaign", ["campaignId"])
    .index("by_agent", ["agentId"]),

  // Phone Numbers
  phoneNumbers: defineTable({
    number: v.string(),
    displayName: v.string(),
    type: v.union(v.literal("sip"), v.literal("pstn"), v.literal("virtual")),
    status: v.union(v.literal("active"), v.literal("inactive"), v.literal("maintenance")),
    provider: v.string(),
    location: v.string(),
    assignedUser: v.optional(v.string()),
    callsToday: v.number(),
    callsThisWeek: v.number(),
    callsThisMonth: v.number(),
    successRate: v.number(),
    avgCallDuration: v.string(),
    lastUsed: v.string(),
    sipConfig: v.optional(v.object({ endpoint: v.string(), username: v.string(), domain: v.string(), port: v.number(), protocol: v.union(v.literal("UDP"), v.literal("TCP"), v.literal("TLS")), codec: v.array(v.string()) })),
    features: v.array(v.string()),
    createdAt: v.string(),
    updatedAt: v.string(),
  })
    .index("by_status", ["status"])
    .index("by_type", ["type"])
    .index("by_provider", ["provider"]),

  // Transcript Entries
  transcriptEntries: defineTable({
    callId: v.string(),
    callAnalyticsId: v.optional(v.id("callAnalytics")),
    timestamp: v.string(),
    speaker: v.union(v.literal("agent"), v.literal("customer"), v.literal("system")),
    content: v.string(),
    sentiment: v.optional(v.union(v.literal("positive"), v.literal("negative"), v.literal("neutral"))),
    order: v.number(),
  })
    .index("by_call", ["callId"])
    .index("by_analytics", ["callAnalyticsId", "order"])
    .index("by_speaker", ["callId", "speaker"]),

  // Dashboard Statistics
  dashboardStats: defineTable({
    userId: v.string(),
    date: v.string(),
    totalCalls: v.number(),
    activeCalls: v.number(),
    successRate: v.number(),
    avgCallDuration: v.string(),
    totalAgents: v.number(),
    activeAgents: v.number(),
    idleAgents: v.number(),
    offlineAgents: v.number(),
    inboundCalls: v.number(),
    outboundCalls: v.number(),
    completedCalls: v.number(),
    failedCalls: v.number(),
    avgSentimentScore: v.number(),
    avgQualityScore: v.number(),
    transferRate: v.number(),
    updatedAt: v.string(),
  })
    .index("by_user_date", ["userId", "date"]),

  // YouTube Transcripts
  youtubeTranscripts: defineTable({
    videoId: v.string(),
    youtubeUrl: v.string(),
    transcript: v.optional(v.string()),
    language: v.optional(v.string()),
    wordCount: v.optional(v.number()),
    createdAt: v.string(),
    userId: v.optional(v.string()),
    videoTitle: v.optional(v.string()),
    videoAuthor: v.optional(v.string()),
    videoDuration: v.optional(v.number()),
    thumbnailUrl: v.optional(v.string()),
  })
    .index("by_video", ["videoId"])
    .index("by_user", ["userId"]),

  // Transcript Jobs Queue
  transcriptJobs: defineTable({
    jobId: v.string(),
    userId: v.string(),
    youtubeUrl: v.string(),
    videoId: v.string(),
    status: v.union(v.literal("pending"), v.literal("processing"), v.literal("completed"), v.literal("failed")),
    error: v.optional(v.string()),
    createdAt: v.string(),
    completedAt: v.optional(v.string()),
    videoTitle: v.optional(v.string()),
    videoAuthor: v.optional(v.string()),
  })
    .index("by_job", ["jobId"])
    .index("by_user", ["userId"])
    .index("by_status", ["status"]),

  // Hunter Lead Searches
  leadSearches: defineTable({
    searchId: v.string(),
    userId: v.string(),
    searchName: v.string(),
    searchObjective: v.string(),
    selectedSources: v.array(v.string()),
    industry: v.string(),
    location: v.string(),
    companySize: v.optional(v.string()),
    jobTitles: v.array(v.string()),
    keywords: v.optional(v.string()),
    includeEmails: v.boolean(),
    includePhones: v.boolean(),
    includeLinkedIn: v.boolean(),
    validationCriteria: v.optional(v.object({ mustHaveWebsite: v.boolean(), mustHaveContactInfo: v.boolean(), mustHaveSpecificKeywords: v.array(v.string()), mustBeInIndustry: v.boolean(), customValidationRules: v.string() })),
    status: v.union(v.literal("pending"), v.literal("initializing"), v.literal("processing"), v.literal("completed"), v.literal("failed")),
    progress: v.number(),
    currentStage: v.optional(v.string()),
    error: v.optional(v.string()),
    totalLeads: v.optional(v.number()),
    verifiedEmails: v.optional(v.number()),
    verifiedPhones: v.optional(v.number()),
    businessWebsites: v.optional(v.number()),
    avgResponseRate: v.optional(v.string()),
    searchTime: v.optional(v.string()),
    createdAt: v.string(),
    completedAt: v.optional(v.string()),
    updatedAt: v.string(),
    expiresAt: v.optional(v.string()),
    userTier: v.optional(v.union(v.literal("free"), v.literal("premium"), v.literal("enterprise"))),
  })
    .index("by_search", ["searchId"])
    .index("by_user", ["userId"])
    .index("by_status", ["status"])
    .index("by_user_status", ["userId", "status"])
    .index("by_created", ["createdAt"])
    .index("by_expiry", ["expiresAt"]),

  // Lead Search Results
  leadSearchResults: defineTable({
    searchId: v.string(),
    leadId: v.string(),
    name: v.optional(v.string()),
    email: v.optional(v.string()),
    phone: v.optional(v.string()),
    linkedInUrl: v.optional(v.string()),
    websiteUrl: v.optional(v.string()),
    companyName: v.optional(v.string()),
    companySize: v.optional(v.string()),
    industry: v.optional(v.string()),
    location: v.optional(v.string()),
    jobTitle: v.optional(v.string()),
    department: v.optional(v.string()),
    seniority: v.optional(v.string()),
    emailVerified: v.boolean(),
    phoneVerified: v.boolean(),
    confidence: v.number(),
    dataSource: v.string(),
    extractedAt: v.string(),
    lastUpdated: v.string(),
  })
    .index("by_search", ["searchId"])
    .index("by_lead", ["leadId"])
    .index("by_email", ["email"])
    .index("by_company", ["companyName"])
    .index("by_source", ["dataSource"]),

  // User Subscriptions
  userSubscriptions: defineTable({
    userId: v.string(),
    tier: v.union(v.literal("free"), v.literal("premium"), v.literal("enterprise")),
    searchesPerDay: v.number(),
    leadsPerSearch: v.number(),
    totalLeadsPerMonth: v.number(),
    searchesToday: v.number(),
    leadsThisMonth: v.number(),
    lastResetDate: v.string(),
    subscriptionId: v.optional(v.string()),
    status: v.union(v.literal("active"), v.literal("cancelled"), v.literal("expired"), v.literal("trial")),
    createdAt: v.string(),
    updatedAt: v.string(),
    expiresAt: v.optional(v.string()),
  })
    .index("by_user", ["userId"])
    .index("by_tier", ["tier"])
    .index("by_status", ["status"]),

  // Rate Limit Tracking
  rateLimitTracking: defineTable({
    userId: v.string(),
    feature: v.string(),
    windowStart: v.string(),
    requestCount: v.number(),
    lastRequest: v.string(),
  })
    .index("by_user_feature", ["userId", "feature"])
    .index("by_window", ["windowStart"]),

  // Lead Export Jobs
  leadExportJobs: defineTable({
    exportId: v.string(),
    userId: v.string(),
    searchId: v.string(),
    format: v.union(v.literal("csv"), v.literal("json"), v.literal("xlsx")),
    fields: v.array(v.string()),
    filters: v.optional(v.object({ emailVerified: v.optional(v.boolean()), phoneVerified: v.optional(v.boolean()), minConfidence: v.optional(v.number()), dataSources: v.optional(v.array(v.string())) })),
    status: v.union(v.literal("pending"), v.literal("processing"), v.literal("completed"), v.literal("failed")),
    progress: v.number(),
    recordCount: v.optional(v.number()),
    fileUrl: v.optional(v.string()),
    fileSize: v.optional(v.number()),
    createdAt: v.string(),
    completedAt: v.optional(v.string()),
    expiresAt: v.string(),
    error: v.optional(v.string()),
  })
    .index("by_export", ["exportId"])
    .index("by_user", ["userId"])
    .index("by_search", ["searchId"])
    .index("by_status", ["status"]),

  // RAG Workflows
  ragWorkflows: defineTable({
    workflowId: v.string(),
    userId: v.string(),
    name: v.string(),
    description: v.optional(v.string()),
    sourceType: v.union(v.literal("youtube"), v.literal("tiktok"), v.literal("twitch"), v.literal("documents"), v.literal("urls"), v.literal("csv"), v.literal("mixed")),
    embeddingModel: v.string(),
    chunkSize: v.number(),
    overlap: v.number(),
    status: v.union(v.literal("pending"), v.literal("processing"), v.literal("embedding"), v.literal("completed"), v.literal("failed"), v.literal("expired")),
    progress: v.number(),
    currentStage: v.optional(v.string()),
    totalSources: v.number(),
    processedSources: v.number(),
    totalChunks: v.number(),
    totalEmbeddings: v.number(),
    totalTokens: v.number(),
    indexSize: v.string(),
    userTier: v.union(v.literal("free"), v.literal("premium"), v.literal("enterprise")),
    totalFileSize: v.number(),
    createdAt: v.string(),
    startedAt: v.optional(v.string()),
    completedAt: v.optional(v.string()),
    expiresAt: v.optional(v.string()),
    estimatedCost: v.number(),
    actualCost: v.optional(v.number()),
  })
    .index("by_workflow", ["workflowId"])
    .index("by_user", ["userId"])
    .index("by_status", ["status"])
    .index("by_created", ["createdAt"])
    .index("by_expiry", ["expiresAt"]),

  // RAG Sources
  ragSources: defineTable({
    sourceId: v.string(),
    workflowId: v.string(),
    userId: v.string(),
    sourceType: v.union(v.literal("youtube_video"), v.literal("youtube_channel"), v.literal("tiktok_video"), v.literal("tiktok_channel"), v.literal("twitch_video"), v.literal("twitch_channel"), v.literal("document"), v.literal("url")),
    sourceUrl: v.optional(v.string()),
    fileName: v.optional(v.string()),
    fileSize: v.optional(v.number()),
    status: v.union(v.literal("pending"), v.literal("downloading"), v.literal("extracting"), v.literal("chunking"), v.literal("completed"), v.literal("failed")),
    error: v.optional(v.string()),
    content: v.optional(v.string()),
    metadata: v.optional(v.object({ title: v.optional(v.string()), author: v.optional(v.string()), duration: v.optional(v.number()), language: v.optional(v.string()), wordCount: v.optional(v.number()) })),
    chunkCount: v.number(),
    tokenCount: v.number(),
    createdAt: v.string(),
    processedAt: v.optional(v.string()),
  })
    .index("by_source", ["sourceId"])
    .index("by_workflow", ["workflowId"])
    .index("by_user", ["userId"])
    .index("by_status", ["status"]),

  // RAG Embeddings
  ragEmbeddings: defineTable({
    embeddingId: v.string(),
    workflowId: v.string(),
    sourceId: v.string(),
    userId: v.string(),
    chunkIndex: v.number(),
    chunkText: v.string(),
    chunkTokens: v.number(),
    embedding: v.array(v.float64()),
    embeddingModel: v.string(),
    dimensions: v.number(),
    metadata: v.optional(v.object({ sourceType: v.optional(v.string()), position: v.optional(v.object({ start: v.number(), end: v.number() })), context: v.optional(v.string()) })),
    confidence: v.optional(v.number()),
    createdAt: v.string(),
    expiresAt: v.optional(v.string()),
  })
    .index("by_embedding", ["embeddingId"])
    .index("by_workflow", ["workflowId"])
    .index("by_source", ["sourceId"])
    .index("by_user", ["userId"])
    .index("by_expiry", ["expiresAt"]),

  // RAG Export Jobs
  ragExportJobs: defineTable({
    exportId: v.string(),
    workflowId: v.string(),
    userId: v.string(),
    format: v.union(v.literal("json"), v.literal("jsonl"), v.literal("csv"), v.literal("parquet"), v.literal("pinecone"), v.literal("weaviate")),
    includeMetadata: v.boolean(),
    includeChunks: v.boolean(),
    status: v.union(v.literal("pending"), v.literal("processing"), v.literal("completed"), v.literal("failed")),
    progress: v.number(),
    fileUrl: v.optional(v.string()),
    fileSize: v.optional(v.number()),
    recordCount: v.optional(v.number()),
    createdAt: v.string(),
    completedAt: v.optional(v.string()),
    expiresAt: v.string(),
    error: v.optional(v.string()),
  })
    .index("by_export", ["exportId"])
    .index("by_workflow", ["workflowId"])
    .index("by_user", ["userId"])
    .index("by_status", ["status"]),

  // Audio Transcripts - FINAL, CORRECTED VERSION
  audioTranscripts: defineTable({
    jobId: v.string(),
    userId: v.string(),
    fileName: v.string(),
    fileSize: v.number(),
    fileFormat: v.string(),
    status: v.union(v.literal("pending"), v.literal("processing"), v.literal("completed"), v.literal("failed")),
    transcript: v.optional(v.string()),
    speakers: v.optional(v.array(v.object({
      speaker: v.string(),
      start: v.number(),
      end: v.number(),
      duration: v.number(),
      text: v.optional(v.string()),                    // 🔥 Transcribed text for this segment
      sentiment: v.optional(v.string()),               // 🎭 Basic sentiment
      speaker_similarity: v.optional(v.number()),      // 🎯 Speaker ID confidence
      langextract_analysis: v.optional(v.any()),       // 🔥 LangExtract analysis per segment
      emotion2vec: v.optional(v.any())                 // 🎭 Emotion2Vec results per segment
    }))),
    // Optional: structured insights from LangExtract webhook
    langextract: v.optional(v.any()),
    processingStartedAt: v.optional(v.union(v.number(), v.string())),
    completedAt: v.optional(v.union(v.number(), v.string())),
    error: v.optional(v.string()),
    createdAt: v.optional(v.any()),
    expiresAt: v.optional(v.any()),
  })
    .index("by_job", ["jobId"])
    .index("by_user", ["userId", "status"])
    .index("by_user_creation", ["userId"]),

  
  // TikTok Users
  tiktokUsers: defineTable({
    username: v.string(),
    userId: v.string(),
    secUid: v.string(),
    avatar: v.optional(v.string()),
    nickname: v.optional(v.string()),
    signature: v.optional(v.string()),
    verified: v.optional(v.boolean()),
    followerCount: v.optional(v.number()),
    followingCount: v.optional(v.number()),
    videoCount: v.optional(v.number()),
    heartCount: v.optional(v.number()),
    privateAccount: v.optional(v.boolean()),
    cachedAt: v.number(),
  })
    .index("by_username", ["username"])
    .index("by_userId", ["userId"])
    .index("by_cached", ["cachedAt"]),
  
  // TikTok Videos
  tiktokVideos: defineTable({
    videoId: v.string(),
    username: v.string(),
    title: v.string(),
    thumbnail: v.optional(v.string()),
    dynamicCover: v.optional(v.string()),
    duration: v.number(),
    createTime: v.number(),
    views: v.number(),
    likes: v.number(),
    comments: v.number(),
    shares: v.number(),
    saves: v.number(),
    playAddr: v.optional(v.string()),
    downloadAddr: v.optional(v.string()),
    downloadStatus: v.optional(v.union(v.literal("pending"), v.literal("downloading"), v.literal("completed"), v.literal("failed"))),
    localPath: v.optional(v.string()),
    musicId: v.optional(v.string()),
    musicTitle: v.optional(v.string()),
    musicAuthor: v.optional(v.string()),
    musicOriginal: v.optional(v.boolean()),
    hashtags: v.optional(v.array(v.object({ id: v.string(), name: v.string(), title: v.optional(v.string()) }))),
    cachedAt: v.number(),
  })
    .index("by_video", ["videoId"])
    .index("by_username", ["username"])
    .index("by_cached", ["cachedAt"])
    .index("by_download_status", ["downloadStatus"]),
  
  // TikTok Jobs
  tiktokJobs: defineTable({
    jobId: v.string(),
    userId: v.string(),
    username: v.string(),
    action: v.union(v.literal("fetch_user"), v.literal("fetch_videos"), v.literal("download_videos")),
    status: v.union(v.literal("pending"), v.literal("processing"), v.literal("downloading"), v.literal("completed"), v.literal("failed")),
    videoIds: v.optional(v.array(v.string())),
    progress: v.optional(v.number()),
    totalVideos: v.optional(v.number()),
    completedVideos: v.optional(v.number()),
    error: v.optional(v.string()),
    createdAt: v.number(),
    completedAt: v.optional(v.number()),
  })
    .index("by_job", ["jobId"])
    .index("by_user", ["userId"])
    .index("by_username", ["username"])
    .index("by_status", ["status"])
    .index("by_user_status", ["userId", "status"])
    .index("by_created", ["createdAt"]),
  
  // YouTube Channels
  youtubeChannels: defineTable({
    channelId: v.string(),
    channelName: v.string(),
    channelHandle: v.optional(v.string()),
    channelUrl: v.string(),
    avatar: v.optional(v.string()),
    banner: v.optional(v.string()),
    description: v.optional(v.string()),
    subscriberCount: v.optional(v.number()),
    videoCount: v.optional(v.number()),
    viewCount: v.optional(v.number()),
    joinedDate: v.optional(v.string()),
    country: v.optional(v.string()),
    cachedAt: v.number(),
  })
    .index("by_channel", ["channelId"])
    .index("by_handle", ["channelHandle"])
    .index("by_name", ["channelName"])
    .index("by_cached", ["cachedAt"]),
  
  // YouTube Videos
  youtubeVideos: defineTable({
    videoId: v.string(),
    channelId: v.string(),
    channelName: v.string(),
    title: v.string(),
    description: v.optional(v.string()),
    thumbnail: v.optional(v.string()),
    thumbnails: v.optional(v.array(v.object({ quality: v.string(), url: v.optional(v.string()), width: v.number(), height: v.number() }))),
    duration: v.number(),
    uploadDate: v.optional(v.string()),
    viewCount: v.optional(v.number()),
    likeCount: v.optional(v.number()),
    commentCount: v.optional(v.number()),
    tags: v.optional(v.array(v.string())),
    category: v.optional(v.string()),
    language: v.optional(v.string()),
    downloadStatus: v.optional(v.union(v.literal("pending"), v.literal("downloading"), v.literal("completed"), v.literal("failed"))),
    localPath: v.optional(v.string()),
    fileSize: v.optional(v.number()),
    hasTranscript: v.optional(v.boolean()),
    transcriptLanguages: v.optional(v.array(v.string())),
    cachedAt: v.number(),
  })
    .index("by_video", ["videoId"])
    .index("by_channel", ["channelId"])
    .index("by_channel_name", ["channelName"])
    .index("by_upload", ["uploadDate"])
    .index("by_cached", ["cachedAt"])
    .index("by_download_status", ["downloadStatus"]),
  
  // YouTube Jobs
  youtubeJobs: defineTable({
    jobId: v.string(),
    userId: v.string(),
    channelUrl: v.optional(v.string()),
    channelId: v.optional(v.string()),
    action: v.union(v.literal("fetch_channel"), v.literal("fetch_videos"), v.literal("download_videos")),
    status: v.union(v.literal("pending"), v.literal("processing"), v.literal("downloading"), v.literal("completed"), v.literal("failed")),
    videoIds: v.optional(v.array(v.string())),
    sortBy: v.optional(v.string()),
    count: v.optional(v.number()),
    progress: v.optional(v.number()),
    totalVideos: v.optional(v.number()),
    completedVideos: v.optional(v.number()),
    error: v.optional(v.string()),
    createdAt: v.number(),
    completedAt: v.optional(v.number()),
  })
    .index("by_job", ["jobId"])
    .index("by_user", ["userId"])
    .index("by_channel", ["channelId"])
    .index("by_status", ["status"])
    .index("by_user_status", ["userId", "status"])
    .index("by_created", ["createdAt"]),
  
  // Twitch Channels
  twitchChannels: defineTable({
    username: v.string(),
    displayName: v.string(),
    profileImage: v.optional(v.string()),
    bio: v.optional(v.string()),
    isVerified: v.boolean(),
    isPartner: v.boolean(),
    followerCount: v.number(),
    videoCount: v.number(),
    isLive: v.boolean(),
    channelUrl: v.string(),
    cachedAt: v.number(),
  })
    .index("by_username", ["username"])
    .index("by_cached", ["cachedAt"]),
  
  // Twitch Videos
  twitchVideos: defineTable({
    videoId: v.string(),
    channelUsername: v.string(),
    title: v.string(),
    thumbnail: v.optional(v.string()),
    duration: v.number(),
    viewCount: v.number(),
    createdAt: v.number(),
    url: v.optional(v.string()),
    type: v.union(v.literal("vod"), v.literal("clip"), v.literal("highlight")),
    game: v.optional(v.string()),
    language: v.optional(v.string()),
    description: v.optional(v.string()),
    downloadStatus: v.optional(v.union(v.literal("pending"), v.literal("downloading"), v.literal("completed"), v.literal("failed"))),
    localPath: v.optional(v.string()),
    fileSize: v.optional(v.number()),
    cachedAt: v.number(),
  })
    .index("by_video", ["videoId"])
    .index("by_channel", ["channelUsername"])
    .index("by_type", ["type"])
    .index("by_cached", ["cachedAt"])
    .index("by_download_status", ["downloadStatus"]),
  
  // Twitch Jobs
  twitchJobs: defineTable({
    jobId: v.string(),
    userId: v.string(),
    channelUrl: v.optional(v.string()),
    channelName: v.optional(v.string()),
    action: v.union(v.literal("fetch_channel"), v.literal("fetch_videos"), v.literal("download_videos")),
    status: v.union(v.literal("pending"), v.literal("processing"), v.literal("downloading"), v.literal("completed"), v.literal("failed")),
    videoIds: v.optional(v.array(v.string())),
    videoType: v.optional(v.string()),
    count: v.optional(v.number()),
    progress: v.optional(v.number()),
    totalVideos: v.optional(v.number()),
    completedVideos: v.optional(v.number()),
    error: v.optional(v.string()),
    result: v.optional(v.any()),
    createdAt: v.number(),
    completedAt: v.optional(v.number()),
  })
    .index("by_job", ["jobId"])
    .index("by_user", ["userId"])
    .index("by_channel", ["channelName"])
    .index("by_status", ["status"])
    .index("by_user_status", ["userId", "status"])
    .index("by_created", ["createdAt"]),
  
  // Instagram Users
  instagramUsers: defineTable({
    username: v.string(),
    userId: v.string(),
    fullName: v.optional(v.string()),
    biography: v.optional(v.string()),
    profilePicUrl: v.optional(v.string()),
    isVerified: v.optional(v.boolean()),
    isPrivate: v.optional(v.boolean()),
    followerCount: v.optional(v.number()),
    followingCount: v.optional(v.number()),
    postCount: v.optional(v.number()),
    externalUrl: v.optional(v.string()),
    cachedAt: v.number(),
  })
    .index("by_username", ["username"])
    .index("by_userId", ["userId"])
    .index("by_cached", ["cachedAt"]),
  
  // Instagram Posts
  instagramPosts: defineTable({
    postId: v.string(),
    username: v.string(),
    caption: v.optional(v.string()),
    mediaType: v.union(v.literal("image"), v.literal("video"), v.literal("carousel")),
    thumbnail: v.optional(v.string()),
    mediaUrl: v.optional(v.string()),
    likeCount: v.number(),
    commentCount: v.number(),
    timestamp: v.number(),
    location: v.optional(v.string()),
    isVideo: v.boolean(),
    videoDuration: v.optional(v.number()),
    carouselMediaCount: v.optional(v.number()),
    downloadStatus: v.optional(v.union(v.literal("pending"), v.literal("downloading"), v.literal("completed"), v.literal("failed"))),
    localPath: v.optional(v.string()),
    fileSize: v.optional(v.number()),
    cachedAt: v.number(),
  })
    .index("by_post", ["postId"])
    .index("by_username", ["username"])
    .index("by_cached", ["cachedAt"])
    .index("by_download_status", ["downloadStatus"]),
  
  // Instagram Jobs
  instagramJobs: defineTable({
    jobId: v.string(),
    userId: v.string(),
    username: v.string(),
    action: v.union(v.literal("fetch_user"), v.literal("fetch_posts"), v.literal("download_posts")),
    status: v.union(v.literal("pending"), v.literal("processing"), v.literal("downloading"), v.literal("completed"), v.literal("failed")),
    postIds: v.optional(v.array(v.string())),
    count: v.optional(v.number()),
    progress: v.optional(v.number()),
    totalPosts: v.optional(v.number()),
    completedPosts: v.optional(v.number()),
    result: v.optional(v.any()),
    error: v.optional(v.string()),
    createdAt: v.number(),
    completedAt: v.optional(v.number()),
  })
    .index("by_job", ["jobId"])
    .index("by_user", ["userId"])
    .index("by_username", ["username"])
    .index("by_status", ["status"])
    .index("by_user_status", ["userId", "status"])
    .index("by_created", ["createdAt"]),
  
  // Voice Clone Jobs
  voiceCloneJobs: defineTable({
    jobId: v.string(),
    userId: v.string(),
    status: v.union(v.literal("pending"), v.literal("processing"), v.literal("completed"), v.literal("failed")),
    voiceName: v.string(),
    audioFileUrl: v.optional(v.string()),
    audioFileName: v.optional(v.string()),
    audioFileSize: v.optional(v.number()),
    apiJobId: v.optional(v.string()),
    sampleText: v.optional(v.string()),
    voiceId: v.optional(v.string()),
    resultUrl: v.optional(v.string()),
    workerInfo: v.optional(v.object({ environment: v.string(), gpuType: v.string(), dropletId: v.optional(v.string()), ip: v.optional(v.string()) })),
    error: v.optional(v.string()),
    errorDetails: v.optional(v.object({ code: v.string(), message: v.string(), stack: v.optional(v.string()) })),
    createdAt: v.number(),
    startedAt: v.optional(v.number()),
    completedAt: v.optional(v.number()),
    processingTime: v.optional(v.number()),
    settings: v.optional(v.object({ exaggeration: v.optional(v.number()), chunkSize: v.optional(v.number()), cfgWeight: v.optional(v.number()) })),
  })
    .index("by_job", ["jobId"])
    .index("by_user", ["userId"])
    .index("by_status", ["status"])
    .index("by_user_status", ["userId", "status"])
    .index("by_created", ["createdAt"]),

  // Bulk Processing Jobs - SIMPLIFIED FOR RAG
  bulkJobs: defineTable({
    jobId: v.string(),
    userId: v.string(),
    jobType: v.string(), // e.g., "document-rag"
    status: v.union(v.literal("pending"), v.literal("uploading"), v.literal("processing"), v.literal("completed"), v.literal("failed")),
    statusMessage: v.optional(v.string()),
    fileName: v.optional(v.string()),
    fileSize: v.optional(v.number()),
    ragEntryId: v.optional(v.string()), // To link to the RAG entry
    error: v.optional(v.string()),
    createdAt: v.number(),
    updatedAt: v.optional(v.number()),
  })
    .index("by_jobId", ["jobId"])
    .index("by_user", ["userId"])
    .index("by_status", ["status"])
    .index("by_user_status", ["userId", "status"]),


  // Bulk Job Exports
  bulkJobExports: defineTable({
    exportId: v.string(),
    jobId: v.string(),
    userId: v.string(),
    format: v.union(v.literal("json"), v.literal("csv"), v.literal("parquet"), v.literal("vector"), v.literal("zip")),
    status: v.union(v.literal("pending"), v.literal("processing"), v.literal("completed"), v.literal("failed"), v.literal("expired")),
    filename: v.optional(v.string()),
    fileSize: v.optional(v.number()),
    filePath: v.optional(v.string()),
    downloadUrl: v.optional(v.string()),
    createdAt: v.number(),
    completedAt: v.optional(v.number()),
    expiresAt: v.optional(v.number()),
    errorMessage: v.optional(v.string())
  })
    .index("by_exportId", ["exportId"])
    .index("by_jobId", ["jobId"])
    .index("by_user", ["userId"])
    .index("by_status", ["status"])
    .index("by_created", ["createdAt"])
    .index("by_expires", ["expiresAt"]),

  // Procedural Audio Generation Jobs
  proceduralAudioJobs: defineTable({
    jobId: v.string(),
    userId: v.string(),
    config: v.object({
      prompt: v.string(),
      duration: v.number(),
      intensity: v.number(),
      name: v.string()
    }),
    status: v.union(v.literal("pending"), v.literal("processing"), v.literal("completed"), v.literal("failed")),
    audioUrl: v.optional(v.string()),
    audioId: v.optional(v.string()),
    fileName: v.optional(v.string()),
    fileSize: v.optional(v.number()),
    metadata: v.optional(v.object({
      size: v.string(),
      duration: v.string(),
      quality: v.string(),
      format: v.string()
    })),
    error: v.optional(v.string()),
    createdAt: v.number(),
    startedAt: v.optional(v.number()),
    completedAt: v.optional(v.number()),
    processingTime: v.optional(v.number()),
    backendJobId: v.optional(v.string())
  })
    .index("by_job", ["jobId"])
    .index("by_user", ["userId"])
    .index("by_status", ["status"])
    .index("by_user_status", ["userId", "status"])
    .index("by_created", ["createdAt"])
    .index("by_completed", ["completedAt"]),

  // Telephony Calls
  telephonyCalls: defineTable({
    callId: v.string(),
    userId: v.string(),
    direction: v.union(v.literal("inbound"), v.literal("outbound")),
    phoneNumber: v.string(),
    sipEndpoint: v.optional(v.string()),
    status: v.union(v.literal("connecting"), v.literal("connected"), v.literal("recording"), v.literal("processing"), v.literal("completed"), v.literal("failed"), v.literal("cancelled")),
    audioStreamUrl: v.optional(v.string()),
    recordingUrl: v.optional(v.string()),
    gstreamerPipeline: v.optional(v.string()),
    currentTranscript: v.optional(v.string()),
    currentSentiment: v.optional(v.string()),
    speakerLabels: v.optional(v.array(v.string())),
    fullTranscript: v.optional(v.string()),
    sentimentAnalysis: v.optional(v.any()),
    speakerDiarization: v.optional(v.any()),
    startTime: v.string(),
    endTime: v.optional(v.string()),
    duration: v.optional(v.number()),
    createdAt: v.string(),
    updatedAt: v.string(),
  })
    .index("by_call", ["callId"])
    .index("by_user", ["userId"])
    .index("by_status", ["status"])
    .index("by_user_status", ["userId", "status"]),

  // Real-time Audio Chunks
  audioChunks: defineTable({
    callId: v.string(),
    chunkId: v.string(),
    sequence: v.number(),
    audioData: v.string(),
    format: v.string(),
    sampleRate: v.number(),
    duration: v.number(),
    processed: v.boolean(),
    transcript: v.optional(v.string()),
    sentiment: v.optional(v.string()),
    speaker: v.optional(v.string()),
    timestamp: v.string(),
  })
    .index("by_call", ["callId"])
    .index("by_sequence", ["callId", "sequence"])
    .index("by_processed", ["callId", "processed"]),

  // GStreamer Pipeline Jobs
  gstreamerJobs: defineTable({
    jobId: v.string(),
    callId: v.string(),
    userId: v.string(),
    pipeline: v.string(),
    port: v.number(),
    codec: v.string(),
    status: v.union(v.literal("starting"), v.literal("running"), v.literal("stopping"), v.literal("completed"), v.literal("error")),
    bytesProcessed: v.number(),
    packetsReceived: v.number(),
    errors: v.array(v.string()),
    createdAt: v.string(),
    startedAt: v.optional(v.string()),
    completedAt: v.optional(v.string()),
  })
    .index("by_job", ["jobId"])
    .index("by_call", ["callId"])
    .index("by_status", ["status"]),

  // Telephony Jobs
  telephonyJobs: defineTable({
    jobId: v.string(),
    userId: v.string(),
    callId: v.string(),
    jobType: v.union(v.literal("call_start"), v.literal("call_process"), v.literal("call_end"), v.literal("asr_analysis"), v.literal("sentiment_analysis")),
    status: v.union(v.literal("pending"), v.literal("processing"), v.literal("completed"), v.literal("failed")),
    progress: v.object({ overall: v.number(), currentStage: v.number(), itemsTotal: v.number(), itemsCompleted: v.number(), itemsFailed: v.number() }),
    result: v.optional(v.any()),
    error: v.optional(v.string()),
    createdAt: v.string(),
    startedAt: v.optional(v.string()),
    completedAt: v.optional(v.string()),
  })
    .index("by_job", ["jobId"])
    .index("by_call", ["callId"])
    .index("by_user", ["userId"])
    .index("by_status", ["status"])
    .index("by_user_status", ["userId", "status"]),
  // Web Content Documents - for Jina Reader API processing
  webDocuments: defineTable({
    url: v.optional(v.string()),
    title: v.string(),
    content: v.string(),
    markdown: v.string(),
    metadata: v.object({
      publishedTime: v.optional(v.string()),
      author: v.optional(v.string()),
      description: v.optional(v.string()),
      keywords: v.optional(v.array(v.string())),
      language: v.optional(v.string()),
      wordCount: v.optional(v.number()),
    }),
    workflowId: v.string(),
    userId: v.string(),
    status: v.union(v.literal("pending"), v.literal("processing"), v.literal("completed"), v.literal("failed")),
    error: v.optional(v.string()),
    processed: v.boolean(),
    createdAt: v.number(),
    processedAt: v.optional(v.number()),
  })
    .index("by_url", ["url"])
    .index("by_workflow", ["workflowId"])
    .index("by_user", ["userId"])
    .index("by_status", ["status"]),

});



================================================
FILE: frontend/convex/testSetup.ts
================================================
import { mutation } from "./_generated/server";
import { v } from "convex/values";
import { SUBSCRIPTION_TIERS } from "./rateLimitHelpers";

// Create a test user subscription for development
export const createTestSubscription = mutation({
  args: {
    userId: v.string(),
  },
  handler: async (ctx, { userId }) => {
    // Check if subscription already exists
    const existing = await ctx.db
      .query("userSubscriptions")
      .withIndex("by_user", (q) => q.eq("userId", userId))
      .first();

    if (existing) {
      console.log("Subscription already exists for user:", userId);
      return existing._id;
    }

    // Create a free tier subscription for testing
    const now = new Date().toISOString();
    const subscriptionId = await ctx.db.insert("userSubscriptions", {
      userId,
      tier: "free",
      searchesPerDay: SUBSCRIPTION_TIERS.free.searchesPerDay,
      leadsPerSearch: SUBSCRIPTION_TIERS.free.leadsPerSearch,
      totalLeadsPerMonth: SUBSCRIPTION_TIERS.free.totalLeadsPerMonth,
      searchesToday: 0,
      leadsThisMonth: 0,
      lastResetDate: now,
      status: "active",
      createdAt: now,
      updatedAt: now,
    });

    console.log("Created test subscription for user:", userId);
    return subscriptionId;
  },
});

// Create a premium test subscription
export const createPremiumTestSubscription = mutation({
  args: {
    userId: v.string(),
  },
  handler: async (ctx, { userId }) => {
    // Check if subscription already exists
    const existing = await ctx.db
      .query("userSubscriptions")
      .withIndex("by_user", (q) => q.eq("userId", userId))
      .first();

    if (existing) {
      // Update to premium
      await ctx.db.patch(existing._id, {
        tier: "premium",
        searchesPerDay: SUBSCRIPTION_TIERS.premium.searchesPerDay,
        leadsPerSearch: SUBSCRIPTION_TIERS.premium.leadsPerSearch,
        totalLeadsPerMonth: SUBSCRIPTION_TIERS.premium.totalLeadsPerMonth,
        status: "active",
        updatedAt: new Date().toISOString(),
      });
      console.log("Updated subscription to premium for user:", userId);
      return existing._id;
    }

    // Create a premium subscription
    const now = new Date().toISOString();
    const subscriptionId = await ctx.db.insert("userSubscriptions", {
      userId,
      tier: "premium",
      searchesPerDay: SUBSCRIPTION_TIERS.premium.searchesPerDay,
      leadsPerSearch: SUBSCRIPTION_TIERS.premium.leadsPerSearch,
      totalLeadsPerMonth: SUBSCRIPTION_TIERS.premium.totalLeadsPerMonth,
      searchesToday: 0,
      leadsThisMonth: 0,
      lastResetDate: now,
      status: "active",
      createdAt: now,
      updatedAt: now,
    });

    console.log("Created premium subscription for user:", userId);
    return subscriptionId;
  },
});

// Update existing subscription limits to match new SUBSCRIPTION_TIERS
export const updateSubscriptionLimits = mutation({
  args: {
    userId: v.string(),
  },
  handler: async (ctx, { userId }) => {
    const subscription = await ctx.db
      .query("userSubscriptions")
      .withIndex("by_user", (q) => q.eq("userId", userId))
      .first();

    if (!subscription) {
      console.log("No subscription found for user:", userId);
      return null;
    }

    const tier = subscription.tier as keyof typeof SUBSCRIPTION_TIERS;
    const tierConfig = SUBSCRIPTION_TIERS[tier];

    // Update with new limits from SUBSCRIPTION_TIERS
    await ctx.db.patch(subscription._id, {
      searchesPerDay: tierConfig.searchesPerDay,
      leadsPerSearch: tierConfig.leadsPerSearch,
      totalLeadsPerMonth: tierConfig.totalLeadsPerMonth,
      updatedAt: new Date().toISOString(),
    });

    console.log(`Updated ${tier} subscription limits for user:`, userId);
    console.log(`New limits - Searches/day: ${tierConfig.searchesPerDay}, Leads/search: ${tierConfig.leadsPerSearch}, Leads/month: ${tierConfig.totalLeadsPerMonth}`);
    
    return subscription._id;
  },
});


================================================
FILE: frontend/src/app/dashboard/business-hunter/page.tsx
================================================
'use client';

import * as React from 'react';
import { Button } from '@/components/ui/button';
import { Card, CardHeader, CardTitle, CardContent } from '@/components/ui/card';
import { Input } from '@/components/ui/input';
import { Badge } from '@/components/ui/badge';
import { Progress } from '@/components/ui/progress';
import HuntConfigurationModal from '@/components/custom/modals/hunt-configuration-modal';
import ViewWorkflowModal from '@/components/custom/modals/view-workflow-modal';
import SettingsWorkflowModal from '@/components/custom/modals/settings-workflow-modal';
import DeleteConfirmationModal from '@/components/custom/modals/delete-confirmation-modal';
import StatCard from '@/components/custom/stat-card';
import { useQuery, useMutation, useAction } from 'convex/react';
import { api } from '@convex/_generated/api';
import { useHunterSearches } from '@/hooks/useHunterSearch';
import { 
  UilSearchAlt,
  UilBuilding,
  UilMapMarker,
  UilPhone,
  UilEnvelope,
  UilGlobe,
  UilUsersAlt,
  UilDollarSign,
  UilFilter,
  UilExport,
  UilBookmark,
  UilCheckCircle,
  UilClock,
  UilExclamationTriangle,
  UilPlay,
  UilPause,
  UilStopCircle,
  UilPlus,
  UilEdit,
  UilTrash,
  UilLink,
  UilLinkedin,
  UilDatabase,
  UilFileExport,
  UilEye,
  UilSync,
  UilCog,
  UilTrashAlt
} from '@tooni/iconscout-unicons-react';

interface SearchWorkflow {
  id: string;
  name: string;
  status: 'idle' | 'searching' | 'scraping' | 'analyzing' | 'validating' | 'completed' | 'failed';
  progress: number;
  parameters: {
    location: string;
    businessType: string;
    keywords: string[];
    includeLinkedIn: boolean;
    searchDepth: number;
  };
  stats: {
    pagesFound: number;
    pagesScraped: number;
    businessesExtracted: number;
    businessesValidated: number;
    matchRate: number;
  };
  createdAt: string;
  completedAt?: string;
  estimatedTime?: string;
  searchId?: string;
  currentStage?: string;
}

// TODO: Replace with actual user ID from auth
const MOCK_USER_ID = 'user_demo_123';

export default function BusinessHunterPage() {
  const [showCreateModal, setShowCreateModal] = React.useState(false);
  const [showViewModal, setShowViewModal] = React.useState(false);
  const [showSettingsModal, setShowSettingsModal] = React.useState(false);
  const [showDeleteModal, setShowDeleteModal] = React.useState(false);
  const [selectedWorkflow, setSelectedWorkflow] = React.useState<SearchWorkflow | null>(null);
  const [isDeleting, setIsDeleting] = React.useState(false);
  const [isCreating, setIsCreating] = React.useState(false);
  
  // Use real data from Convex
  const { searches: workflows, isLoading, stats } = useHunterSearches(MOCK_USER_ID);
  const createLeadSearch = useAction(api.hunterActions.createLeadSearch);
  const deleteSearch = useAction(api.hunterActions.deleteSearch);
  
  // Convert between frontend and backend status
  const getBackendStatus = (workflow: SearchWorkflow): string => {
    const statusMap: Record<SearchWorkflow['status'], string> = {
      'idle': 'pending',
      'searching': 'processing',
      'scraping': 'processing',
      'analyzing': 'processing',
      'validating': 'processing',
      'completed': 'completed',
      'failed': 'failed'
    };
    return statusMap[workflow.status];
  };
  
  // Poll for updates every 3 seconds for active workflows
  React.useEffect(() => {
    const activeWorkflows = workflows.filter(w => 
      w.status !== 'completed' && w.status !== 'failed'
    );
    
    if (activeWorkflows.length === 0) return;
    
    const interval = setInterval(() => {
      // The hook will automatically refetch
    }, 3000);
    
    return () => clearInterval(interval);
  }, [workflows]);
  
  // Show loading state
  if (isLoading) {
    return (
      <div className="h-full flex items-center justify-center">
        <div className="text-center">
          <div className="inline-flex items-center justify-center w-16 h-16 bg-purple-100 rounded-full mb-4">
            <UilSync className="w-8 h-8 text-purple-600 animate-spin" />
          </div>
          <p className="text-lg font-bold text-gray-600">Loading your searches...</p>
        </div>
      </div>
    );
  }


  const getStatusColor = (status: SearchWorkflow['status']) => {
    switch (status) {
      case 'idle': return 'bg-gray-100 text-gray-700';
      case 'searching': return 'bg-blue-100 text-blue-700';
      case 'scraping': return 'bg-yellow-100 text-yellow-700';
      case 'analyzing': return 'bg-purple-100 text-purple-700';
      case 'validating': return 'bg-orange-100 text-orange-700';
      case 'completed': return 'bg-green-100 text-green-700';
      case 'failed': return 'bg-red-100 text-red-700';
    }
  };

  const getStatusIcon = (status: SearchWorkflow['status']) => {
    switch (status) {
      case 'idle': return <UilClock className="w-5 h-5" />;
      case 'searching': return <UilSearchAlt className="w-5 h-5 animate-pulse" />;
      case 'scraping': return <UilLink className="w-5 h-5 animate-pulse" />;
      case 'analyzing': return <UilDatabase className="w-5 h-5 animate-pulse" />;
      case 'validating': return <UilCheckCircle className="w-5 h-5 animate-pulse" />;
      case 'completed': return <UilCheckCircle className="w-5 h-5" />;
      case 'failed': return <UilExclamationTriangle className="w-5 h-5" />;
    }
  };

  const getWorkflowSteps = (workflow: SearchWorkflow) => {
    const steps = [
      { name: 'Search', status: workflow.progress >= 0 },
      { name: 'Scrape', status: workflow.progress >= 25 },
      { name: 'Analyze', status: workflow.progress >= 50 },
      { name: 'Validate', status: workflow.progress >= 75 },
      { name: 'Complete', status: workflow.progress === 100 }
    ];
    return steps;
  };

  // Modal handlers
  const handleViewWorkflow = (workflow: SearchWorkflow) => {
    setSelectedWorkflow(workflow);
    setShowViewModal(true);
  };

  const handleSettingsWorkflow = (workflow: SearchWorkflow) => {
    setSelectedWorkflow(workflow);
    setShowSettingsModal(true);
  };

  const handleDeleteWorkflow = (workflow: SearchWorkflow) => {
    setSelectedWorkflow(workflow);
    setShowDeleteModal(true);
  };

  const handlePauseResumeWorkflow = (workflow: SearchWorkflow) => {
    // TODO: Implement pause/resume functionality
    console.log('Pause/Resume not yet implemented for:', workflow.id);
  };

  const handleSaveWorkflowSettings = (updatedWorkflow: Partial<SearchWorkflow>) => {
    // TODO: Implement settings update
    console.log('Settings update not yet implemented');
  };

  const handleConfirmDelete = async () => {
    if (!selectedWorkflow || !selectedWorkflow.searchId) return;
    
    setIsDeleting(true);
    
    try {
      await deleteSearch({
        userId: MOCK_USER_ID,
        searchId: selectedWorkflow.searchId
      });
      
      setShowDeleteModal(false);
      setSelectedWorkflow(null);
    } catch (error) {
      console.error('Error deleting search:', error);
      alert('Failed to delete search. Please try again.');
    } finally {
      setIsDeleting(false);
    }
  };

  const handleExportWorkflow = (format: 'csv' | 'crm') => {
    if (!selectedWorkflow) return;
    
    // Simulate export functionality
    const exportData = {
      workflow: selectedWorkflow.name,
      format: format,
      businesses: selectedWorkflow.stats.businessesExtracted,
      timestamp: new Date().toISOString()
    };
    
    console.log('Exporting workflow:', exportData);
    // In real implementation, this would trigger file download or CRM integration
  };

  const closeAllModals = () => {
    setShowViewModal(false);
    setShowSettingsModal(false);
    setShowDeleteModal(false);
    setSelectedWorkflow(null);
  };

  return (
    <div className="h-full overflow-y-auto" style={{ fontFamily: 'Noyh-Bold, sans-serif' }}>
      {/* Page Header */}
      <div className="mb-8">
        <div className="flex justify-between items-start">
          <div>
            <h1 className="text-4xl font-black uppercase text-black mb-2">BUSINESS HUNTER</h1>
            <p className="text-lg text-gray-600">Automated business discovery and validation workflows</p>
          </div>
          <Button
            onClick={() => setShowCreateModal(true)}
            variant="default"
            size="lg"
            className="font-bold"
          >
            <UilPlus className="w-5 h-5 mr-2" />
            NEW HUNT
          </Button>
        </div>
      </div>

      {/* Active Workflows Summary */}
      <div className="grid grid-cols-1 md:grid-cols-4 gap-4 mb-8">
        <StatCard
          title="Active Hunts"
          value={workflows.filter(w => w.status !== 'completed' && w.status !== 'failed').length}
          icon={<UilSync className="w-6 h-6 text-white animate-spin" />}
          iconBgColor="bg-purple-600"
          bgGradient="from-purple-50 to-purple-100"
        />

        <StatCard
          title="Pages Found"
          value={workflows.reduce((acc, w) => acc + w.stats.pagesFound, 0).toLocaleString()}
          icon={<UilGlobe className="w-6 h-6 text-white" />}
          iconBgColor="bg-green-600"
          bgGradient="from-green-50 to-green-100"
        />

        <StatCard
          title="Businesses Found"
          value={workflows.reduce((acc, w) => acc + w.stats.businessesExtracted, 0)}
          icon={<UilBuilding className="w-6 h-6 text-white" />}
          iconBgColor="bg-orange-600"
          bgGradient="from-orange-50 to-orange-100"
        />

        <StatCard
          title="Avg Match Rate"
          value={`${Math.round(workflows.reduce((acc, w) => acc + w.stats.matchRate, 0) / workflows.length)}%`}
          icon={<UilCheckCircle className="w-6 h-6 text-white" />}
          iconBgColor="bg-pink-600"
          bgGradient="from-pink-50 to-pink-100"
        />
      </div>

      {/* Workflow Cards Grid */}
      <div className="grid grid-cols-1 lg:grid-cols-2 gap-6">
        {workflows.map((workflow, index) => (
          <Card 
            key={workflow.id}
            className={`border-4 border-black shadow-[6px_6px_0_rgba(0,0,0,1)] hover:shadow-[8px_8px_0_rgba(0,0,0,1)] transition-all duration-200 bg-white transform ${
              index % 3 === 0 ? 'rotate-1' : index % 3 === 1 ? '-rotate-1' : ''
            }`}
          >
            <CardHeader className={`border-b-4 border-black ${
              workflow.status === 'completed' ? 'bg-green-400' :
              workflow.status === 'failed' ? 'bg-red-400' :
              'bg-yellow-400'
            }`}>
              <div className="flex items-start justify-between">
                <div>
                  <CardTitle className="text-2xl font-black uppercase text-black">{workflow.name}</CardTitle>
                  <div className="flex items-center gap-3 mt-2">
                    <Badge className={`border-2 border-black font-bold uppercase ${getStatusColor(workflow.status)}`}>
                      {getStatusIcon(workflow.status)}
                      <span className="ml-2">{workflow.status}</span>
                    </Badge>
                    {workflow.estimatedTime && (
                      <span className="text-sm font-bold text-black/70">
                        <UilClock className="w-4 h-4 inline mr-1" />
                        {workflow.estimatedTime}
                      </span>
                    )}
                  </div>
                </div>
                <div className="flex gap-2">
                  {workflow.status !== 'completed' && workflow.status !== 'failed' && (
                    <Button
                      size="sm"
                      variant="neutral"
                      className="p-2"
                      onClick={() => handlePauseResumeWorkflow(workflow)}
                      title={workflow.status === 'idle' ? 'Resume workflow' : 'Pause workflow'}
                    >
                      <UilPause className="w-4 h-4 text-black" />
                    </Button>
                  )}
                  <Button
                    size="sm"
                    variant="neutral"
                    className="p-2"
                    onClick={() => handleViewWorkflow(workflow)}
                    title="View workflow details"
                  >
                    <UilEye className="w-4 h-4 text-black" />
                  </Button>
                  <Button
                    size="sm"
                    variant="neutral"
                    className="p-2"
                    onClick={() => handleSettingsWorkflow(workflow)}
                    title="Edit workflow settings"
                  >
                    <UilCog className="w-4 h-4 text-black" />
                  </Button>
                  <Button
                    size="sm"
                    variant="neutral"
                    className="p-2"
                    onClick={() => handleDeleteWorkflow(workflow)}
                    title="Delete workflow"
                  >
                    <UilTrashAlt className="w-4 h-4 text-black" />
                  </Button>
                </div>
              </div>
            </CardHeader>
            
            <CardContent className="p-6">
              {/* Progress Steps */}
              <div className="mb-6">
                <div className="flex items-center justify-center mb-4">
                  <div className="flex items-center gap-3">
                    {getWorkflowSteps(workflow).map((step, idx) => {
                      const stepIcons = [
                        UilSearchAlt, // Search
                        UilLink,      // Scrape  
                        UilDatabase,  // Analyze
                        UilCheckCircle, // Validate
                        UilCheckCircle  // Complete
                      ];
                      const StepIcon = stepIcons[idx];
                      
                      return (
                        <React.Fragment key={idx}>
                          <div className={`
                            relative px-4 py-3 border-4 border-black flex items-center gap-2 font-bold text-sm
                            transition-all duration-300 min-w-fit
                            ${step.status 
                              ? 'bg-[rgb(0,82,255)] text-white shadow-[3px_3px_0_rgba(0,0,0,1)]' 
                              : 'bg-gray-300 text-gray-600 shadow-[2px_2px_0_rgba(0,0,0,1)]'
                            }
                          `}>
                            <StepIcon className="w-4 h-4 flex-shrink-0" />
                            <span className="hidden sm:inline text-sm">{step.name}</span>
                            <span className="sm:hidden">{idx + 1}</span>
                          </div>
                          {idx < getWorkflowSteps(workflow).length - 1 && (
                            <div className={`w-6 h-2 border-2 border-black transition-all duration-300 ${
                              getWorkflowSteps(workflow)[idx + 1]?.status 
                                ? 'bg-[rgb(0,82,255)] shadow-[2px_2px_0_rgba(0,0,0,1)]' 
                                : 'bg-gray-400'
                            }`}></div>
                          )}
                        </React.Fragment>
                      );
                    })}
                  </div>
                </div>
                <Progress value={workflow.progress} className="h-3 border-2 border-black" />
              </div>

              {/* Parameters */}
              <div className="space-y-3 mb-4">
                <div className="flex items-center gap-2 text-sm">
                  <UilMapMarker className="w-4 h-4 text-gray-500" />
                  <span className="font-bold">Location:</span>
                  <span>{workflow.parameters.location}</span>
                </div>
                <div className="flex items-center gap-2 text-sm">
                  <UilBuilding className="w-4 h-4 text-gray-500" />
                  <span className="font-bold">Type:</span>
                  <span>{workflow.parameters.businessType}</span>
                </div>
                <div className="flex items-center gap-2 text-sm">
                  <UilFilter className="w-4 h-4 text-gray-500" />
                  <span className="font-bold">Keywords:</span>
                  <span>{workflow.parameters.keywords.join(', ')}</span>
                </div>
                <div className="flex items-center gap-4 text-sm">
                  <div className="flex items-center gap-2">
                    <UilLinkedin className="w-4 h-4 text-gray-500" />
                    <span className="font-bold">LinkedIn:</span>
                    <span>{workflow.parameters.includeLinkedIn ? 'Yes' : 'No'}</span>
                  </div>
                  <div className="flex items-center gap-2">
                    <UilSearchAlt className="w-4 h-4 text-gray-500" />
                    <span className="font-bold">Depth:</span>
                    <span>{workflow.parameters.searchDepth} levels</span>
                  </div>
                </div>
              </div>

              {/* Stats Grid */}
              <div className="grid grid-cols-2 gap-3 mb-4">
                <div className="p-3 bg-gray-50 border-2 border-black">
                  <p className="text-xs font-bold text-gray-600 uppercase">Pages Found</p>
                  <p className="text-xl font-black text-black">{workflow.stats.pagesFound.toLocaleString()}</p>
                </div>
                <div className="p-3 bg-gray-50 border-2 border-black">
                  <p className="text-xs font-bold text-gray-600 uppercase">Scraped</p>
                  <p className="text-xl font-black text-black">{workflow.stats.pagesScraped.toLocaleString()}</p>
                </div>
                <div className="p-3 bg-gray-50 border-2 border-black">
                  <p className="text-xs font-bold text-gray-600 uppercase">Businesses</p>
                  <p className="text-xl font-black text-black">{workflow.stats.businessesExtracted}</p>
                </div>
                <div className="p-3 bg-gray-50 border-2 border-black">
                  <p className="text-xs font-bold text-gray-600 uppercase">Match Rate</p>
                  <p className="text-xl font-black text-green-600">{workflow.stats.matchRate}%</p>
                </div>
              </div>

              {/* Action Buttons */}
              <div className="flex gap-2">
                {workflow.status === 'completed' && (
                  <>
                    <Button variant="default" className="flex-1 px-3 py-2 text-sm font-bold">
                      <UilFileExport className="w-4 h-4 mr-1" />
                      EXPORT CSV
                    </Button>
                    <Button variant="default" className="flex-1 px-3 py-2 text-sm font-bold">
                      <UilDatabase className="w-4 h-4 mr-1" />
                      TO CRM
                    </Button>
                  </>
                )}
                {workflow.status !== 'completed' && workflow.status !== 'failed' && (
                  <Button variant="default" className="flex-1 px-3 py-2 text-sm font-bold">
                    <UilStopCircle className="w-4 h-4 mr-1" />
                    STOP HUNT
                  </Button>
                )}
              </div>

              {/* Created Date */}
              <p className="text-xs text-gray-500 mt-4">
                Started: {new Date(workflow.createdAt).toLocaleString()}
                {workflow.completedAt && ` • Completed: ${new Date(workflow.completedAt).toLocaleString()}`}
              </p>
            </CardContent>
          </Card>
        ))}

        {/* Create New Workflow Card */}
        <Card 
          onClick={() => setShowCreateModal(true)}
          className="border-4 border-dashed border-gray-400 shadow-[4px_4px_0_rgba(0,0,0,0.3)] hover:shadow-[6px_6px_0_rgba(0,0,0,0.5)] hover:border-black transition-all duration-200 bg-gray-50 cursor-pointer group min-h-[400px]"
        >
          <CardContent className="h-full flex flex-col items-center justify-center p-8">
            <div className="w-20 h-20 bg-gray-200 border-4 border-gray-400 group-hover:border-black group-hover:bg-gray-300 rounded-full flex items-center justify-center mb-4 transition-all">
              <UilPlus className="w-10 h-10 text-gray-600 group-hover:text-black" />
            </div>
            <p className="text-xl font-black text-gray-600 group-hover:text-black uppercase">Start New Hunt</p>
            <p className="text-sm text-gray-500 mt-2 text-center">Configure search parameters and deploy automated discovery workflow</p>
          </CardContent>
        </Card>
      </div>

      {/* Hunt Configuration Modal */}
      <HuntConfigurationModal
        isOpen={showCreateModal}
        onClose={() => {
          setShowCreateModal(false);
          setIsCreating(false);
        }}
        onSave={async (huntData) => {
          setIsCreating(true);
          
          try {
            // Convert frontend format to backend format
            const searchConfig = {
              searchName: huntData.name,
              searchObjective: `Find ${huntData.businessType} businesses in ${huntData.location}`,
              selectedSources: ['web'], // Default to web search
              industry: huntData.businessType,
              location: huntData.location,
              companySize: undefined, // Not collected in current modal
              jobTitles: [], // Not collected in current modal
              keywords: huntData.keywords.join(', '),
              includeEmails: true,
              includePhones: true,
              includeLinkedIn: huntData.includeLinkedIn,
              validationCriteria: {
                mustHaveWebsite: true,
                mustHaveContactInfo: true,
                mustHaveSpecificKeywords: huntData.keywords,
                mustBeInIndustry: true,
                customValidationRules: ''
              }
            };
            
            const result = await createLeadSearch({
              userId: MOCK_USER_ID,
              searchConfig
            });
            
            console.log('Search created:', result);
            setShowCreateModal(false);
            
            // The searches will auto-refresh due to the subscription
          } catch (error) {
            console.error('Error creating search:', error);
            alert(`Failed to create search: ${error.message || 'Unknown error'}`);
          } finally {
            setIsCreating(false);
          }
        }}
      />

      {/* View Workflow Modal */}
      <ViewWorkflowModal
        isOpen={showViewModal}
        onClose={closeAllModals}
        workflow={selectedWorkflow}
        onExport={handleExportWorkflow}
      />

      {/* Settings Workflow Modal */}
      <SettingsWorkflowModal
        isOpen={showSettingsModal}
        onClose={closeAllModals}
        workflow={selectedWorkflow}
        onSave={handleSaveWorkflowSettings}
      />

      {/* Delete Confirmation Modal */}
      <DeleteConfirmationModal
        isOpen={showDeleteModal}
        onClose={closeAllModals}
        onConfirm={handleConfirmDelete}
        itemName={selectedWorkflow?.name || ''}
        itemType="workflow"
        warningMessage="This will permanently delete the workflow and all its data"
        consequences={[
          'All collected business data will be lost',
          'Workflow progress cannot be recovered',
          'This action cannot be undone',
          selectedWorkflow?.status !== 'completed' && selectedWorkflow?.status !== 'failed' 
            ? 'Active search process will be immediately stopped' 
            : 'Historical results will be permanently deleted'
        ].filter(Boolean) as string[]}
        requiresNameConfirmation={selectedWorkflow?.stats.businessesExtracted > 50}
        isLoading={isDeleting}
      />
    </div>
  );
}


================================================
FILE: frontend/src/app/onboarding/hunter/page.tsx
================================================
'use client';

import * as React from 'react';
import { Card, CardHeader, CardTitle, CardContent } from '@/components/ui/card';
import { Button } from '@/components/ui/button';
import { useAction, useQuery, useMutation } from "convex/react";
import { api } from "@convex/_generated/api";
import SimpleOnboardingNav from '@/components/custom/simple-onboarding-nav';
import VerificationModal from '@/components/custom/modals/verification-modal';
import { OnboardingFooter } from '@/components/custom/onboarding-footer';
import { useConvexErrorHandler } from '@/hooks/useConvexErrorHandler';
import { toast } from 'sonner';
import { TooltipProvider } from '@/components/ui/tooltip';
import { 
  UilSearch, 
  UilPhone, 
  UilAnalytics,
  UilFilter,
  UilUserCheck,
  UilPlay,
  UilCheckCircle,
  UilCrosshair,
  UilGlobe,
  UilDatabase,
  UilBuilding
} from '@tooni/iconscout-unicons-react';

// Import step components
import { SearchDefinitionStep, SearchDefinitionInfoSections } from '@/components/onboarding/hunter/SearchDefinitionStep';
import { IndustryLocationStep } from '@/components/onboarding/hunter/IndustryLocationStep';
import { CompanyDetailsStep } from '@/components/onboarding/hunter/CompanyDetailsStep';
import { SearchKeywordsStep } from '@/components/onboarding/hunter/SearchKeywordsStep';
import { ContactPreferencesStep } from '@/components/onboarding/hunter/ContactPreferencesStep';
import { ValidationCriteriaStep } from '@/components/onboarding/hunter/ValidationCriteriaStep';
import { SearchPreviewStep } from '@/components/onboarding/hunter/SearchPreviewStep';
import { SearchProgressStep } from '@/components/onboarding/hunter/SearchProgressStep';
import { SearchResultsStep } from '@/components/onboarding/hunter/SearchResultsStep';

import { 
  SearchCriteria, 
  ValidationCriteria, 
  ContactPreferences, 
  SearchResults, 
  LeadSource,
  StepProps 
} from '@/components/onboarding/hunter/types';

// Constants
const leadSources: LeadSource[] = [
  {
    id: 'web',
    name: 'Web Search',
    icon: <UilGlobe className="h-8 w-8" />,
    description: 'Crawl websites and online directories',
    color: 'bg-green-600'
  },
  {
    id: 'database',
    name: 'B2B Database',
    icon: <UilDatabase className="h-8 w-8" />,
    description: 'Access verified business contacts',
    color: 'bg-purple-600'
  },
  {
    id: 'directory',
    name: 'Business Directories',
    icon: <UilBuilding className="h-8 w-8" />,
    description: 'Search Yellow Pages and industry directories',
    color: 'bg-orange-600'
  }
];

const industries = [
  'Technology',
  'Healthcare',
  'Finance',
  'Real Estate',
  'Retail',
  'Manufacturing',
  'Education',
  'Consulting',
  'Other'
];

const jobTitles = [
  'CEO',
  'CTO',
  'VP Sales',
  'Marketing Director',
  'HR Manager',
  'Operations Manager',
  'Product Manager',
  'Business Owner'
];

export default function HunterOnboarding() {
  // const { user } = useUser(); // Temporarily commented out for backend integration
  const user = { id: "temp-user-123" }; // Temporary mock user for testing
  const createTestSubscription = useMutation(api.testSetup.createTestSubscription);
  const updateSubscriptionLimits = useMutation(api.testSetup.updateSubscriptionLimits);
  const { handleConvexError } = useConvexErrorHandler();
  
  // Step state
  const [currentStep, setCurrentStep] = React.useState(1);
  
  // Search definition state
  const [searchName, setSearchName] = React.useState('');
  const [searchObjective, setSearchObjective] = React.useState('');
  const [selectedSources, setSelectedSources] = React.useState<string[]>([]);
  
  // Search criteria state
  const [searchCriteria, setSearchCriteria] = React.useState<SearchCriteria>({
    industry: '',
    location: '',
    companySize: '1-100',
    jobTitles: [],
    keywords: ''
  });
  const [customIndustry, setCustomIndustry] = React.useState('');
  
  // Contact preferences state
  const [contactPreferences, setContactPreferences] = React.useState<ContactPreferences>({
    includeEmails: true,
    includePhones: true,
    includeLinkedIn: false
  });
  
  // Validation criteria state
  const [validationCriteria, setValidationCriteria] = React.useState<ValidationCriteria>({
    mustHaveWebsite: true,
    mustHaveContactInfo: true,
    mustHaveSpecificKeywords: [],
    mustBeInIndustry: true,
    customValidationRules: ''
  });
  
  // Search execution state
  const [isSearching, setIsSearching] = React.useState(false);
  const [searchProgress, setSearchProgress] = React.useState(0);
  const [currentStatus, setCurrentStatus] = React.useState('');
  const [searchResults, setSearchResults] = React.useState<SearchResults | null>(null);
  const [showVerification, setShowVerification] = React.useState(false);
  const [currentSearchId, setCurrentSearchId] = React.useState<string | null>(null);
  const [devMode, setDevMode] = React.useState(false);

  // Convex actions and queries
  const createLeadSearch = useAction(api.hunterActions.createLeadSearch);
  const getSearchStatus = useAction(api.hunterActions.getSearchStatus);
  const userUsageStats = useQuery(api.rateLimitHelpers.getUserUsageStats, 
    user?.id ? { userId: user.id } : "skip"
  );

  // Auto-fill function for dev mode
  React.useEffect(() => {
    if (devMode) {
      setSearchName('Belfast Roofing Contractors Q4');
      setSearchObjective('Finding roofing contractors and construction companies in Belfast area for partnership opportunities');
      setSelectedSources(['web']);
      setSearchCriteria({
        industry: 'Other',
        location: 'Belfast, Northern Ireland',
        companySize: '1-10',
        jobTitles: ['Business Owner', 'Operations Manager'],
        keywords: 'roofing, roof repair, slate, tiles, guttering, Belfast'
      });
      setCustomIndustry('Roofing & Construction');
      setContactPreferences({
        includeEmails: true,
        includePhones: true,
        includeLinkedIn: false
      });
      setValidationCriteria({
        mustHaveWebsite: true,
        mustHaveContactInfo: true,
        mustHaveSpecificKeywords: ['roofing', 'contractor', 'Belfast'],
        mustBeInIndustry: true,
        customValidationRules: 'Must offer residential or commercial roofing services'
      });
    }
  }, [devMode]);

  // Create test subscription and update limits on mount
  React.useEffect(() => {
    if (user?.id) {
      createTestSubscription({ userId: user.id })
        .then(() => {
          return updateSubscriptionLimits({ userId: user.id });
        })
        .catch((err) => {
          console.log("Subscription handling:", err.message);
          updateSubscriptionLimits({ userId: user.id }).catch(console.error);
        });
    }
  }, [user?.id, createTestSubscription, updateSubscriptionLimits]);

  // Handler functions
  const handleSourceSelect = (sourceId: string) => {
    if (selectedSources.includes(sourceId)) {
      setSelectedSources(selectedSources.filter(s => s !== sourceId));
    } else {
      setSelectedSources([...selectedSources, sourceId]);
    }
  };

  const toggleJobTitle = (title: string) => {
    setSearchCriteria(prev => ({
      ...prev,
      jobTitles: prev.jobTitles.includes(title)
        ? prev.jobTitles.filter(t => t !== title)
        : [...prev.jobTitles, title]
    }));
  };

  const canStartSearch = () => {
    if (!searchName || !searchObjective || selectedSources.length === 0 || 
        !searchCriteria.industry || !searchCriteria.location) {
      return false;
    }
    if (searchCriteria.location.toLowerCase() === searchCriteria.industry.toLowerCase()) {
      return false;
    }
    if (searchName.toLowerCase() === searchCriteria.industry.toLowerCase()) {
      return false;
    }
    return true;
  };

  const startSearch = async () => {
    if (!user?.id) {
      toast.error('Please sign in to start a search');
      return;
    }

    setIsSearching(true);
    setCurrentStep(5);
    setCurrentStatus('Initializing search...');
    setSearchProgress(10);
    
    await new Promise(resolve => setTimeout(resolve, 1000));
    setShowVerification(true);
  };

  const handleVerificationComplete = async (email: string, phone: string) => {
    setShowVerification(false);
    
    if (!user?.id) {
      toast.error('Please sign in to continue');
      return;
    }

    try {
      const searchConfig = {
        searchName,
        searchObjective,
        selectedSources,
        industry: searchCriteria.industry === 'Other' ? customIndustry : searchCriteria.industry,
        location: searchCriteria.location,
        companySize: searchCriteria.companySize || '1-100',
        jobTitles: searchCriteria.jobTitles,
        keywords: searchCriteria.keywords,
        includeEmails: contactPreferences.includeEmails,
        includePhones: contactPreferences.includePhones,
        includeLinkedIn: contactPreferences.includeLinkedIn,
        validationCriteria: {
          mustHaveWebsite: validationCriteria.mustHaveWebsite,
          mustHaveContactInfo: validationCriteria.mustHaveContactInfo,
          mustHaveSpecificKeywords: validationCriteria.mustHaveSpecificKeywords,
          mustBeInIndustry: validationCriteria.mustBeInIndustry,
          customValidationRules: validationCriteria.customValidationRules,
        },
      };

      const result = await createLeadSearch({
        userId: user.id,
        searchConfig,
      });

      setCurrentSearchId(result.searchId);
      pollSearchProgress(result.searchId);
      
    } catch (error) {
      console.error('Search creation failed:', error);
      setCurrentStatus('Search failed: ' + (error.message || 'Unknown error'));
      setIsSearching(false);
      handleConvexError(error);
    }
  };

  // Poll search progress
  const pollSearchProgress = async (searchId: string) => {
    const maxAttempts = 60;
    let attempts = 0;
    let lastProgress = 0;
    let stuckCounter = 0;

    const poll = async () => {
      if (attempts >= maxAttempts) {
        setCurrentStatus('Search timed out - please check back later');
        setIsSearching(false);
        return;
      }

      try {
        const status = await getSearchStatus({ searchId });
        
        const newProgress = status.progress || 0;
        if (newProgress > lastProgress) {
          const increment = (newProgress - lastProgress) / 10;
          for (let i = 1; i <= 10; i++) {
            setTimeout(() => {
              setSearchProgress(prev => Math.min(prev + increment, newProgress));
            }, i * 50);
          }
          lastProgress = newProgress;
          stuckCounter = 0;
        } else {
          stuckCounter++;
          if (stuckCounter > 6) {
            setCurrentStatus(status.currentStage + ' (this may take a while...)');
          }
        }

        setCurrentStatus(status.currentStage || 'Processing...');

        if (status.status === 'completed') {
          setSearchProgress(100);
          setSearchResults({
            totalLeads: status.totalLeads || 0,
            verifiedEmails: status.verifiedEmails || 0,
            verifiedPhones: status.verifiedPhones || 0,
            businessWebsites: status.businessWebsites || 0,
            avgResponseRate: status.avgResponseRate || '0%',
            searchTime: status.searchTime || '0m 0s'
          });
          setIsSearching(false);
          setCurrentStep(6);
          return;
        } else if (status.status === 'failed') {
          setCurrentStatus('Search failed: ' + (status.error || 'Unknown error'));
          setIsSearching(false);
          
          toast.error('Search failed. Click to retry', {
            action: {
              label: 'Retry',
              onClick: () => {
                setCurrentStep(4);
                setSearchProgress(0);
                setCurrentStatus('');
              }
            },
            duration: 10000
          });
          return;
        }

        attempts++;
        const pollInterval = newProgress > 90 ? 5000 : 10000;
        setTimeout(poll, pollInterval);
        
      } catch (error) {
        console.error('Error polling search status:', error);
        attempts++;
        
        if (attempts > 3) {
          setCurrentStatus('Connection issue - retrying...');
        }
        
        setTimeout(poll, 15000);
      }
    };

    poll();
  };

  const handleStepChange = (step: number) => {
    if (step < currentStep) {
      setCurrentStep(step);
    }
  };

  // Create step props object
  const stepProps: StepProps = {
    currentStep,
    setCurrentStep,
    searchName,
    setSearchName,
    searchObjective,
    setSearchObjective,
    selectedSources,
    setSelectedSources,
    searchCriteria,
    setSearchCriteria,
    customIndustry,
    setCustomIndustry,
    contactPreferences,
    setContactPreferences,
    validationCriteria,
    setValidationCriteria,
    isSearching,
    setIsSearching,
    searchProgress,
    setSearchProgress,
    currentStatus,
    setCurrentStatus,
    searchResults,
    setSearchResults,
    currentSearchId,
    setCurrentSearchId,
    showVerification,
    setShowVerification,
    devMode,
    setDevMode,
    handleSourceSelect,
    toggleJobTitle,
    canStartSearch,
    startSearch,
    handleVerificationComplete,
    handleStepChange,
    userUsageStats,
    createLeadSearch,
    getSearchStatus,
    leadSources,
    industries,
    jobTitles
  };

  return (
    <TooltipProvider>
      <div className="min-h-screen bg-violet-400 relative pb-8" style={{ 
        fontFamily: 'Noyh-Bold, sans-serif',
        backgroundImage: `linear-gradient(rgba(15, 23, 41, 0.8) 1px, transparent 1px), linear-gradient(90deg, rgba(15, 23, 41, 0.8) 1px, transparent 1px)`,
        backgroundSize: '60px 60px'
      }}>
      {/* Dev Mode Toggle */}
      {process.env.NODE_ENV === 'development' && (
        <div className="fixed top-4 right-4 z-50">
          <Button
            onClick={() => setDevMode(!devMode)}
            className={`h-10 px-4 text-sm font-black uppercase ${
              devMode 
                ? 'bg-green-500 hover:bg-green-600 text-white' 
                : 'bg-gray-200 hover:bg-gray-300 text-black'
            } border-2 border-black`}
          >
            DEV MODE {devMode ? 'ON' : 'OFF'}
          </Button>
        </div>
      )}
      
      <div className="flex flex-col items-center justify-center min-h-screen p-4">
        <div className="w-full max-w-4xl space-y-8">
          {/* Persistent Title Card */}
          <Card className="transform -rotate-1 relative overflow-hidden">
            <CardHeader className="relative">
              <div className="absolute top-2 left-4 w-8 h-8 bg-violet-600 border-2 border-black flex items-center justify-center">
                <UilSearch className="h-4 w-4 text-white" />
              </div>
              <div className="absolute top-2 right-4 w-8 h-8 bg-violet-500 border-2 border-black flex items-center justify-center">
                <UilCrosshair className="h-4 w-4 text-white" />
              </div>
              <div className="absolute bottom-3 left-6 w-6 h-6 bg-yellow-400 border-2 border-black rotate-12">
                <div className="w-2 h-2 bg-black absolute top-1 left-1"></div>
              </div>
              <div className="absolute bottom-2 right-8 w-4 h-4 bg-pink-500 border-2 border-black -rotate-12"></div>
              <div className="flex justify-center mb-4">
                <Button className="w-20 h-20 bg-violet-600 hover:bg-violet-700 border-4 border-black p-0">
                  {currentStep === 1 && <UilSearch className="h-12 w-12 text-white" />}
                  {currentStep === 2 && <UilBuilding className="h-12 w-12 text-white" />}
                  {currentStep === 2.5 && <UilFilter className="h-12 w-12 text-white" />}
                  {currentStep === 2.75 && <UilCrosshair className="h-12 w-12 text-white" />}
                  {currentStep === 3 && <UilUserCheck className="h-12 w-12 text-white" />}
                  {currentStep === 3.5 && <UilFilter className="h-12 w-12 text-white" />}
                  {currentStep === 4 && <UilPlay className="h-12 w-12 text-white" />}
                  {currentStep === 5 && <UilAnalytics className="h-12 w-12 text-white" />}
                  {currentStep === 6 && <UilCheckCircle className="h-12 w-12 text-white" />}
                </Button>
              </div>
              <CardTitle className="text-5xl md:text-6xl font-black uppercase text-center text-black relative z-10">
                {currentStep === 1 && 'SEARCH DEFINITION'}
                {currentStep === 2 && 'INDUSTRY & LOCATION'}
                {currentStep === 2.5 && 'COMPANY DETAILS'}
                {currentStep === 2.75 && 'SEARCH KEYWORDS'}
                {currentStep === 3 && 'CONTACT PREFERENCES'}
                {currentStep === 3.5 && 'VALIDATION CRITERIA'}
                {currentStep === 4 && 'SEARCH PREVIEW'}
                {currentStep === 5 && 'SEARCHING LEADS'}
                {currentStep === 6 && 'SEARCH COMPLETE'}
              </CardTitle>
              <p className="text-lg md:text-xl text-gray-700 mt-4 font-bold text-center">
                {currentStep === 1 && 'DEFINE YOUR SEARCH OBJECTIVES'}
                {currentStep === 2 && 'SET TARGET MARKET & GEOGRAPHY'}
                {currentStep === 2.5 && 'SPECIFY COMPANY PROFILE'}
                {currentStep === 2.75 && 'REFINE WITH KEYWORDS'}
                {currentStep === 3 && 'CHOOSE CONTACT INFORMATION'}
                {currentStep === 3.5 && 'SET VALIDATION RULES'}
                {currentStep === 4 && 'REVIEW AND LAUNCH SEARCH'}
                {currentStep === 5 && 'FINDING YOUR PERFECT CUSTOMERS'}
                {currentStep === 6 && 'YOUR LEADS ARE READY'}
              </p>
              <div className="flex justify-center items-center mt-3 gap-2">
                <div className="w-3 h-3 bg-violet-600 animate-pulse"></div>
                <div className="w-2 h-6 bg-black"></div>
                <div className="w-4 h-4 bg-violet-500 animate-pulse delay-150"></div>
                <div className="w-2 h-8 bg-black"></div>
                <div className="w-3 h-3 bg-violet-600 animate-pulse delay-300"></div>
              </div>
            </CardHeader>
          </Card>

          {/* Step Components */}
          {currentStep === 1 && <SearchDefinitionStep {...stepProps} />}
          {currentStep === 2 && <IndustryLocationStep {...stepProps} />}
          {currentStep === 2.5 && <CompanyDetailsStep {...stepProps} />}
          {currentStep === 2.75 && <SearchKeywordsStep {...stepProps} />}
          {currentStep === 3 && <ContactPreferencesStep {...stepProps} />}
          {currentStep === 3.5 && <ValidationCriteriaStep {...stepProps} />}
          {currentStep === 4 && <SearchPreviewStep {...stepProps} />}
          {currentStep === 5 && <SearchProgressStep {...stepProps} />}
          {currentStep === 6 && <SearchResultsStep {...stepProps} />}
        </div>
        
        {/* Info Sections - Only on Step 1 */}
        {currentStep === 1 && <SearchDefinitionInfoSections />}
      </div>



      {/* Verification Modal */}
      {showVerification && (
        <VerificationModal
          isOpen={showVerification}
          onClose={() => setShowVerification(false)}
          onComplete={handleVerificationComplete}
          devMode={devMode}
        />
      )}
      
      <div className="mt-8">
        <OnboardingFooter />
      </div>
    </div>
    </TooltipProvider>
  );
}


================================================
FILE: frontend/src/components/onboarding/hunter/CompanyDetailsStep.tsx
================================================
'use client';

import * as React from 'react';
import { Card, CardContent } from '@/components/ui/card';
import { Button } from '@/components/ui/button';
import { Star15 } from '@/components/ui/star';
import { Tooltip, TooltipContent, TooltipTrigger } from '@/components/ui/tooltip';
import { 
  UilArrowRight,
  UilArrowLeft,
  UilInfoCircle
} from '@tooni/iconscout-unicons-react';
import { StepProps } from './types';

export function CompanyDetailsStep({
  searchCriteria,
  setSearchCriteria,
  toggleJobTitle,
  setCurrentStep,
  jobTitles
}: StepProps) {
  return (
    <Card className="transform -rotate-1 relative overflow-hidden">
      <CardContent className="p-8">
        <div className="text-center mb-8">
          <h1 className="text-4xl md:text-5xl font-black uppercase text-black">
            COMPANY DETAILS
          </h1>
        </div>
        <p className="text-xl text-center text-gray-700 mb-8">
          Narrow down your ideal prospect profile
        </p>
        <div className="space-y-6">
          {/* Company Size */}
          <div>
            <div className="flex items-center gap-2 mb-3">
              <label className="text-xl font-black uppercase block">
                COMPANY SIZE <span className="text-sm font-normal">(OPTIONAL)</span>
              </label>
              <Tooltip>
                <TooltipTrigger asChild>
                  <button className="p-0 bg-transparent border-none outline-none">
                    <UilInfoCircle className="h-4 w-4 text-gray-500 hover:text-black cursor-help" />
                  </button>
                </TooltipTrigger>
                <TooltipContent side="top">
                  <p>Filter companies by employee count. Smaller companies are often more accessible, larger ones have bigger budgets.</p>
                </TooltipContent>
              </Tooltip>
            </div>
            <div className="grid grid-cols-2 md:grid-cols-3 gap-3">
              {['1-10', '11-50', '51-100', '101-500', '501-1000', '1000+'].map((size) => (
                <Button
                  key={size}
                  variant={searchCriteria.companySize === size ? "header" : "outline"}
                  className={`h-12 font-bold border-2 border-black relative ${
                    searchCriteria.companySize === size ? 'bg-yellow-400' : 'bg-white hover:bg-violet-100'
                  }`}
                  onClick={() => setSearchCriteria({...searchCriteria, companySize: size})}
                >
                  {searchCriteria.companySize === size && (
                    <div className="absolute -top-4 -right-4 z-[100]" style={{animation: 'overshoot 0.3s ease-out'}}>
                      <div className="relative">
                        <div className="animate-spin" style={{animationDuration: '15s', animationDelay: '0.3s'}}>
                          <Star15 color="#FFD700" size={40} className="w-10 h-10" stroke="black" strokeWidth={4} />
                        </div>
                      </div>
                    </div>
                  )}
                  {size}
                </Button>
              ))}
            </div>
          </div>

          {/* Job Titles */}
          <div>
            <div className="flex items-center gap-2 mb-3">
              <label className="text-xl font-black uppercase block">
                TARGET JOB TITLES <span className="text-sm font-normal">(OPTIONAL)</span>
              </label>
              <Tooltip>
                <TooltipTrigger asChild>
                  <button className="p-0 bg-transparent border-none outline-none">
                    <UilInfoCircle className="h-4 w-4 text-gray-500 hover:text-black cursor-help" />
                  </button>
                </TooltipTrigger>
                <TooltipContent side="top">
                  <p>Target specific job roles. Select multiple titles to cast a wider net. AI will find similar roles automatically.</p>
                </TooltipContent>
              </Tooltip>
            </div>
            <div className="grid grid-cols-2 md:grid-cols-4 gap-3">
              {jobTitles.map((title) => (
                <Button
                  key={title}
                  variant="subheader"
                  className={`h-12 font-bold border-2 border-black relative ${
                     searchCriteria.jobTitles.includes(title) 
                      ? 'bg-yellow-400' 
                      : 'bg-white hover:bg-violet-50'                  }`}
                  onClick={() => toggleJobTitle(title)}
                >
                  {searchCriteria.jobTitles.includes(title) && (
                    <div className="absolute -top-4 -right-4 z-[100]" style={{animation: 'overshoot 0.3s ease-out'}}>
                      <div className="relative">
                        <div className="animate-spin" style={{animationDuration: '15s', animationDelay: '0.3s'}}>
                          <Star15 color="#FFD700" size={40} className="w-10 h-10" stroke="black" strokeWidth={4} />
                        </div>
                      </div>
                    </div>
                  )}
                  {title}
                </Button>
              ))}
            </div>
          </div>

          <div className="bg-violet-50 border-2 border-black rounded-lg p-4">
            <div className="flex items-start gap-3">
              <Button size="sm" variant="neutral" className="bg-white flex-shrink-0">
                <span className="text-violet-600 font-black">2</span>
              </Button>
              <div>
                <p className="text-sm font-bold">STEP 2 OF 3</p>
                <p className="text-sm text-gray-700 mt-1">
                  Both fields are optional. Skip if you want to cast a wide net or be specific to target exact decision-makers.
                </p>
              </div>
            </div>
          </div>

          <div className="flex gap-4">
            <Button
              className="flex-1 h-14 text-lg font-black uppercase bg-gray-300 hover:bg-gray-400 text-black"
              onClick={() => setCurrentStep(2)}
            >
              <UilArrowLeft className="mr-2 h-6 w-6" />
              BACK
            </Button>
            <Button
              className="flex-1 h-14 text-lg font-black uppercase bg-yellow-400 hover:bg-yellow-400/90 text-black"
              onClick={() => setCurrentStep(2.75)}
            >
              CONTINUE
              <UilArrowRight className="ml-2 h-6 w-6" />
            </Button>
          </div>
        </div>
      </CardContent>
    </Card>
  );
}


================================================
FILE: frontend/src/components/onboarding/hunter/ContactPreferencesStep.tsx
================================================
'use client';

import * as React from 'react';
import { Card, CardContent } from '@/components/ui/card';
import { Button } from '@/components/ui/button';
import { Switch } from '@/components/ui/switch';
import { 
  UilArrowRight,
  UilArrowLeft,
  UilEnvelope,
  UilPhone
} from '@tooni/iconscout-unicons-react';
import { StepProps } from './types';
import PremiumFeatureCard from '@/components/custom/premium-feature-card';

export function ContactPreferencesStep({
  contactPreferences,
  setContactPreferences,
  setCurrentStep
}: StepProps) {
  return (
    <Card className="transform -rotate-1 relative overflow-hidden">
      <CardContent className="p-8">
        <div className="text-center mb-8">
          <h1 className="text-4xl md:text-5xl font-black uppercase text-black">
            CONTACT PREFERENCES
          </h1>
        </div>
        <p className="text-xl text-center text-gray-700 mb-8">
          Select what contact information to include
        </p>
        <div className="space-y-6">
          <Card className="border-2 border-black bg-violet-50">
            <CardContent className="p-6">
              <div className="flex items-center justify-between">
                <div className="flex items-center gap-4">
                  <Button size="icon" variant="header" className="w-12 h-12 bg-blue-500">
                    <UilEnvelope className="h-6 w-6 text-white" />
                  </Button>
                  <div>
                    <h3 className="text-lg font-black uppercase">EMAIL ADDRESSES</h3>
                    <p className="text-sm text-gray-600">Include verified business emails</p>
                  </div>
                </div>
                <Switch
                  checked={contactPreferences.includeEmails}
                  onCheckedChange={(checked) => 
                    setContactPreferences({...contactPreferences, includeEmails: checked})
                  }
                />
              </div>
            </CardContent>
          </Card>

          <Card className="border-2 border-black bg-violet-50">
            <CardContent className="p-6">
              <div className="flex items-center justify-between">
                <div className="flex items-center gap-4">
                  <Button size="icon" variant="header" className="w-12 h-12 bg-green-500">
                    <UilPhone className="h-6 w-6 text-white" />
                  </Button>
                  <div>
                    <h3 className="text-lg font-black uppercase">PHONE NUMBERS</h3>
                    <p className="text-sm text-gray-600">Include direct dial and mobile numbers</p>
                  </div>
                </div>
                <Switch
                  checked={contactPreferences.includePhones}
                  onCheckedChange={(checked) => 
                    setContactPreferences({...contactPreferences, includePhones: checked})
                  }
                />
              </div>
            </CardContent>
          </Card>

          <PremiumFeatureCard
            title="LINKEDIN INTEGRATION"
            description="Access LinkedIn profiles and advanced social selling features"
            features={[
              'LinkedIn profile URLs and data',
              'Connection degree insights',
              'Recent LinkedIn activity',
              'Shared connections',
              'InMail credits included'
            ]}
            currentPlan="basic"
          />

          <PremiumFeatureCard
            title="ADVANCED ENRICHMENT"
            description="Get even more valuable data about your leads"
            features={[
              'Email verification and deliverability checks',
              'Social media profiles (Twitter, Facebook)',
              'Personal mobile numbers',
              'Technology stack used by company',
              'Recent news and triggers',
              'Buying intent signals'
            ]}
            currentPlan="basic"
          />

          <div className="flex gap-4">
            <Button
              className="flex-1 h-14 text-lg font-black uppercase bg-gray-300 hover:bg-gray-400 text-black"
              onClick={() => setCurrentStep(2.75)}
            >
              <UilArrowLeft className="mr-2 h-6 w-6" />
              BACK
            </Button>
            <Button
              className="flex-1 h-14 text-lg font-black uppercase bg-yellow-400 hover:bg-yellow-400/90 text-black"
              onClick={() => setCurrentStep(3.5)}
            >
              CONTINUE
              <UilArrowRight className="ml-2 h-6 w-6" />
            </Button>
          </div>
        </div>
      </CardContent>
    </Card>
  );
}


================================================
FILE: frontend/src/components/onboarding/hunter/IndustryLocationStep.tsx
================================================
'use client';

import * as React from 'react';
import { Card, CardContent } from '@/components/ui/card';
import { Button } from '@/components/ui/button';
import { Input } from '@/components/ui/input';
import { Star15 } from '@/components/ui/star';
import { 
  UilArrowRight,
  UilArrowLeft
} from '@tooni/iconscout-unicons-react';
import { StepProps } from './types';

export function IndustryLocationStep({
  searchCriteria,
  setSearchCriteria,
  customIndustry,
  setCustomIndustry,
  setCurrentStep,
  industries
}: StepProps) {
  return (
    <Card className="transform rotate-1 relative overflow-hidden">
      <CardContent className="p-8">
        <div className="text-center mb-8">
          <h1 className="text-4xl md:text-5xl font-black uppercase text-black">
            INDUSTRY & LOCATION
          </h1>
        </div>
        <p className="text-xl text-center text-gray-700 mb-8">
          Define your target market and geographic focus
        </p>
        <div className="space-y-6">
          {/* Industry Selection */}
          <div>
            <label className="text-xl font-black uppercase mb-3 block">
              TARGET INDUSTRY
            </label>
            <div className="grid grid-cols-2 md:grid-cols-3 gap-3 mb-3">
              {industries.map((industry) => (
                <Button
                  key={industry}
                  variant={searchCriteria.industry === industry || (industry === 'Other' && searchCriteria.industry === customIndustry) ? "header" : "default"}
                  className={`h-12 font-bold border-2 border-black relative ${
                     searchCriteria.industry === industry || (industry === 'Other' && searchCriteria.industry === customIndustry) 
                      ? 'bg-yellow-400' 
                      : 'bg-white hover:bg-violet-100'                  }`}
                  onClick={() => {
                    if (industry === 'Other') {
                      setSearchCriteria({...searchCriteria, industry: customIndustry || 'Other'});
                    } else {
                      setSearchCriteria({...searchCriteria, industry});
                      setCustomIndustry('');
                    }
                  }}
                >
                  {(searchCriteria.industry === industry || (industry === 'Other' && searchCriteria.industry === customIndustry)) && (
                    <div className="absolute -top-4 -right-4 z-[100]" style={{animation: 'overshoot 0.3s ease-out'}}>
                      <div className="relative">
                        <div className="animate-spin" style={{animationDuration: '15s', animationDelay: '0.3s'}}>
                          <Star15 color="#FFD700" size={40} className="w-10 h-10" stroke="black" strokeWidth={4} />
                        </div>
                      </div>
                    </div>
                  )}
                  {industry}
                </Button>
              ))}
            </div>
            {/* Custom Industry Input */}
            {(searchCriteria.industry === 'Other' || searchCriteria.industry === customIndustry) && (
              <Input
                type="text"
                value={customIndustry}
                onChange={(e) => {
                  setCustomIndustry(e.target.value);
                  setSearchCriteria({...searchCriteria, industry: e.target.value || 'Other'});
                }}
                placeholder="Enter custom industry..."
                className="h-12 text-lg font-semibold border-4 border-black rounded-[3px]"
              />
            )}
          </div>

          {/* Location */}
          <div>
            <label className="text-xl font-black uppercase mb-3 block">
              TARGET LOCATION
            </label>
            <Input
              type="text"
              value={searchCriteria.location}
              onChange={(e) => setSearchCriteria({...searchCriteria, location: e.target.value})}
              placeholder="e.g., United States, California, San Francisco"
              className={`h-14 text-lg font-semibold border-4 border-black rounded-[3px] ${
                searchCriteria.location && searchCriteria.location.toLowerCase() === searchCriteria.industry.toLowerCase() 
                  ? 'border-red-500' 
                  : ''
              }`}
            />
            {searchCriteria.location && searchCriteria.location.toLowerCase() === searchCriteria.industry.toLowerCase() && (
              <p className="text-red-500 text-sm mt-2 font-bold">
                Location must be a geographic location, not the same as industry
              </p>
            )}
          </div>

          <div className="bg-violet-50 border-2 border-black rounded-lg p-4">
            <div className="flex items-start gap-3">
              <Button size="sm" variant="neutral" className="bg-white flex-shrink-0">
                <span className="text-violet-600 font-black">1</span>
              </Button>
              <div>
                <p className="text-sm font-bold">STEP 1 OF 3</p>
                <p className="text-sm text-gray-700 mt-1">
                  Start with broad targeting - we&apos;ll help you narrow down to specific companies and contacts in the next steps.
                </p>
              </div>
            </div>
          </div>

          <div className="flex gap-4">
            <Button
              className="flex-1 h-14 text-lg font-black uppercase bg-gray-300 hover:bg-gray-400 text-black"
              onClick={() => setCurrentStep(1)}
            >
              <UilArrowLeft className="mr-2 h-6 w-6" />
              BACK
            </Button>
            <Button
              className="flex-1 h-14 text-lg font-black uppercase bg-yellow-400 hover:bg-yellow-400/90 text-black"
              onClick={() => setCurrentStep(2.5)}
              disabled={!searchCriteria.industry || !searchCriteria.location}
            >
              CONTINUE
              <UilArrowRight className="ml-2 h-6 w-6" />
            </Button>
          </div>
        </div>
      </CardContent>
    </Card>
  );
}


================================================
FILE: frontend/src/components/onboarding/hunter/SearchDefinitionStep.tsx
================================================
'use client';

import * as React from 'react';
import { Card, CardContent } from '@/components/ui/card';
import { Button } from '@/components/ui/button';
import { Input } from '@/components/ui/input';
import { Badge } from '@/components/ui/badge';
import { Textarea } from '@/components/ui/textarea';
import { Star15 } from '@/components/ui/star';
import { 
  UilArrowRight,
  UilInfoCircle,
  UilSearch,
  UilDatabase,
  UilChartGrowth,
  UilGlobe,
  UilBuilding
} from '@tooni/iconscout-unicons-react';
import { StepProps } from './types';
import PremiumFeatureCard from '@/components/custom/premium-feature-card';

export function SearchDefinitionStep({
  searchName,
  setSearchName,
  searchObjective,
  setSearchObjective,
  selectedSources,
  handleSourceSelect,
  setCurrentStep,
  userUsageStats,
  leadSources
}: StepProps) {
  return (
    <Card className="transform rotate-1 relative overflow-hidden">
      <CardContent className="p-8">
        <div className="space-y-6">
          {/* Info Section */}
          <Card className="bg-violet-50 border-2 border-black">
            <CardContent className="p-6">
              <h3 className="text-2xl font-black uppercase mb-3">INTELLIGENT LEAD HUNTER</h3>
              <p className="text-lg text-gray-700 mb-4">
                Hunter combines powerful search capabilities with automated outreach to find and contact your perfect customers.
              </p>
              <div className="grid grid-cols-1 md:grid-cols-2 gap-3">
                <div className="flex items-center gap-2">
                  <div className="w-2 h-2 bg-violet-600 rounded-full"></div>
                  <span className="font-medium">Multi-source search</span>
                </div>
                <div className="flex items-center gap-2">
                  <div className="w-2 h-2 bg-violet-600 rounded-full"></div>
                  <span className="font-medium">Smart filtering</span>
                </div>
                <div className="flex items-center gap-2">
                  <div className="w-2 h-2 bg-violet-600 rounded-full"></div>
                  <span className="font-medium">Automated outreach</span>
                </div>
                <div className="flex items-center gap-2">
                  <div className="w-2 h-2 bg-violet-600 rounded-full"></div>
                  <span className="font-medium">Real-time enrichment</span>
                </div>
              </div>
            </CardContent>
          </Card>

          <div>
            <label className="text-xl font-black uppercase mb-3 block">
              SEARCH NAME
            </label>
            <Input
              type="text"
              value={searchName}
              onChange={(e) => setSearchName(e.target.value)}
              placeholder="e.g., Q4 Enterprise Outreach"
              className="h-16 text-lg font-semibold border-4 border-black rounded-[3px]"
            />
          </div>
          
          <div>
            <label className="text-xl font-black uppercase mb-3 block">
              SEARCH OBJECTIVE
            </label>
            <Textarea
              value={searchObjective}
              onChange={(e) => setSearchObjective(e.target.value)}
              placeholder="What type of leads are you looking for? What's your ideal customer profile?"
              className="min-h-[120px] text-lg font-semibold border-4 border-black rounded-[3px] resize-none"
            />
          </div>
          
          {/* Lead Sources */}
          <div>
            <label className="text-xl font-black uppercase mb-3 block">
              SELECT LEAD SOURCES
            </label>
            <div className="grid grid-cols-1 md:grid-cols-3 gap-4">
              {leadSources.map((source) => {
                const isLocked = source.id === 'database' || source.id === 'directory';
                return (
                  <Card 
                    key={source.id}
                    className={`transform transition-all border-4 border-black relative ${
                      isLocked 
                        ? 'bg-gray-100 opacity-75 cursor-not-allowed' 
                        : `cursor-pointer hover:scale-105 ${
                            selectedSources.includes(source.id) 
                              ? 'shadow-[8px_8px_0_rgba(0,0,0,1)] z-10 bg-yellow-400'
                              : 'bg-violet-50'
                          }`
                    }`}
                    onClick={() => !isLocked && handleSourceSelect(source.id)}
                  >
                    {!isLocked && selectedSources.includes(source.id) && (
                      <div className="absolute -top-8 -right-8 sm:-top-12 sm:-right-12 md:-top-16 md:-right-16 z-[100]" style={{animation: 'overshoot 0.3s ease-out'}}>
                        <div className="relative">
                          <div className="animate-spin" style={{animationDuration: '15s', animationDelay: '0.3s'}}>
                            <Star15 color="#FFD700" size={80} className="w-20 h-20 sm:w-24 sm:h-24 md:w-[120px] md:h-[120px]" stroke="black" strokeWidth={8} />
                          </div>
                          <div className="absolute inset-0 flex items-center justify-center">
                            <span className="text-black font-black text-[10px] sm:text-xs uppercase tracking-wider transform rotate-12" style={{ fontFamily: 'Noyh-Bold, sans-serif' }}>
                              SELECTED
                            </span>
                          </div>
                        </div>
                      </div>
                    )}
                    <CardContent className="p-6 text-center relative">
                      {isLocked && (
                        <Badge className="absolute top-2 right-2 bg-yellow-200 text-black border-2 border-black">
                          LOCKED
                        </Badge>
                      )}
                      <div className={`inline-flex items-center justify-center w-16 h-16 rounded-full mb-3 ${
                        isLocked 
                          ? 'bg-gray-400'
                          : selectedSources.includes(source.id) ? 'bg-yellow-400' : source.color
                      }`}>
                        {React.cloneElement(source.icon, { 
                          className: `h-8 w-8 ${
                            isLocked 
                              ? 'text-white'
                              : selectedSources.includes(source.id) ? 'text-black' : 'text-white'
                          }` 
                        })}
                      </div>
                      <h3 className="text-lg font-black uppercase mb-1">{source.name}</h3>
                      <p className="text-sm">{isLocked ? 'Premium feature' : source.description}</p>
                    </CardContent>
                  </Card>
                );
              })}
            </div>
          </div>
          
          {/* Usage Stats Display */}
          {userUsageStats && (
            <Card className="bg-violet-50 border-2 border-black">
              <CardContent className="p-4">
                <div className="flex items-center justify-between mb-3">
                  <h4 className="font-black uppercase text-sm">Your Usage Today</h4>
                  <Badge className={`border-2 border-black ${
                    userUsageStats.subscription?.tier === 'free' ? 'bg-gray-200' :
                    userUsageStats.subscription?.tier === 'premium' ? 'bg-yellow-200' : 'bg-purple-200'
                  } text-black`}>
                    {userUsageStats.subscription?.tier?.toUpperCase()} PLAN
                  </Badge>
                </div>
                <div className="grid grid-cols-2 gap-4 text-sm">
                  <div>
                    <p className="font-bold">Searches Today</p>
                    <p className="text-violet-600">
                      {userUsageStats.usage.searchesToday} / {
                        userUsageStats.usage.searchesRemaining === -1 
                          ? '∞' 
                          : userUsageStats.subscription?.searchesPerDay
                      }
                    </p>
                  </div>
                  <div>
                    <p className="font-bold">Leads This Month</p>
                    <p className="text-violet-600">
                      {userUsageStats.usage.leadsThisMonth} / {
                        userUsageStats.usage.leadsRemaining === -1 
                          ? '∞' 
                          : userUsageStats.subscription?.totalLeadsPerMonth
                      }
                    </p>
                  </div>
                </div>
              </CardContent>
            </Card>
          )}

          <div className="bg-violet-50 border-2 border-black rounded-lg p-4">
            <div className="flex items-start gap-3">
              <Button size="sm" variant="neutral" className="bg-white flex-shrink-0">
                <UilInfoCircle className="h-4 w-4" />
              </Button>
              <div>
                <p className="text-sm font-bold">PRO TIP</p>
                <p className="text-sm text-gray-700 mt-1">
                  Using multiple sources increases lead quality and quantity. We&apos;ll cross-reference data for accuracy.
                </p>
              </div>
            </div>
          </div>
          
          <Button
            className="w-full h-14 text-lg font-black uppercase bg-yellow-400 hover:bg-yellow-400/90 text-black"
            onClick={() => {
              // Check if user has remaining searches
              if (userUsageStats?.usage.searchesRemaining === 0) {
                alert('You have reached your daily search limit. Please upgrade your plan to continue.');
                return;
              }
              setCurrentStep(2);
            }}
            disabled={!searchName || !searchObjective || selectedSources.length === 0}
          >
            CONTINUE
            <UilArrowRight className="ml-2 h-6 w-6" />
          </Button>
        </div>
      </CardContent>
    </Card>
  );
}

/* Bottom Info Sections - Can be imported separately or included */
export function SearchDefinitionInfoSections() {
  return (
    <div className="mt-12 max-w-4xl mx-auto px-4 sm:px-6 space-y-6">
      <Card className="transform -rotate-1 relative overflow-hidden bg-violet-50">
        <CardContent className="relative pt-6">
          <div className="flex items-start gap-4">
            <Button
              size="icon"
              variant="default"
              className="w-12 h-12 flex-shrink-0 bg-violet-600 hover:bg-violet-700 text-white border-black"
            >
              <UilSearch className="h-6 w-6 text-white" />
            </Button>
            <div className="flex-1">
              <h3 className="text-2xl font-black text-black mb-3 uppercase" style={{ fontFamily: 'Noyh-Bold, sans-serif' }}>
                LEAD GENERATION POWERHOUSE
              </h3>
              <p className="text-gray-700 mb-6 text-lg leading-relaxed">
                Hunter finds <span className="font-black text-violet-600">10x more qualified leads</span> than traditional methods by searching 
                across web directories, business listings, and B2B databases simultaneously. Our AI-powered enrichment ensures every lead comes with 
                verified contact information and detailed insights.
              </p>
              <div className="grid grid-cols-1 md:grid-cols-2 gap-4">
                <div className="flex items-center gap-3">
                  <div className="w-2 h-2 bg-violet-600 rounded-full"></div>
                  <span className="text-black font-medium">Cross-platform lead search</span>
                </div>
                <div className="flex items-center gap-3">
                  <div className="w-2 h-2 bg-violet-600 rounded-full"></div>
                  <span className="text-black font-medium">Real-time data enrichment</span>
                </div>
                <div className="flex items-center gap-3">
                  <div className="w-2 h-2 bg-violet-600 rounded-full"></div>
                  <span className="text-black font-medium">Email verification included</span>
                </div>
                <div className="flex items-center gap-3">
                  <div className="w-2 h-2 bg-violet-600 rounded-full"></div>
                  <span className="text-black font-medium">Direct dial numbers</span>
                </div>
              </div>
            </div>
          </div>
        </CardContent>
      </Card>

      <Card className="transform rotate-1 relative overflow-hidden bg-violet-50">
        <CardContent className="pt-6">
          <div className="flex items-start gap-4">
            <Button
              size="icon"
              variant="default"
              className="w-12 h-12 flex-shrink-0 bg-yellow-400 hover:bg-yellow-400/90 text-black"
            >
              <UilDatabase className="h-6 w-6 text-black" />
            </Button>
            <div className="flex-1">
              <h3 className="text-xl font-black text-black mb-3 uppercase" style={{ fontFamily: 'Noyh-Bold, sans-serif' }}>
                DATA ACCURACY GUARANTEE
              </h3>
              <p className="text-gray-700 text-lg leading-relaxed">
                Every lead is <span className="font-black text-violet-600">triple-verified</span> across multiple data sources. 
                Our proprietary matching algorithm ensures 95%+ accuracy on contact information, while continuous updates keep your 
                lead data fresh and actionable.
              </p>
            </div>
          </div>
        </CardContent>
      </Card>

      <PremiumFeatureCard
        title="ADVANCED SEARCH FILTERS"
        description="Unlock powerful filtering options to find exactly who you need"
        features={[
          'Technographic data (tech stack used)',
          'Funding and revenue filters',
          'Intent data and buying signals',
          'Social media activity level',
          'Custom boolean search queries'
        ]}
        currentPlan="basic"
      />
    </div>
  );
}


================================================
FILE: frontend/src/components/onboarding/hunter/SearchKeywordsStep.tsx
================================================
'use client';

import * as React from 'react';
import { Card, CardContent } from '@/components/ui/card';
import { Button } from '@/components/ui/button';
import { Input } from '@/components/ui/input';
import { Tooltip, TooltipContent, TooltipTrigger } from '@/components/ui/tooltip';
import { 
  UilArrowRight,
  UilArrowLeft,
  UilInfoCircle,
  UilSearch
} from '@tooni/iconscout-unicons-react';
import { StepProps } from './types';

export function SearchKeywordsStep({
  searchCriteria,
  setSearchCriteria,
  setCurrentStep
}: StepProps) {
  return (
    <Card className="transform rotate-1 relative overflow-hidden">
      <CardContent className="p-8">
        <div className="text-center mb-8">
          <h1 className="text-4xl md:text-5xl font-black uppercase text-black">
            SEARCH KEYWORDS
          </h1>
        </div>
        <p className="text-xl text-center text-gray-700 mb-8">
          Fine-tune your search with specific keywords
        </p>
        <div className="space-y-6">
          {/* Keywords */}
          <div>
            <div className="flex items-center gap-2 mb-3">
              <label className="text-xl font-black uppercase block">
                SEARCH KEYWORDS <span className="text-sm font-normal">(OPTIONAL)</span>
              </label>
              <Tooltip>
                <TooltipTrigger asChild>
                  <button className="p-0 bg-transparent border-none outline-none">
                    <UilInfoCircle className="h-4 w-4 text-gray-500 hover:text-black cursor-help" />
                  </button>
                </TooltipTrigger>
                <TooltipContent side="top">
                  <p>Add keywords to refine your search. Use commas to separate multiple terms. Example: &quot;SaaS, B2B, startup&quot;</p>
                </TooltipContent>
              </Tooltip>
            </div>
            <Input
              type="text"
              value={searchCriteria.keywords}
              onChange={(e) => setSearchCriteria({...searchCriteria, keywords: e.target.value})}
              placeholder="e.g., SaaS, B2B, Enterprise, Cloud, API, Integration"
              className="h-14 text-lg font-semibold border-4 border-black rounded-[3px]"
            />
          </div>

          {/* Info about keywords */}
          <Card className="bg-violet-50 border-2 border-black">
            <CardContent className="p-6">
              <div className="flex items-start gap-4">
                <Button
                  size="icon"
                  variant="default"
                  className="w-12 h-12 flex-shrink-0 bg-violet-600 hover:bg-violet-700 text-white border-black"
                >
                  <UilSearch className="h-6 w-6 text-white" />
                </Button>
                <div className="flex-1">
                  <h3 className="text-lg font-black text-black mb-3 uppercase">
                    SMART KEYWORD MATCHING
                  </h3>
                  <p className="text-gray-700 text-sm leading-relaxed mb-4">
                    Our AI will search for these keywords on company websites, social profiles, and business listings. 
                    The more specific your keywords, the more targeted your results.
                  </p>
                  <div className="grid grid-cols-1 md:grid-cols-2 gap-2">
                    <div className="flex items-center gap-2">
                      <div className="w-2 h-2 bg-violet-600 rounded-full"></div>
                      <span className="text-black text-xs font-medium">Technology stack keywords</span>
                    </div>
                    <div className="flex items-center gap-2">
                      <div className="w-2 h-2 bg-violet-600 rounded-full"></div>
                      <span className="text-black text-xs font-medium">Business model terms</span>
                    </div>
                    <div className="flex items-center gap-2">
                      <div className="w-2 h-2 bg-violet-600 rounded-full"></div>
                      <span className="text-black text-xs font-medium">Service offerings</span>
                    </div>
                    <div className="flex items-center gap-2">
                      <div className="w-2 h-2 bg-violet-600 rounded-full"></div>
                      <span className="text-black text-xs font-medium">Industry-specific terms</span>
                    </div>
                  </div>
                </div>
              </div>
            </CardContent>
          </Card>

          <div className="bg-violet-50 border-2 border-black rounded-lg p-4">
            <div className="flex items-start gap-3">
              <Button size="sm" variant="neutral" className="bg-white flex-shrink-0">
                <span className="text-violet-600 font-black">3</span>
              </Button>
              <div>
                <p className="text-sm font-bold">FINAL STEP</p>
                <p className="text-sm text-gray-700 mt-1">
                  Keywords help narrow your search but are completely optional. Leave blank to find all companies in your target industry and location.
                </p>
              </div>
            </div>
          </div>

          <div className="flex gap-4">
            <Button
              className="flex-1 h-14 text-lg font-black uppercase bg-gray-300 hover:bg-gray-400 text-black"
              onClick={() => setCurrentStep(2.5)}
            >
              <UilArrowLeft className="mr-2 h-6 w-6" />
              BACK
            </Button>
            <Button
              className="flex-1 h-14 text-lg font-black uppercase bg-yellow-400 hover:bg-yellow-400/90 text-black"
              onClick={() => setCurrentStep(3)}
            >
              CONTINUE
              <UilArrowRight className="ml-2 h-6 w-6" />
            </Button>
          </div>
        </div>
      </CardContent>
    </Card>
  );
}


================================================
FILE: frontend/src/components/onboarding/hunter/SearchPreviewStep.tsx
================================================
'use client';

import * as React from 'react';
import { Card, CardContent } from '@/components/ui/card';
import PremiumFeatureCard from '@/components/custom/premium-feature-card';
import { Button } from '@/components/ui/button';
import { Badge } from '@/components/ui/badge';
import { 
  UilArrowLeft,
  UilSearch,
  UilInfoCircle,
  UilClipboardNotes,
  UilChartGrowth
} from '@tooni/iconscout-unicons-react';
import { StepProps } from './types';

export function SearchPreviewStep({
  searchName,
  searchObjective,
  searchCriteria,
  customIndustry,
  selectedSources,
  canStartSearch,
  startSearch,
  setCurrentStep,
  userUsageStats
}: StepProps) {
  return (
    <Card className="transform rotate-1 relative overflow-hidden">
      <CardContent className="p-8">
        <div className="text-center mb-8">
          <h1 className="text-4xl md:text-5xl font-black uppercase text-black">
            READY TO HUNT
          </h1>
        </div>
        <div className="space-y-6">
          <Card className="bg-violet-100 border-4 border-black shadow-[6px_6px_0_rgba(0,0,0,1)]">
            <CardContent className="p-6">
              <h3 className="text-2xl font-black uppercase mb-6 flex items-center gap-3">
                <UilClipboardNotes className="h-6 w-6" />
                SEARCH SUMMARY
              </h3>
              <div className="space-y-4">
                <div className="bg-white border-2 border-black rounded-lg p-3">
                  <p className="text-xs font-black uppercase text-gray-600 mb-1">SEARCH NAME</p>
                  <p className="font-bold text-lg">{searchName}</p>
                </div>
                <div className="bg-white border-2 border-black rounded-lg p-3">
                  <p className="text-xs font-black uppercase text-gray-600 mb-1">OBJECTIVE</p>
                  <p className="font-semibold">{searchObjective}</p>
                </div>
                <div className="grid grid-cols-2 gap-3">
                  <div className="bg-white border-2 border-black rounded-lg p-3">
                    <p className="text-xs font-black uppercase text-gray-600 mb-1">INDUSTRY</p>
                    <p className="font-bold">{searchCriteria.industry === 'Other' ? customIndustry : searchCriteria.industry}</p>
                  </div>
                  <div className="bg-white border-2 border-black rounded-lg p-3">
                    <p className="text-xs font-black uppercase text-gray-600 mb-1">LOCATION</p>
                    <p className="font-bold">{searchCriteria.location}</p>
                  </div>
                </div>
                {searchCriteria.companySize && (
                  <div className="bg-white border-2 border-black rounded-lg p-3">
                    <p className="text-xs font-black uppercase text-gray-600 mb-1">COMPANY SIZE</p>
                    <p className="font-bold">{searchCriteria.companySize} employees</p>
                  </div>
                )}
                {searchCriteria.jobTitles.length > 0 && (
                  <div className="bg-white border-2 border-black rounded-lg p-3">
                    <p className="text-xs font-black uppercase text-gray-600 mb-1">TARGET ROLES</p>
                    <div className="flex flex-wrap gap-2 mt-2">
                      {searchCriteria.jobTitles.map((title) => (
                        <Badge key={title} className="bg-violet-200 text-black border-2 border-black">
                          {title}
                        </Badge>
                      ))}
                    </div>
                  </div>
                )}
                <div className="bg-white border-2 border-black rounded-lg p-3">
                  <p className="text-xs font-black uppercase text-gray-600 mb-1">LEAD SOURCES</p>
                  <div className="flex flex-wrap gap-2 mt-2">
                    {selectedSources.map((source) => (
                      <Badge key={source} className="bg-green-200 text-black border-2 border-black">
                        {source.toUpperCase()}
                      </Badge>
                    ))}
                  </div>
                </div>
              </div>
            </CardContent>
          </Card>

          <Card className="bg-violet-100 border-2 border-black shadow-[6px_6px_0_rgba(0,0,0,1)] transform -rotate-1">
            <CardContent className="p-6 text-center">
              <UilChartGrowth className="h-12 w-12 mx-auto mb-3 text-violet-600" />
              <h3 className="text-2xl font-black uppercase mb-2">ESTIMATED RESULTS</h3>
              <p className="text-4xl font-black text-violet-600 mb-2">30</p>
              <p className="text-lg font-medium">QUALIFIED LEADS</p>
            </CardContent>
          </Card>

          <PremiumFeatureCard
            title="PREMIUM PLAN"
            description="Get 10,000 qualified leads per month with unlimited searches and 10x lead generation"
            price="$100/month"
            badge="PREMIUM"
            className="transform rotate-2"
          />

          <div className="bg-violet-50 border-2 border-black rounded-lg p-4">
            <div className="flex items-start gap-3">
              <Button size="sm" variant="neutral" className="bg-white flex-shrink-0">
                <UilInfoCircle className="h-4 w-4" />
              </Button>
              <div>
                <p className="text-sm font-bold">WHAT HAPPENS NEXT</p>
                <p className="text-sm text-gray-700 mt-1">
                  We&apos;ll search across all selected sources, verify contact information, and compile your lead list. 
                  This typically takes 3-5 minutes depending on search complexity.
                </p>
              </div>
            </div>
          </div>

          <div className="flex gap-4">
            <Button
              className="flex-1 h-14 text-lg font-black uppercase bg-gray-300 hover:bg-gray-400 text-black"
              onClick={() => setCurrentStep(3.5)}
            >
              <UilArrowLeft className="mr-2 h-6 w-6" />
              BACK
            </Button>
            <Button
              className="flex-1 h-14 text-lg font-black uppercase bg-yellow-400 hover:bg-yellow-400/90 text-black"
              onClick={() => {
                // Check limits before starting search
                if (userUsageStats?.usage.searchesRemaining === 0) {
                  alert('You have reached your daily search limit. Please upgrade your plan to continue.');
                  return;
                }
                if (userUsageStats?.usage.leadsRemaining === 0) {
                  alert('You have reached your monthly lead limit. Please upgrade your plan to continue.');
                  return;
                }
                startSearch();
              }}
              disabled={!canStartSearch()}
            >
              START HUNTING
              <UilSearch className="ml-2 h-6 w-6" />
            </Button>
          </div>
        </div>
      </CardContent>
    </Card>
  );
}


================================================
FILE: frontend/src/components/onboarding/hunter/SearchProgressStep.tsx
================================================
'use client';

import * as React from 'react';
import { Card, CardContent } from '@/components/ui/card';
import { 
  UilSearch,
  UilBuilding,
  UilGlobe,
  UilDatabase
} from '@tooni/iconscout-unicons-react';
import { StepProps } from './types';
import PremiumFeatureCard from '@/components/custom/premium-feature-card';

export function SearchProgressStep({
  currentStatus,
  searchProgress
}: StepProps) {
  return (
    <Card className="transform -rotate-1 relative overflow-hidden">
      <CardContent className="p-8">
        <div className="text-center mb-8">
          <h1 className="text-4xl md:text-5xl font-black uppercase text-black">
            HUNTING IN PROGRESS
          </h1>
        </div>
        <div className="space-y-6">
          <div className="text-center mb-8">
            <div className="inline-flex items-center justify-center w-24 h-24 bg-violet-400 border-4 border-black rounded-full mb-4">
              <UilSearch className="h-12 w-12 text-black animate-pulse" />
            </div>
            <p className="text-xl font-bold text-gray-700">{currentStatus}</p>
          </div>

          <div className="space-y-2">
            <div className="flex justify-between text-sm font-bold">
              <span>PROGRESS</span>
              <span>{searchProgress}%</span>
            </div>
            <div className="w-full bg-gray-200 rounded-full h-6 border-2 border-black overflow-hidden">
              <div
                className="bg-violet-400 h-full transition-all duration-500"
                style={{ width: `${searchProgress}%` }}
              />
            </div>
          </div>

          <div className="grid grid-cols-2 md:grid-cols-3 gap-4">
            <Card className="bg-violet-50 border-2 border-black">
              <CardContent className="p-4 text-center">
                <UilBuilding className="h-8 w-8 mx-auto mb-2 text-orange-600" />
                <p className="text-sm font-bold uppercase">Directories</p>
                <p className="text-2xl font-black">{searchProgress >= 20 ? '✓' : '...'}</p>
              </CardContent>
            </Card>
            <Card className="bg-violet-50 border-2 border-black">
              <CardContent className="p-4 text-center">
                <UilGlobe className="h-8 w-8 mx-auto mb-2 text-green-600" />
                <p className="text-sm font-bold uppercase">Web</p>
                <p className="text-2xl font-black">{searchProgress >= 40 ? '✓' : '...'}</p>
              </CardContent>
            </Card>
            <Card className="bg-violet-50 border-2 border-black">
              <CardContent className="p-4 text-center">
                <UilDatabase className="h-8 w-8 mx-auto mb-2 text-purple-600" />
                <p className="text-sm font-bold uppercase">Database</p>
                <p className="text-2xl font-black">{searchProgress >= 60 ? '✓' : '...'}</p>
              </CardContent>
            </Card>
          </div>

          <PremiumFeatureCard
            title="SPEED UP SEARCHES"
            description="Upgrade to search 10x faster with priority processing"
            features={[
              'Priority search queue',
              'Parallel processing',
              'No rate limits',
              'Real-time results'
            ]}
            currentPlan="basic"
          />
        </div>
      </CardContent>
    </Card>
  );
}


================================================
FILE: frontend/src/components/onboarding/hunter/SearchResultsStep.tsx
================================================
'use client';

import * as React from 'react';
import { Card, CardContent } from '@/components/ui/card';
import { Button } from '@/components/ui/button';
import { 
  UilInfoCircle,
  UilUsersAlt,
  UilPhone
} from '@tooni/iconscout-unicons-react';
import { StepProps } from './types';

export function SearchResultsStep({
  searchResults,
  currentSearchId,
  userUsageStats
}: StepProps) {
  return (
    <Card className="transform rotate-1 relative overflow-hidden">
      <CardContent className="p-8">
        <div className="text-center mb-8">
          <h1 className="text-4xl md:text-5xl font-black uppercase text-black">
            HUNT COMPLETE!
          </h1>
        </div>
        <div className="space-y-6">
          <p className="text-xl text-center text-gray-700">
            Your lead list is ready! We found high-quality prospects matching your criteria.
          </p>
          
          {userUsageStats?.subscription?.tier === 'free' && (
            <Card className="bg-yellow-50 border-2 border-black">
              <CardContent className="p-4">
                <div className="flex items-start gap-3">
                  <Button size="sm" variant="neutral" className="bg-yellow-200 flex-shrink-0">
                    <UilInfoCircle className="h-4 w-4" />
                  </Button>
                  <div>
                    <p className="text-sm font-bold">FREE TIER NOTICE</p>
                    <p className="text-sm text-gray-700 mt-1">
                      Your search results will be available for 7 days. Upgrade to Premium to keep your data permanently.
                    </p>
                  </div>
                </div>
              </CardContent>
            </Card>
          )}

          {searchResults && (
            <div className="grid grid-cols-2 md:grid-cols-3 gap-4">
              <Card className="bg-violet-50 border-2 border-black transform -rotate-1">
                <CardContent className="p-4 text-center">
                  <p className="text-sm font-bold uppercase text-gray-600">Total Leads</p>
                  <p className="text-3xl font-black">{searchResults.totalLeads}</p>
                </CardContent>
              </Card>
              <Card className="bg-violet-50 border-2 border-black transform rotate-1">
                <CardContent className="p-4 text-center">
                  <p className="text-sm font-bold uppercase text-gray-600">Verified Emails</p>
                  <p className="text-3xl font-black">{searchResults.verifiedEmails}</p>
                </CardContent>
              </Card>
              <Card className="bg-violet-50 border-2 border-black transform -rotate-1">
                <CardContent className="p-4 text-center">
                  <p className="text-sm font-bold uppercase text-gray-600">Phone Numbers</p>
                  <p className="text-3xl font-black">{searchResults.verifiedPhones}</p>
                </CardContent>
              </Card>
              <Card className="bg-violet-50 border-2 border-black transform rotate-1">
                <CardContent className="p-4 text-center">
                  <p className="text-sm font-bold uppercase text-gray-600">Websites</p>
                  <p className="text-3xl font-black">{searchResults.businessWebsites}</p>
                </CardContent>
              </Card>
              <Card className="bg-violet-50 border-2 border-black transform -rotate-1">
                <CardContent className="p-4 text-center">
                  <p className="text-sm font-bold uppercase text-gray-600">Response Rate</p>
                  <p className="text-3xl font-black">{searchResults.avgResponseRate}</p>
                </CardContent>
              </Card>
              <Card className="bg-green-50 border-2 border-black transform rotate-1">
                <CardContent className="p-4 text-center">
                  <p className="text-sm font-bold uppercase text-gray-600">Search Time</p>
                  <p className="text-3xl font-black">{searchResults.searchTime}</p>
                </CardContent>
              </Card>
            </div>
          )}

          <div className="flex flex-col sm:flex-row gap-4">
            <Button
              className="flex-1 h-14 text-lg font-black uppercase bg-violet-400 hover:bg-violet-400/90 text-black"
              onClick={() => {
                if (currentSearchId) {
                  window.location.href = `/dashboard/hunter/search/${currentSearchId}`;
                } else {
                  window.location.href = '/dashboard/hunter';
                }
              }}
            >
              VIEW LEADS
              <UilUsersAlt className="ml-2 h-6 w-6" />
            </Button>
            <Button
              className="flex-1 h-14 text-lg font-black uppercase bg-[rgb(0,82,255)] hover:bg-blue-600 text-white"
              onClick={() => window.location.href = '/dashboard/calls'}
            >
              START CALLING
              <UilPhone className="ml-2 h-6 w-6" />
            </Button>
          </div>
        </div>
      </CardContent>
    </Card>
  );
}


================================================
FILE: frontend/src/components/onboarding/hunter/types.ts
================================================
import * as React from 'react';

export interface SearchCriteria {
  industry: string;
  location: string;
  companySize: string;
  jobTitles: string[];
  keywords: string;
}

export interface ValidationCriteria {
  mustHaveWebsite: boolean;
  mustHaveContactInfo: boolean;
  mustHaveSpecificKeywords: string[];
  mustBeInIndustry: boolean;
  customValidationRules: string;
}

export interface LeadSource {
  id: string;
  name: string;
  icon: React.ReactNode;
  description: string;
  color: string;
}

export interface ContactPreferences {
  includeEmails: boolean;
  includePhones: boolean;
  includeLinkedIn: boolean;
}

export interface SearchResults {
  totalLeads: number;
  verifiedEmails: number;
  verifiedPhones: number;
  businessWebsites: number;
  avgResponseRate: string;
  searchTime: string;
}

export interface StepProps {
  // Step state
  currentStep: number;
  setCurrentStep: (step: number) => void;
  
  // Search definition state
  searchName: string;
  setSearchName: (name: string) => void;
  searchObjective: string;
  setSearchObjective: (objective: string) => void;
  selectedSources: string[];
  setSelectedSources: (sources: string[]) => void;
  
  // Search criteria state
  searchCriteria: SearchCriteria;
  setSearchCriteria: (criteria: SearchCriteria) => void;
  customIndustry: string;
  setCustomIndustry: (industry: string) => void;
  
  // Contact preferences state
  contactPreferences: ContactPreferences;
  setContactPreferences: (preferences: ContactPreferences) => void;
  
  // Validation criteria state
  validationCriteria: ValidationCriteria;
  setValidationCriteria: (criteria: ValidationCriteria) => void;
  
  // Search execution state
  isSearching: boolean;
  setIsSearching: (searching: boolean) => void;
  searchProgress: number;
  setSearchProgress: (progress: number) => void;
  currentStatus: string;
  setCurrentStatus: (status: string) => void;
  searchResults: SearchResults | null;
  setSearchResults: (results: SearchResults | null) => void;
  currentSearchId: string | null;
  setCurrentSearchId: (id: string | null) => void;
  
  // Verification state
  showVerification: boolean;
  setShowVerification: (show: boolean) => void;
  
  // Dev mode state
  devMode: boolean;
  setDevMode: (mode: boolean) => void;
  
  // Functions
  handleSourceSelect: (sourceId: string) => void;
  toggleJobTitle: (title: string) => void;
  canStartSearch: () => boolean;
  startSearch: () => Promise<void>;
  handleVerificationComplete: (email: string, phone: string) => Promise<void>;
  handleStepChange: (step: number) => void;
  
  // Convex data
  userUsageStats?: any;
  createLeadSearch?: any;
  getSearchStatus?: any;
  
  // Constants
  leadSources: LeadSource[];
  industries: string[];
  jobTitles: string[];
}


================================================
FILE: frontend/src/components/onboarding/hunter/ValidationCriteriaStep.tsx
================================================
'use client';

import * as React from 'react';
import { Card, CardContent } from '@/components/ui/card';
import { Button } from '@/components/ui/button';
import { Input } from '@/components/ui/input';
import { Textarea } from '@/components/ui/textarea';
import { Switch } from '@/components/ui/switch';
import { Tooltip, TooltipContent, TooltipTrigger } from '@/components/ui/tooltip';
import { 
  UilArrowRight,
  UilArrowLeft,
  UilGlobe,
  UilEnvelope,
  UilBuilding,
  UilCrosshair,
  UilInfoCircle,
  UilClipboardNotes
} from '@tooni/iconscout-unicons-react';
import { StepProps } from './types';

export function ValidationCriteriaStep({
  validationCriteria,
  setValidationCriteria,
  setCurrentStep
}: StepProps) {
  return (
    <Card className="transform rotate-1 relative overflow-hidden">
      <CardContent className="p-8">
        <div className="text-center mb-8">
          <h1 className="text-4xl md:text-5xl font-black uppercase text-black">
            VALIDATION CRITERIA
          </h1>
        </div>
        <p className="text-xl text-center text-gray-700 mb-8">
          Define what makes a lead valid for your search
        </p>
        <div className="space-y-6">
          <Card className="border-2 border-black bg-violet-50">
            <CardContent className="p-6">
              <div className="flex items-center justify-between">
                <div className="flex items-center gap-4">
                  <Button size="icon" variant="header" className="w-12 h-12 bg-green-500">
                    <UilGlobe className="h-6 w-6 text-white" />
                  </Button>
                  <div>
                    <h3 className="text-lg font-black uppercase">ACTIVE WEBSITE</h3>
                    <p className="text-sm text-gray-600">Must have a functioning business website</p>
                  </div>
                </div>
                <Tooltip>
                  <TooltipTrigger asChild>
                    <Switch
                      checked={validationCriteria.mustHaveWebsite}
                      onCheckedChange={(checked) => 
                        setValidationCriteria({...validationCriteria, mustHaveWebsite: checked})
                      }
                    />
                  </TooltipTrigger>
                  <TooltipContent>
                    <p>Only include businesses with verified, active websites</p>
                  </TooltipContent>
                </Tooltip>
              </div>
            </CardContent>
          </Card>

          <Card className="border-2 border-black bg-violet-50">
            <CardContent className="p-6">
              <div className="flex items-center justify-between">
                <div className="flex items-center gap-4">
                  <Button size="icon" variant="header" className="w-12 h-12 bg-blue-500">
                    <UilEnvelope className="h-6 w-6 text-white" />
                  </Button>
                  <div>
                    <h3 className="text-lg font-black uppercase">CONTACT INFORMATION</h3>
                    <p className="text-sm text-gray-600">Must have visible contact details</p>
                  </div>
                </div>
                <Tooltip>
                  <TooltipTrigger asChild>
                    <Switch
                      checked={validationCriteria.mustHaveContactInfo}
                      onCheckedChange={(checked) => 
                        setValidationCriteria({...validationCriteria, mustHaveContactInfo: checked})
                      }
                    />
                  </TooltipTrigger>
                  <TooltipContent>
                    <p>Filter out businesses without verifiable contact information</p>
                  </TooltipContent>
                </Tooltip>
              </div>
            </CardContent>
          </Card>

          <Card className="border-2 border-black bg-violet-50">
            <CardContent className="p-6">
              <div className="flex items-center justify-between">
                <div className="flex items-center gap-4">
                  <Button size="icon" variant="header" className="w-12 h-12 bg-purple-500">
                    <UilBuilding className="h-6 w-6 text-white" />
                  </Button>
                  <div>
                    <h3 className="text-lg font-black uppercase">INDUSTRY MATCH</h3>
                    <p className="text-sm text-gray-600">Must be in the selected industry</p>
                  </div>
                </div>
                <Tooltip>
                  <TooltipTrigger asChild>
                    <Switch
                      checked={validationCriteria.mustBeInIndustry}
                      onCheckedChange={(checked) => 
                        setValidationCriteria({...validationCriteria, mustBeInIndustry: checked})
                      }
                    />
                  </TooltipTrigger>
                  <TooltipContent>
                    <p>Strictly enforce industry classification matching</p>
                  </TooltipContent>
                </Tooltip>
              </div>
            </CardContent>
          </Card>

          <Card className="border-2 border-black bg-violet-50">
            <CardContent className="p-6">
              <div>
                <Tooltip>
                  <TooltipTrigger asChild>
                    <h3 className="text-lg font-black uppercase mb-3 flex items-center gap-3 cursor-help">
                      <UilCrosshair className="h-6 w-6" />
                      REQUIRED KEYWORDS
                      <UilInfoCircle className="h-4 w-4 text-gray-600" />
                    </h3>
                  </TooltipTrigger>
                  <TooltipContent className="max-w-xs">
                    <p>Leads must have ALL of these keywords on their website to be included in results</p>
                  </TooltipContent>
                </Tooltip>
                <p className="text-sm text-gray-600 mb-3">
                  Comma-separated keywords that must appear on the website
                </p>
                <Input
                  type="text"
                  value={validationCriteria.mustHaveSpecificKeywords.join(', ')}
                  onChange={(e) => {
                    const value = e.target.value;
                    // Only split by comma if the user is not in the middle of typing
                    if (value.endsWith(',') || value.endsWith(', ')) {
                      setValidationCriteria({
                        ...validationCriteria, 
                        mustHaveSpecificKeywords: value.split(',').map(k => k.trim()).filter(k => k)
                      });
                    } else {
                      // For display purposes, update the array on blur or when needed
                      const keywords = value.split(',').map(k => k.trim()).filter(k => k);
                      setValidationCriteria({
                        ...validationCriteria, 
                        mustHaveSpecificKeywords: keywords
                      });
                    }
                  }}
                  onBlur={(e) => {
                    // Ensure clean split on blur
                    const keywords = e.target.value.split(',').map(k => k.trim()).filter(k => k);
                    setValidationCriteria({
                      ...validationCriteria, 
                      mustHaveSpecificKeywords: keywords
                    });
                  }}
                  placeholder="e.g., partner, affiliate, reseller, api, integration"
                  className="h-14 text-lg font-semibold border-4 border-black rounded-[3px]"
                />
              </div>
            </CardContent>
          </Card>

          <Card className="border-2 border-black bg-violet-50">
            <CardContent className="p-6">
              <div>
                <h3 className="text-lg font-black uppercase mb-3 flex items-center gap-3">
                  <UilClipboardNotes className="h-6 w-6" />
                  CUSTOM VALIDATION RULES
                </h3>
                <p className="text-sm text-gray-600 mb-3">
                  Additional requirements or criteria for lead validation
                </p>
                <Textarea
                  value={validationCriteria.customValidationRules}
                  onChange={(e) => setValidationCriteria({
                    ...validationCriteria, 
                    customValidationRules: e.target.value
                  })}
                  placeholder="e.g., Must offer enterprise solutions, Must have case studies, Must serve international clients..."
                  className="min-h-[120px] text-lg font-semibold border-4 border-black rounded-[3px] resize-none"
                />
              </div>
            </CardContent>
          </Card>

          <div className="flex gap-4">
            <Button
              className="flex-1 h-14 text-lg font-black uppercase bg-gray-300 hover:bg-gray-400 text-black"
              onClick={() => setCurrentStep(3)}
            >
              <UilArrowLeft className="mr-2 h-6 w-6" />
              BACK
            </Button>
            <Button
              className="flex-1 h-14 text-lg font-black uppercase bg-yellow-400 hover:bg-yellow-400/90 text-black"
              onClick={() => setCurrentStep(4)}
            >
              CONTINUE
              <UilArrowRight className="ml-2 h-6 w-6" />
            </Button>
          </div>
        </div>
      </CardContent>
    </Card>
  );
}


================================================
FILE: frontend/src/hooks/useHunterSearch.ts
================================================
'use client';

import { useQuery } from 'convex/react';
import { api } from '@convex/_generated/api';
import { useEffect, useState } from 'react';
import { useConvexErrorHandler } from './useConvexErrorHandler';

interface SearchWorkflow {
  id: string;
  searchId?: string;
  name: string;
  status: 'idle' | 'searching' | 'scraping' | 'analyzing' | 'validating' | 'completed' | 'failed';
  progress: number;
  currentStage?: string;
  parameters: {
    location: string;
    businessType: string;
    keywords: string[];
    includeLinkedIn: boolean;
    searchDepth: number;
  };
  stats: {
    pagesFound: number;
    pagesScraped: number;
    businessesExtracted: number;
    businessesValidated: number;
    matchRate: number;
  };
  createdAt: string;
  completedAt?: string;
  estimatedTime?: string;
}

// Map backend status to frontend status
const mapBackendStatus = (status: string): SearchWorkflow['status'] => {
  const statusMap: Record<string, SearchWorkflow['status']> = {
    'pending': 'idle',
    'initializing': 'searching',
    'processing': 'analyzing',
    'completed': 'completed',
    'failed': 'failed'
  };
  return statusMap[status] || 'searching';
};

// Map progress to stage
const getStageFromProgress = (progress: number): SearchWorkflow['status'] => {
  if (progress === 0) return 'idle';
  if (progress < 25) return 'searching';
  if (progress < 50) return 'scraping';
  if (progress < 75) return 'analyzing';
  if (progress < 100) return 'validating';
  return 'completed';
};

export function useHunterSearches(userId: string) {
  const [searches, setSearches] = useState<SearchWorkflow[]>([]);
  const [isLoading, setIsLoading] = useState(true);
  
  // Get user's search history with stats
  const searchHistory = useQuery(api.hunterQueries.getUserSearchesForHunter, { 
    userId,
    includeStats: true 
  });
  
  // Get dashboard data for statistics
  const dashboardData = useQuery(api.hunterQueries.getUserDashboardData, { userId });

  useEffect(() => {
    if (!searchHistory) {
      setIsLoading(true);
      return;
    }

    // Convert backend searches to frontend format
    const convertedSearches: SearchWorkflow[] = searchHistory.map((search: any) => ({
      id: search.searchId,
      searchId: search.searchId, // Include searchId for actions
      name: search.searchName || 'Untitled Search',
      status: search.progress >= 100 ? 'completed' : getStageFromProgress(search.progress || 0),
      progress: search.progress || 0,
      currentStage: search.currentStage || '',
      parameters: {
        location: search.location || 'Unknown',
        businessType: search.industry || 'Unknown',
        keywords: search.keywords ? search.keywords.split(',').map((k: string) => k.trim()) : [],
        includeLinkedIn: search.includeLinkedIn || false,
        searchDepth: 3 // Default value
      },
      stats: {
        pagesFound: 0, // These will be updated from search results
        pagesScraped: 0,
        businessesExtracted: search.totalLeads || 0,
        businessesValidated: search.verifiedEmails || 0,
        matchRate: search.totalLeads > 0 ? 
          Math.round((search.verifiedEmails / search.totalLeads) * 100) : 0
      },
      createdAt: search.createdAt,
      completedAt: search.completedAt,
      estimatedTime: search.status === 'processing' ? 
        `${Math.max(1, Math.round((100 - search.progress) / 2))} min remaining` : undefined
    }));

    setSearches(convertedSearches);
    setIsLoading(false);
  }, [searchHistory]);

  // Poll for updates on active searches
  useEffect(() => {
    const activeSearches = searches.filter(s => 
      s.status !== 'completed' && s.status !== 'failed'
    );
    
    if (activeSearches.length === 0) return;

    // Poll every 3 seconds for active searches
    const interval = setInterval(() => {
      // Trigger a refetch by updating a dummy state
      // This will cause Convex to re-query
      setSearches(prev => [...prev]);
    }, 3000);

    return () => clearInterval(interval);
  }, [searches]);

  return {
    searches,
    isLoading,
    stats: dashboardData?.stats || {
      totalSearches: 0,
      activeSearches: 0,
      totalLeadsThisMonth: 0,
      searchesToday: 0
    }
  };
}

export function useHunterSearch(searchId: string) {
  const search = useQuery(api.hunterQueries.getLeadSearch, { searchId });
  const [pollingEnabled, setPollingEnabled] = useState(true);

  useEffect(() => {
    if (!search) return;
    
    // Stop polling if search is completed or failed
    if (search.status === 'completed' || search.status === 'failed') {
      setPollingEnabled(false);
    }
  }, [search]);

  // Poll for updates if search is active
  useEffect(() => {
    if (!pollingEnabled) return;

    const interval = setInterval(() => {
      // Force re-query by updating state
      // Convex will automatically refetch
    }, 2000);

    return () => clearInterval(interval);
  }, [pollingEnabled]);

  return {
    search,
    isLoading: !search,
    progress: search?.progress || 0,
    status: search?.status || 'pending',
    currentStage: search?.currentStage || ''
  };
}

